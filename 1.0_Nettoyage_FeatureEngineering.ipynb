{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b280b98",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# ===============================================\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# IMPORTS VISUALISATION ET API EXTERNE\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ===============================================\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstackapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StackAPI \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\matplotlib\\__init__.py:1296\u001b[39m\n\u001b[32m   1292\u001b[39m     rcParams[\u001b[33m'\u001b[39m\u001b[33mbackend_fallback\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.environ.get(\u001b[33m'\u001b[39m\u001b[33mMPLBACKEND\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1296\u001b[39m     \u001b[43mrcParams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbackend\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = os.environ.get(\u001b[33m'\u001b[39m\u001b[33mMPLBACKEND\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1299\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_backend\u001b[39m(*, auto_select=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1300\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1301\u001b[39m \u001b[33;03m    Return the name of the current backend.\u001b[39;00m\n\u001b[32m   1302\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1320\u001b[39m \u001b[33;03m    matplotlib.use\u001b[39;00m\n\u001b[32m   1321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\matplotlib\\__init__.py:769\u001b[39m, in \u001b[36mRcParams.__setitem__\u001b[39m\u001b[34m(self, key, val)\u001b[39m\n\u001b[32m    767\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m     cval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[32m    771\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKey \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mve\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\matplotlib\\rcsetup.py:273\u001b[39m, in \u001b[36mvalidate_backend\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_backend\u001b[39m(s):\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m _auto_backend_sentinel \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mbackend_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_valid_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    274\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m s\n\u001b[32m    275\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\matplotlib\\backends\\registry.py:244\u001b[39m, in \u001b[36mBackendRegistry.is_valid_backend\u001b[39m\u001b[34m(self, backend)\u001b[39m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# Only load entry points if really need to and not already done so.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ensure_entry_points_loaded\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend_to_gui_framework:\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\matplotlib\\backends\\registry.py:116\u001b[39m, in \u001b[36mBackendRegistry._ensure_entry_points_loaded\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_ensure_entry_points_loaded\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# Load entry points, if they have not already been loaded.\u001b[39;00m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._loaded_entry_points:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         entries = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_entry_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m         \u001b[38;5;28mself\u001b[39m._validate_and_store_entry_points(entries)\n\u001b[32m    118\u001b[39m         \u001b[38;5;28mself\u001b[39m._loaded_entry_points = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\matplotlib\\backends\\registry.py:136\u001b[39m, in \u001b[36mBackendRegistry._read_entry_points\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_entry_points\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    129\u001b[39m     \u001b[38;5;66;03m# Read entry points of modules that self-advertise as Matplotlib backends.\u001b[39;00m\n\u001b[32m    130\u001b[39m     \u001b[38;5;66;03m# Expects entry points like this one from matplotlib-inline (in pyproject.toml\u001b[39;00m\n\u001b[32m    131\u001b[39m     \u001b[38;5;66;03m# format):\u001b[39;00m\n\u001b[32m    132\u001b[39m     \u001b[38;5;66;03m#   [project.entry-points.\"matplotlib.backend\"]\u001b[39;00m\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m#   inline = \"matplotlib_inline.backend_inline\"\u001b[39;00m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetadata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mim\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     entry_points = \u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mentry_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmatplotlib.backend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m     entries = [(entry.name, entry.value) \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m entry_points]\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# For backward compatibility, if matplotlib-inline and/or ipympl are installed\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# but too old to include entry points, create them. Do not import ipympl\u001b[39;00m\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# directly as this calls matplotlib.use() whilst in this function.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\metadata\\__init__.py:1011\u001b[39m, in \u001b[36mentry_points\u001b[39m\u001b[34m(**params)\u001b[39m\n\u001b[32m   1000\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return EntryPoint objects for all installed packages.\u001b[39;00m\n\u001b[32m   1001\u001b[39m \n\u001b[32m   1002\u001b[39m \u001b[33;03mPass selection parameters (group or name) to filter the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1006\u001b[39m \u001b[33;03m:return: EntryPoints for all installed packages.\u001b[39;00m\n\u001b[32m   1007\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1008\u001b[39m eps = itertools.chain.from_iterable(\n\u001b[32m   1009\u001b[39m     dist.entry_points \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m _unique(distributions())\n\u001b[32m   1010\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1011\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEntryPoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m.select(**params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\metadata\\__init__.py:1009\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    999\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mentry_points\u001b[39m(**params) -> EntryPoints:\n\u001b[32m   1000\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return EntryPoint objects for all installed packages.\u001b[39;00m\n\u001b[32m   1001\u001b[39m \n\u001b[32m   1002\u001b[39m \u001b[33;03m    Pass selection parameters (group or name) to filter the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1006\u001b[39m \u001b[33;03m    :return: EntryPoints for all installed packages.\u001b[39;00m\n\u001b[32m   1007\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1008\u001b[39m     eps = itertools.chain.from_iterable(\n\u001b[32m-> \u001b[39m\u001b[32m1009\u001b[39m         \u001b[43mdist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mentry_points\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m _unique(distributions())\n\u001b[32m   1010\u001b[39m     )\n\u001b[32m   1011\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m EntryPoints(eps).select(**params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\metadata\\__init__.py:496\u001b[39m, in \u001b[36mDistribution.entry_points\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    488\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mentry_points\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> EntryPoints:\n\u001b[32m    490\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[33;03m    Return EntryPoints for this distribution.\u001b[39;00m\n\u001b[32m    492\u001b[39m \n\u001b[32m    493\u001b[39m \u001b[33;03m    Custom providers may provide the ``entry_points.txt`` file\u001b[39;00m\n\u001b[32m    494\u001b[39m \u001b[33;03m    or override this property.\u001b[39;00m\n\u001b[32m    495\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m EntryPoints._from_text_for(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mentry_points.txt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\metadata\\__init__.py:915\u001b[39m, in \u001b[36mPathDistribution.read_text\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m    907\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename: \u001b[38;5;28mstr\u001b[39m | os.PathLike[\u001b[38;5;28mstr\u001b[39m]) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    908\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(\n\u001b[32m    909\u001b[39m         \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m,\n\u001b[32m    910\u001b[39m         \u001b[38;5;167;01mIsADirectoryError\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;167;01mPermissionError\u001b[39;00m,\n\u001b[32m    914\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoinpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\pathlib\\_local.py:546\u001b[39m, in \u001b[36mPath.read_text\u001b[39m\u001b[34m(self, encoding, errors, newline)\u001b[39m\n\u001b[32m    543\u001b[39m \u001b[38;5;66;03m# Call io.text_encoding() here to ensure any warning is raised at an\u001b[39;00m\n\u001b[32m    544\u001b[39m \u001b[38;5;66;03m# appropriate stack level.\u001b[39;00m\n\u001b[32m    545\u001b[39m encoding = io.text_encoding(encoding)\n\u001b[32m--> \u001b[39m\u001b[32m546\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPathBase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\pathlib\\_abc.py:632\u001b[39m, in \u001b[36mPathBase.read_text\u001b[39m\u001b[34m(self, encoding, errors, newline)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoding=\u001b[38;5;28;01mNone\u001b[39;00m, errors=\u001b[38;5;28;01mNone\u001b[39;00m, newline=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    629\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    630\u001b[39m \u001b[33;03m    Open the file in text mode, read it, and close the file.\u001b[39;00m\n\u001b[32m    631\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m f.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\pathlib\\_local.py:537\u001b[39m, in \u001b[36mPath.open\u001b[39m\u001b[34m(self, mode, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m    536\u001b[39m     encoding = io.text_encoding(encoding)\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:312\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, errors)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#MISE EN PLACE DES BIBLIOTHEQUES\n",
    "# ===============================================\n",
    "# IMPORTS STANDARD ET DE BASE\n",
    "# ===============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "# ===============================================\n",
    "# IMPORTS VISUALISATION ET API EXTERNE\n",
    "# ===============================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from stackapi import StackAPI \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ===============================================\n",
    "# IMPORTS MLOPS ET TRACKING\n",
    "# ===============================================\n",
    "import mlflow\n",
    "from mlflow.exceptions import MlflowException\n",
    "# from mlflow.tracking import MlflowClient # Peut être ajouté si nécessaire pour la fin du projet\n",
    "\n",
    "# ===============================================\n",
    "# IMPORTS NLP ET PRÉTRAITEMENT\n",
    "# ===============================================\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "# Téléchargements NLTK (à laisser en début de notebook)\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "# ===============================================\n",
    "# IMPORTS SCIKIT-LEARN\n",
    "# ===============================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # <-- AJOUT CRUCIAL MANQUANT !\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, hamming_loss\n",
    "\n",
    "# ===============================================\n",
    "# IMPORTS EMBEDDINGS (GENSIM, HUGGING FACE, TF-HUB)\n",
    "# ===============================================\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb21d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MLFlow Tracking URI configuré : file:///C:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuration MLFlow - définir le chemin de tracking\n",
    "mlflow.set_tracking_uri(\"file:///C:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns\")\n",
    "print(f\" MLFlow Tracking URI configuré : {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa4218",
   "metadata": {},
   "source": [
    "# test  qualité API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c155314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recherche de 50 questions avec le tag 'python' et un score > 8 sur les 90 derniers jours...\n",
      "\n",
      "--- Résultat du Test API ---\n",
      "Questions récupérées : 56/50 (Succès de l'appel).\n",
      "         date_creation                                              titre  \\\n",
      "0  2025-01-09 22:04:59      How to add requirements.txt to uv environment   \n",
      "1  2024-12-18 12:45:52  &#39;super&#39; object has no attribute &#39;_...   \n",
      "2  2025-01-13 16:24:07  How/why are {2,3,10} and {x,3,10} with x=2 ord...   \n",
      "3  2025-08-02 18:59:55  How to set up a simple hello-world example whe...   \n",
      "4  2025-04-02 11:41:54  import numpy failed after upgrading MacOS to 15.4   \n",
      "\n",
      "                                              tags  score body_snippet  \n",
      "0                          python, python-venv, uv     48       N/A...  \n",
      "1  python, machine-learning, scikit-learn, xgboost     32       N/A...  \n",
      "2                python, cpython, python-internals     21       N/A...  \n",
      "3                    python, c, python-3.x, cython     20       N/A...  \n",
      "4                             python, macos, numpy     18       N/A...  \n"
     ]
    }
   ],
   "source": [
    "# --- Critères de la Requête ---\n",
    "TAG = 'python'\n",
    "MIN_SCORE = 8\n",
    "PAGE_SIZE = 50 # Le maximum par requête non authentifiée\n",
    "\n",
    "# Période définie : Nous prenons les 3 derniers mois comme exemple de \"période définie\"\n",
    "to_date = int(time.time()) # Aujourd'hui (timestamp UNIX)\n",
    "from_date = int((datetime.now() - timedelta(days=365)).timestamp()) # Il y a 90 jours\n",
    "\n",
    "# 1. Initialiser le client de l'API pour Stack Overflow\n",
    "SITE = StackAPI('stackoverflow')\n",
    "\n",
    "# 2. Effectuer la requête\n",
    "print(f\"Recherche de {PAGE_SIZE} questions avec le tag '{TAG}' et un score > {MIN_SCORE} sur les 90 derniers jours...\")\n",
    "\n",
    "try:\n",
    "    # La méthode fetch utilise l'endpoint 'questions' par défaut\n",
    "    questions_data = SITE.fetch(\n",
    "        'questions', \n",
    "        pagesize=PAGE_SIZE, \n",
    "        tagged=TAG, \n",
    "        sort='votes',   # Trier par votes pour appliquer le filtre 'min'\n",
    "        min=MIN_SCORE,  # Filtrer sur le score minimal (votes)\n",
    "        fromdate=from_date, \n",
    "        todate=to_date,\n",
    "\n",
    "    )\n",
    "\n",
    "    # 3. Préparer les données pour le DataFrame\n",
    "    data_list = []\n",
    "    items = questions_data.get('items', [])\n",
    "    \n",
    "    for q in items:\n",
    "                # Nous ne prenons que les données nécessaires (RGPD)\n",
    "        data_list.append({\n",
    "            'date_creation': datetime.fromtimestamp(q['creation_date']).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'titre': q['title'],\n",
    "            'tags': \", \".join(q['tags']) if 'tags' in q else 'N/A',\n",
    "            'score': q['score'],\n",
    "            'body_snippet': q.get('body', 'N/A')[:100] + '...' \n",
    "        })\n",
    "\n",
    "    # 4. Afficher le DataFrame\n",
    "    df_api_test = pd.DataFrame(data_list)\n",
    "    print(f\"\\n--- Résultat du Test API ---\")\n",
    "    print(f\"Questions récupérées : {len(df_api_test)}/{PAGE_SIZE} (Succès de l'appel).\")\n",
    "    print(df_api_test.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nErreur lors de l'appel à l'API : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6afe2e",
   "metadata": {},
   "source": [
    "# Préparation et Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d07e799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame d'entraînement chargé avec succès.\n",
      "\n",
      "Nettoyage du HTML en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lza\\AppData\\Local\\Temp\\ipykernel_22864\\842519030.py:20: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  soup = BeautifulSoup(text, 'html.parser')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu du texte nettoyé :\n",
      "Paging a collection with LINQ  How do you page through a collection in LINQ given that you have a  startIndex  and a  count ?  \n"
     ]
    }
   ],
   "source": [
    "# Simulation du chargement du fichier CSV des 50 000 questions\n",
    "try:\n",
    "    df_train = pd.read_csv('./data/stack_overflow_brut.csv', encoding='utf-8')\n",
    "    # On va créer une colonne de texte combiné pour l'analyse\n",
    "    df_train['Text_Raw'] = df_train['Title'] + \" \" + df_train['Body']\n",
    "    print(\"DataFrame d'entraînement chargé avec succès.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Erreur : Fichier d'entraînement 50k non trouvé. Passez à la simulation.\")\n",
    "\n",
    "# --- Fonctions de Nettoyage ---\n",
    "\n",
    "def clean_html_and_code(text):\n",
    "    \"\"\"\n",
    "    Supprime les balises HTML et extrait le texte brut.\n",
    "    Ceci est VITAL car le 'Body' Stack Overflow est en HTML.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Utilise BeautifulSoup pour parser et extraire le texte\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    cleaned_text = soup.get_text(separator=' ')\n",
    "    \n",
    "    # Optionnel : Remplacer les retours à la ligne par des espaces\n",
    "    cleaned_text = re.sub('\\n', ' ', cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Application de la première étape de nettoyage\n",
    "print(\"\\nNettoyage du HTML en cours...\")\n",
    "df_train['Text_Cleaned'] = df_train['Text_Raw'].apply(clean_html_and_code)\n",
    "\n",
    "# Affichage des 5 premières lignes pour valider le nettoyage\n",
    "print(\"Aperçu du texte nettoyé :\")\n",
    "print(df_train[['Text_Raw', 'Text_Cleaned']].head(1)['Text_Cleaned'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b657dad0",
   "metadata": {},
   "source": [
    "# Nettoyage linguistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1916c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Vérification du Pipeline de Nettoyage ---\n",
      "                                        Text_Cleaned  \\\n",
      "0  Paging a collection with LINQ  How do you page...   \n",
      "1  How do I add existing comments to RDoc in Ruby...   \n",
      "\n",
      "                                          Tokens_LDA  \\\n",
      "0  paging collection linq how page collection lin...   \n",
      "1  how add existing comment rdoc ruby want format...   \n",
      "\n",
      "                                           Tokens_DL  \n",
      "0  paging a collection with linq how do you page ...  \n",
      "1  how do i add existing comments to rdoc in ruby...  \n"
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "def tokenizer_fct(sentence) :\n",
    "    # print(sentence)\n",
    "    sentence_clean = sentence.replace('-', ' ').replace('+', ' ').replace('/', ' ').replace('#', ' ')\n",
    "    word_tokens = word_tokenize(sentence_clean)\n",
    "    return word_tokens\n",
    "\n",
    "# Stop words\n",
    "\n",
    "stop_w = list(set(stopwords.words('english'))) + ['[', ']', ',', '.', ':', '?', '(', ')']\n",
    "\n",
    "def stop_word_filter_fct(list_words) :\n",
    "    filtered_w = [w for w in list_words if not w in stop_w]\n",
    "    filtered_w2 = [w for w in filtered_w if len(w) > 2]\n",
    "    return filtered_w2\n",
    "\n",
    "# lower case et alpha\n",
    "def lower_start_fct(list_words) :\n",
    "    lw = [w.lower() for w in list_words if (not w.startswith(\"@\")) \n",
    "    #                                   and (not w.startswith(\"#\"))\n",
    "                                       and (not w.startswith(\"http\"))]\n",
    "    return lw\n",
    "\n",
    "# Lemmatizer (base d'un mot)\n",
    "def lemma_fct(list_words) :\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_w = [lemmatizer.lemmatize(w) for w in list_words]\n",
    "    return lem_w\n",
    "\n",
    "# Fonction de préparation du texte pour le bag of words (Countvectorizer et Tf_idf, Word2Vec)\n",
    "def transform_bow_fct(desc_text) :\n",
    "    word_tokens = tokenizer_fct(desc_text)\n",
    "    sw = stop_word_filter_fct(word_tokens)\n",
    "    lw = lower_start_fct(sw)\n",
    "    # lem_w = lemma_fct(lw)    \n",
    "    transf_desc_text = ' '.join(lw)\n",
    "    return transf_desc_text\n",
    "\n",
    "# Fonction de préparation du texte pour le bag of words avec lemmatization\n",
    "def transform_bow_lem_fct(desc_text) :\n",
    "    word_tokens = tokenizer_fct(desc_text)\n",
    "    sw = stop_word_filter_fct(word_tokens)\n",
    "    lw = lower_start_fct(sw)\n",
    "    lem_w = lemma_fct(lw)    \n",
    "    transf_desc_text = ' '.join(lem_w)\n",
    "    return transf_desc_text\n",
    "\n",
    "# Fonction de préparation du texte pour le Deep learning (USE et BERT)\n",
    "def transform_dl_fct(desc_text) :\n",
    "    word_tokens = tokenizer_fct(desc_text)\n",
    "#    sw = stop_word_filter_fct(word_tokens)\n",
    "    lw = lower_start_fct(word_tokens)\n",
    "    # lem_w = lemma_fct(lw)    \n",
    "    transf_desc_text = ' '.join(lw)\n",
    "    return transf_desc_text\n",
    "\n",
    "# Assurez-vous que votre colonne 'Text_Cleaned' est bien le texte sans HTML\n",
    "\n",
    "# 1. Création de la colonne pour LDA / Bag-of-Words (avec lemmatisation)\n",
    "# C'est la préparation la plus complète et la plus efficace pour les méthodes classiques\n",
    "df_train['Tokens_LDA'] = df_train['Text_Cleaned'].apply(lambda x : transform_bow_lem_fct(x))\n",
    "\n",
    "# 2. Création de la colonne pour le Deep Learning (sans lemmatisation ni stop words)\n",
    "# Les modèles comme BERT et USE préfèrent garder le contexte intact\n",
    "df_train['Tokens_DL'] = df_train['Text_Cleaned'].apply(lambda x : transform_dl_fct(x))\n",
    "\n",
    "# Affichage pour la validation\n",
    "print(\"--- Vérification du Pipeline de Nettoyage ---\")\n",
    "print(df_train[['Text_Cleaned', 'Tokens_LDA', 'Tokens_DL']].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69047561",
   "metadata": {},
   "source": [
    "# Création du dictionnaire et du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ad8fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage de la création du Dictionnaire et du Corpus...\n",
      "\n",
      "--- Préparation du Corpus LDA Terminé ---\n",
      "Taille du vocabulaire final : 24054 mots\n",
      "Nombre de documents analysés : 50000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Note : Votre fonction transform_bow_lem_fct retourne une CHAÎNE de caractères.\n",
    "# Gensim a besoin d'une LISTE de listes de mots. Nous utilisons .apply(str.split) \n",
    "# pour convertir chaque chaîne en liste de mots.\n",
    "print(\"Démarrage de la création du Dictionnaire et du Corpus...\")\n",
    "\n",
    "# 1. Création du Dictionnaire\n",
    "# Cette ligne identifie et numérote tous les mots uniques (le vocabulaire)\n",
    "dictionary = corpora.Dictionary(df_train['Tokens_LDA'].apply(str.split))\n",
    "\n",
    "# 2. Filtrage des Extrêmes (Crucial pour le bruit)\n",
    "# On garde un vocabulaire pertinent pour le modèle (mots ni trop rares, ni trop fréquents)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5) \n",
    "\n",
    "# 3. Création du Corpus (Format Bag-of-Words)\n",
    "# Chaque document est transformé en une liste de (id_mot, fréquence)\n",
    "corpus = [dictionary.doc2bow(tokens.split()) for tokens in df_train['Tokens_LDA']]\n",
    "\n",
    "print(f\"\\n--- Préparation du Corpus LDA Terminé ---\")\n",
    "#topic modeling\n",
    "print(f\"Taille du vocabulaire final : {len(dictionary)} mots\")\n",
    "print(f\"Nombre de documents analysés : {len(corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb39cc",
   "metadata": {},
   "source": [
    "# Lancement du LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cada6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Démarrage de l'entraînement LDA avec 10 thèmes ---\n",
      "\n",
      "Suggestions de Tags (Mots-Clés par Thème, Coherence: 0.5785) :\n",
      "Thème 1: 0.061*\"public\" + 0.044*\"new\" + 0.043*\"int\" + 0.042*\"string\" + 0.034*\"android\"\n",
      "Thème 2: 0.033*\"image\" + 0.024*\"event\" + 0.018*\"item\" + 0.018*\"button\" + 0.017*\"new\"\n",
      "Thème 3: 0.014*\"n't\" + 0.013*\"would\" + 0.013*\"like\" + 0.012*\"way\" + 0.012*\"using\"\n",
      "Thème 4: 0.025*\"value\" + 0.024*\"string\" + 0.020*\"array\" + 0.015*\"list\" + 0.012*\"number\"\n",
      "Thème 5: 0.042*\"file\" + 0.022*\"error\" + 0.020*\"server\" + 0.009*\"project\" + 0.009*\"using\"\n",
      "Thème 6: 0.023*\"class\" + 0.019*\"object\" + 0.015*\"function\" + 0.015*\"method\" + 0.014*\"code\"\n",
      "Thème 7: 0.036*\"table\" + 0.025*\"database\" + 0.021*\"query\" + 0.019*\"select\" + 0.018*\"sql\"\n",
      "Thème 8: 0.027*\"page\" + 0.025*\"view\" + 0.014*\"url\" + 0.012*\"form\" + 0.011*\"model\"\n",
      "Thème 9: 0.056*\"user\" + 0.030*\"2012\" + 0.029*\"lib\" + 0.028*\"gem\" + 0.026*\"ruby\"\n",
      "Thème 10: 0.037*\"div\" + 0.022*\"function\" + 0.021*\"class=\" + 0.020*\"text\" + 0.018*\"id=\"\n",
      "\n",
      "Run MLFlow ID : 6720c83c396f4ce6945a607a48fda422\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Définition de l'Expérience MLFlow\n",
    "EXPERIMENT_NAME = \"Approche_Non_Supervisee_LDA\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# --- Hyperparamètres ---\n",
    "NUM_TOPICS = 10 \n",
    "PASSES = 15 # Nombre d'itérations, impacte le temps de calcul\n",
    "\n",
    "print(f\"\\n--- Démarrage de l'entraînement LDA avec {NUM_TOPICS} thèmes ---\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"LDA_Topics_{NUM_TOPICS}_V1\") as run:\n",
    "    \n",
    "    # 1. Enregistrement des paramètres dans MLFlow\n",
    "    mlflow.log_param(\"num_topics\", NUM_TOPICS)\n",
    "    mlflow.log_param(\"pass_iterations\", PASSES)\n",
    "    mlflow.log_param(\"model\", \"LDA\")\n",
    "    mlflow.log_param(\"dataset\", \"df_train\")\n",
    "    \n",
    "    # 2. Entraînement du modèle\n",
    "    lda_model = LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=NUM_TOPICS,\n",
    "        random_state=42, \n",
    "        passes=PASSES \n",
    "    )\n",
    "\n",
    "    # 3. Évaluation (Coherence Score - Mesure de la qualité des thèmes)\n",
    "    coherence_model_lda = CoherenceModel(\n",
    "        model=lda_model, \n",
    "        texts=df_train['Tokens_LDA'].apply(str.split), # Utilisation des tokens pour la cohérence\n",
    "        dictionary=dictionary, \n",
    "        coherence='c_v'\n",
    "    )\n",
    "    coherence_score = coherence_model_lda.get_coherence()\n",
    "    mlflow.log_metric(\"coherence_score\", coherence_score) # La métrique est envoyée à MLFlow\n",
    "    \n",
    "    # 4. Affichage des 5 meilleurs mots-clés (suggestions de tags)\n",
    "    print(f\"\\nSuggestions de Tags (Mots-Clés par Thème, Coherence: {coherence_score:.4f}) :\")\n",
    "    for idx, topic in lda_model.print_topics(-1, num_words=5):\n",
    "        print(f\"Thème {idx+1}: {topic}\")\n",
    "\n",
    "    print(f\"\\nRun MLFlow ID : {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f135b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# On retire les chevrons et on split par le séparateur '><'\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [tag.strip() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags_str.strip(\u001b[33m'\u001b[39m\u001b[33m<>\u001b[39m\u001b[33m'\u001b[39m).split(\u001b[33m'\u001b[39m\u001b[33m><\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m tag.strip()]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m df_train[\u001b[33m'\u001b[39m\u001b[33mTags_List\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf_train\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mTags\u001b[39m\u001b[33m'\u001b[39m].apply(extract_tags)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 2. Filtrage des Tags Rares (Essentiel pour la classification Multi-label)\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# On ne peut pas classifier des milliers de tags qui apparaissent une seule fois.\u001b[39;00m\n\u001b[32m     13\u001b[39m all_tags = \u001b[38;5;28mlist\u001b[39m(itertools.chain.from_iterable(df_train[\u001b[33m'\u001b[39m\u001b[33mTags_List\u001b[39m\u001b[33m'\u001b[39m]))\n",
      "\u001b[31mNameError\u001b[39m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Extraction des Tags de la chaîne HTML (<tag1><tag2>...)\n",
    "def extract_tags(tags_str):\n",
    "    \"\"\"Extrait la liste de tags à partir de la chaîne HTML.\"\"\"\n",
    "    if not isinstance(tags_str, str):\n",
    "        return []\n",
    "    # On retire les chevrons et on split par le séparateur '><'\n",
    "    return [tag.strip() for tag in tags_str.strip('<>').split('><') if tag.strip()]\n",
    "\n",
    "df_train['Tags_List'] = df_train['Tags'].apply(extract_tags)\n",
    "\n",
    "# 2. Filtrage des Tags Rares (Essentiel pour la classification Multi-label)\n",
    "# On ne peut pas classifier des milliers de tags qui apparaissent une seule fois.\n",
    "all_tags = list(itertools.chain.from_iterable(df_train['Tags_List']))\n",
    "tags_counts = pd.Series(all_tags).value_counts()\n",
    "\n",
    "# Nous gardons uniquement les tags qui apparaissent au moins 50 fois\n",
    "TAG_MIN_COUNT = 50 \n",
    "frequent_tags = tags_counts[tags_counts >= TAG_MIN_COUNT].index.tolist()\n",
    "print(f\"\\nNombre total de tags: {len(tags_counts)}. Nombre de tags fréquents retenus: {len(frequent_tags)}.\")\n",
    "\n",
    "# 3. Filtrer les listes de Tags pour ne garder que les tags fréquents\n",
    "df_train['Tags_Filtered'] = df_train['Tags_List'].apply(\n",
    "    lambda tags: [tag for tag in tags if tag in frequent_tags]\n",
    ")\n",
    "\n",
    "# 4. Création du MultiLabelBinarizer (Matrice Y)\n",
    "mlb = MultiLabelBinarizer()\n",
    "# Y_labels est votre matrice d'étiquettes binaire (0 ou 1 pour chaque tag)\n",
    "Y_labels = mlb.fit_transform(df_train['Tags_Filtered']) \n",
    "label_names = mlb.classes_ # Nom des colonnes de Y\n",
    "\n",
    "print(f\"Forme de la matrice des étiquettes Y (Questions x Tags): {Y_labels.shape}\")\n",
    "#la matrice des cibles Y est prête"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99f0b6",
   "metadata": {},
   "source": [
    "# Modélisation Supervisée : approche Bag-of-Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54bd773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du jeu d'entraînement (X_train) : 37565 questions\n",
      "Taille du jeu de test (X_test) : 9392 questions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# X = Texte propre pour le BoW (chaîne de caractères)\n",
    "X = df_train['Tokens_LDA']\n",
    "# Y = Matrice des labels (MultiLabelBinarizer)\n",
    "# Y_labels a été créé à l'étape précédente\n",
    "# Nous devons nous assurer que les données sans tags fréquents sont exclues\n",
    "X = X[df_train['Tags_Filtered'].apply(lambda x: len(x) > 0)]\n",
    "Y = Y_labels[df_train['Tags_Filtered'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# Séparation des données : 80% Entraînement, 20% Test\n",
    "# La variable 'stratify' n'est pas utilisée pour la multi-label classification par défaut de sklearn\n",
    "# Nous gardons un random_state pour la reproductibilité\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Taille du jeu d'entraînement (X_train) : {X_train.shape[0]} questions\")\n",
    "print(f\"Taille du jeu de test (X_test) : {X_test.shape[0]} questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae85d593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de la matrice TF-IDF d'entraînement (Questions x Features) : (37565, 20000)\n",
      "Forme de la matrice TF-IDF de test : (9392, 20000)\n"
     ]
    }
   ],
   "source": [
    "# Nous allons transformer le texte de $X$ en une matrice de nombres (la matrice TF-IDF).\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. Initialisation du TfidfVectorizer\n",
    "# max_features = 20000 : On limite le vocabulaire à 20 000 mots les plus fréquents pour réduire la dimension et le bruit\n",
    "vectorizer = TfidfVectorizer(max_features=20000)\n",
    "\n",
    "# 2. Entraînement du Vectorizer sur les données d'ENTRAÎNEMENT SEULEMENT\n",
    "X_train_features = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# 3. Transformation des données de TEST\n",
    "# Le Vectorizer entraîné est appliqué aux données de test\n",
    "X_test_features = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Forme de la matrice TF-IDF d'entraînement (Questions x Features) : {X_train_features.shape}\")\n",
    "print(f\"Forme de la matrice TF-IDF de test : {X_test_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943bd9a",
   "metadata": {},
   "source": [
    "Entraînement du Classifieur et Tracking MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17adfdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'expérience MLFlow active est maintenant : Approche_Supervisee_Features (existante)\n"
     ]
    }
   ],
   "source": [
    "from mlflow.exceptions import MlflowException\n",
    "\n",
    "EXPERIMENT_NAME = \"Approche_Supervisee_Features\"\n",
    "\n",
    "try:\n",
    "    # 1. Tente de définir l'expérience comme active. \n",
    "    # Si elle existe, cela fonctionne. Si elle n'existe pas, cela lève une MlflowException.\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    print(f\"L'expérience MLFlow active est maintenant : {EXPERIMENT_NAME} (existante)\")\n",
    "\n",
    "except MlflowException:\n",
    "    # 2. Si set_experiment échoue (car l'expérience n'existe pas), on la crée.\n",
    "    mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "    \n",
    "    # On la définit ensuite comme active.\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    print(f\"Nouvelle expérience créée et activée : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb48b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Démarrage de l'entraînement LogisticRegression avec TF-IDF (BoW) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 12:15:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score Micro (Baseline) : 0.1066\n",
      "Hamming Loss : 0.0049\n",
      "\n",
      "Run MLFlow ID : ae413ad970014c1c9d539249872d5b19\n",
      "Taux de Couverture (Top 5) : 0.5055\n"
     ]
    }
   ],
   "source": [
    "# --- Hyperparamètres ---\n",
    "MODEL_NAME = \"LogisticRegression\"\n",
    "C_PARAM = 0.1 # Paramètre de régularisation pour LogReg\n",
    "FEATURE_TYPE = \"TF-IDF (BoW)\"\n",
    "K_SUGGEST = 5\n",
    "\n",
    "print(f\"\\n--- Démarrage de l'entraînement {MODEL_NAME} avec {FEATURE_TYPE} ---\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"{FEATURE_TYPE}_{MODEL_NAME}_C{C_PARAM}\") as run:\n",
    "    \n",
    "    # 1. Enregistrement des paramètres\n",
    "    params = {\n",
    "        \"model\": MODEL_NAME, \n",
    "        \"feature_type\": FEATURE_TYPE,\n",
    "        \"C_param\": C_PARAM,\n",
    "        \"max_features_tfidf\": 20000,\n",
    "        \"top_k_suggested\": K_SUGGEST\n",
    "    }\n",
    "    mlflow.log_params(params) # On passe le dictionnaire complet\n",
    "    # 2. Définition et Entraînement du modèle\n",
    "    classifier = OneVsRestClassifier(LogisticRegression(C=C_PARAM, solver='liblinear', random_state=42))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    classifier.fit(X_train_features, Y_train)\n",
    "    fit_time = time.time() - start_time\n",
    "    \n",
    "    # 3. Prédiction sur le jeu de test\n",
    "    Y_pred = classifier.predict(X_test_features)\n",
    "    #Probas pour le TCTP\n",
    "    Y_proba = classifier.predict_proba(X_test_features)\n",
    "\n",
    "    # 3ter. Calcul du TCTP spécifique à TF-IDF\n",
    "    tctp_score = coverage_rate_top_k(Y_test, Y_proba, mlb, k=K_SUGGEST) \n",
    "    \n",
    "    # 4. Calcul et enregistrement des métriques\n",
    "    # F1-score est souvent la métrique clé en classification multi-label\n",
    "    f1_micro = f1_score(Y_test, Y_pred, average='micro')\n",
    "    precision_micro = precision_score(Y_test, Y_pred, average='micro')\n",
    "    recall_micro = recall_score(Y_test, Y_pred, average='micro')\n",
    "    \n",
    "    # La Hamming Loss est une bonne mesure : c'est le pourcentage de labels mal prédits\n",
    "    h_loss = hamming_loss(Y_test, Y_pred)\n",
    "    mlflow.sklearn.log_model(sk_model=classifier, name=\"TF-IDF\")\n",
    "\n",
    "    mlflow.log_metric(\"f1_micro\", f1_micro)\n",
    "    mlflow.log_metric(\"precision_micro\", precision_micro)\n",
    "    mlflow.log_metric(\"recall_micro\", recall_micro)\n",
    "    mlflow.log_metric(\"hamming_loss\", h_loss)\n",
    "    mlflow.log_metric(f\"tctp_top_{K_SUGGEST}\", tctp_score)\n",
    "    mlflow.log_metric(\"fit_time_sec\", fit_time)\n",
    "\n",
    "    print(f\"F1-Score Micro (Baseline) : {f1_micro:.4f}\")\n",
    "    print(f\"Hamming Loss : {h_loss:.4f}\")\n",
    "    print(f\"\\nRun MLFlow ID : {run.info.run_id}\")\n",
    "    print(f\"Taux de Couverture (Top {K_SUGGEST}) : {tctp_score:.4f}\")\n",
    "    \n",
    "    # On peut maintenant comparer ce score avec l'approche non supervisée (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78be851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemin de travail actuel du Notebook : \n",
      "c:\\Users\\lza\\Documents\\P05_Projet_tags_StackOverflow\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Affiche le chemin complet du dossier où votre Notebook est exécuté\n",
    "notebook_path = os.getcwd() \n",
    "print(f\"Chemin de travail actuel du Notebook : \\n{notebook_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbce336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modèle Word2Vec entraîné. Taille des vecteurs : 100\n"
     ]
    }
   ],
   "source": [
    "# 1. Préparation des données pour Word2Vec\n",
    "# Word2Vec nécessite une liste de listes de mots (tokens)\n",
    "# df_train['Tokens_LDA'] est actuellement une chaîne, nous devons la séparer en listes de tokens.\n",
    "X_train_tokens = X_train.apply(str.split).tolist()\n",
    "X_test_tokens = X_test.apply(str.split).tolist()\n",
    "\n",
    "# 2. Entraînement du Modèle Word2Vec\n",
    "# Paramètres : \n",
    "# vector_size (dimension de l'embedding), window (taille du contexte), min_count (fréquence minimale)\n",
    "VECTOR_SIZE = 100 \n",
    "WINDOW = 5\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=X_train_tokens, # Entraîné uniquement sur le jeu d'entraînement\n",
    "    vector_size=VECTOR_SIZE, \n",
    "    window=WINDOW, \n",
    "    min_count=5, # Ignore les mots qui apparaissent moins de 5 fois\n",
    "    sg=0, # 0=CBOW (plus rapide), 1=Skip-Gram\n",
    "    workers=4, # Utilise 4 cœurs\n",
    "   )\n",
    "w2v_model.train(X_train_tokens, total_examples=len(X_train_tokens), epochs=10)\n",
    "\n",
    "print(f\"\\nModèle Word2Vec entraîné. Taille des vecteurs : {VECTOR_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd6670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de la matrice Word2Vec d'entraînement : (37565, 100)\n"
     ]
    }
   ],
   "source": [
    "def document_vector_fct(word2vec_model, doc_tokens):\n",
    "    \"\"\"Calcule le vecteur d'un document en faisant la moyenne des vecteurs de ses mots.\"\"\"\n",
    "    \n",
    "    # On filtre les mots pour ne garder que ceux qui sont dans le vocabulaire de Word2Vec\n",
    "    words = [word for word in doc_tokens if word in word2vec_model.wv]\n",
    "    \n",
    "    if not words:\n",
    "        # Si la question est vide après filtrage, on retourne un vecteur de zéros\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    \n",
    "    # Retourne la moyenne des vecteurs des mots valides\n",
    "    return np.mean(word2vec_model.wv[words], axis=0)\n",
    "\n",
    "# 1. Création des Features d'Entraînement (X_train)\n",
    "X_train_w2v = np.array([document_vector_fct(w2v_model, tokens) for tokens in X_train_tokens])\n",
    "\n",
    "# 2. Création des Features de Test (X_test)\n",
    "X_test_w2v = np.array([document_vector_fct(w2v_model, tokens) for tokens in X_test_tokens])\n",
    "\n",
    "print(f\"Forme de la matrice Word2Vec d'entraînement : {X_train_w2v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1af846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Démarrage de l'entraînement LogisticRegression avec Word2Vec_Mean (C=0.1) ---\n",
      "F1-Score Micro (Word2Vec) : 0.3082\n",
      "Taux de Couverture (Top 5) : 0.6542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e276d7fc624c13b25b8802e9faceae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run MLFlow ID : b1343e403d7c4678bf1b0aebc06f7c85\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration MLFlow (à garder au début du run) ---\n",
    "EXPERIMENT_NAME = \"Approche_Supervisee_Features\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# --- Hyperparamètres ---\n",
    "MODEL_NAME = \"LogisticRegression\"\n",
    "C_PARAM = 0.1\n",
    "FEATURE_TYPE = \"Word2Vec_Mean\"\n",
    "K_SUGGEST = 5 # Le nombre de tags à suggérer (pour la métrique TCTP)\n",
    "\n",
    "print(f\"\\n--- Démarrage de l'entraînement {MODEL_NAME} avec {FEATURE_TYPE} (C={C_PARAM}) ---\")\n",
    "\n",
    "# Nom du run pour indiquer que le TCTP est bien calculé\n",
    "RUN_NAME = f\"{FEATURE_TYPE}_{MODEL_NAME}_V{VECTOR_SIZE}_TCTP_Fix\" \n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    \n",
    "    # 1. Enregistrement des paramètres\n",
    "    params = {\n",
    "        \"model\": MODEL_NAME, \n",
    "        \"feature_type\": FEATURE_TYPE,\n",
    "        \"w2v_vector_size\": VECTOR_SIZE,\n",
    "        \"w2v_window\": WINDOW,\n",
    "        \"C_param\": C_PARAM,\n",
    "        \"top_k_suggested\": K_SUGGEST \n",
    "    }\n",
    "    mlflow.log_params(params) \n",
    "\n",
    "    # 2. Définition et Entraînement\n",
    "    classifier = OneVsRestClassifier(LogisticRegression(C=C_PARAM, solver='liblinear', random_state=42))\n",
    "    start_time = time.time()\n",
    "    classifier.fit(X_train_w2v, Y_train)\n",
    "    fit_time = time.time() - start_time\n",
    "    \n",
    "    # 3. Prédiction et Métriques\n",
    "    \n",
    "    # a) Prédiction des probabilités (AJOUTÉ ET ESSENTIEL POUR TCTP)\n",
    "    Y_pred_probas = classifier.predict_proba(X_test_w2v) \n",
    "    \n",
    "    # b) Prédiction binaire pour F1\n",
    "    Y_pred_w2v = classifier.predict(X_test_w2v)\n",
    "    f1_micro = f1_score(Y_test, Y_pred_w2v, average='micro')\n",
    "    \n",
    "    # c) Calcul de la métrique métier (TCTP)\n",
    "    tctp_score = coverage_rate_top_k(Y_test, Y_pred_probas, mlb, k=K_SUGGEST) \n",
    "\n",
    "    # 4. Enregistrement des métriques\n",
    "    mlflow.log_metric(\"f1_micro\", f1_micro)\n",
    "    mlflow.log_metric(\"fit_time_sec\", fit_time)\n",
    "    mlflow.log_metric(f\"tctp_top_{K_SUGGEST}\", tctp_score)\n",
    "    \n",
    "    print(f\"F1-Score Micro (Word2Vec) : {f1_micro:.4f}\")\n",
    "    print(f\"Taux de Couverture (Top {K_SUGGEST}) : {tctp_score:.4f}\")\n",
    "    \n",
    "    # 5. Sauvegarde du modèle dans MLFlow (avec bonne pratique MLOps)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=classifier, \n",
    "        name=\"w2v_classifier\",\n",
    "        input_example=X_test_w2v[:1] \n",
    "    )\n",
    "\n",
    "    print(f\"\\nRun MLFlow ID : {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891530e5",
   "metadata": {},
   "source": [
    "# Approches Deap Learning BERT et USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f4a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chargement des embeddings BERT sauvegardés...\n",
      " Embeddings BERT chargés avec succès!\n",
      "   - Forme des features BERT (train) : (37565, 768)\n",
      "   - Forme des features BERT (test) : (9392, 768)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Choix du modèle (Bert de base, non entraîné sur Twitter)\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "MAX_LENGTH = 128 # Longueur maximale des séquences à traiter\n",
    "BATCH_SIZE = 64 # Taille du lot pour accélérer le traitement (ajuster selon votre GPU/RAM)\n",
    "\n",
    "# Dossier pour sauvegarder les embeddings BERT\n",
    "BERT_EMBEDDINGS_DIR = './data/bert_embeddings'\n",
    "os.makedirs(BERT_EMBEDDINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Chemins des fichiers de sauvegarde\n",
    "BERT_TRAIN_PATH = os.path.join(BERT_EMBEDDINGS_DIR, 'X_train_bert.npy')\n",
    "BERT_TEST_PATH = os.path.join(BERT_EMBEDDINGS_DIR, 'X_test_bert.npy')\n",
    "\n",
    "# Vérifier si les embeddings BERT existent déjà\n",
    "if os.path.exists(BERT_TRAIN_PATH) and os.path.exists(BERT_TEST_PATH):\n",
    "    print(\" Chargement des embeddings BERT sauvegardés...\")\n",
    "    X_train_bert = np.load(BERT_TRAIN_PATH)\n",
    "    X_test_bert = np.load(BERT_TEST_PATH)\n",
    "    print(f\" Embeddings BERT chargés avec succès!\")\n",
    "    print(f\"   - Forme des features BERT (train) : {X_train_bert.shape}\")\n",
    "    print(f\"   - Forme des features BERT (test) : {X_test_bert.shape}\")\n",
    "else:\n",
    "    print(\" Les embeddings BERT n'existent pas encore. Génération en cours...\")\n",
    "    print(\"   (Cette opération peut prendre plus de 2 heures la première fois)\")\n",
    "    \n",
    "    # Charger le Tokenizer et le Modèle\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model_bert = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    def get_bert_embeddings(texts):\n",
    "        \"\"\"Génère les embeddings BERT par batch.\"\"\"\n",
    "        embeddings = []\n",
    "        \n",
    "        text_data = texts  \n",
    "        for i in range(0, len(text_data), BATCH_SIZE):\n",
    "            batch = text_data[i:i + BATCH_SIZE]\n",
    "            \n",
    "            # Affichage de la progression\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"   Progression : {i}/{len(text_data)} textes traités...\")\n",
    "            \n",
    "            # 1. Tokenisation (avec paddings et attention mask)\n",
    "            encoded_input = tokenizer(\n",
    "                batch, \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                max_length=MAX_LENGTH, \n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            # 2. Passage dans le modèle\n",
    "            with torch.no_grad():\n",
    "                model_output = model_bert(**encoded_input)\n",
    "                \n",
    "            # 3. Extraction du vecteur [CLS] (représentation de la phrase entière)\n",
    "            # C'est la première position du last_hidden_state\n",
    "            batch_embeddings = model_output.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            embeddings.append(batch_embeddings)\n",
    "            \n",
    "        return np.vstack(embeddings)\n",
    "\n",
    "    print(f\"\\n Extraction des features BERT en cours (Modèle : {MODEL_NAME}, Taille : {MAX_LENGTH})...\")\n",
    "\n",
    "    #Récupération des données BERT en utilisant les indices du split existant.\n",
    "    # Les variables X_train et X_test conservent les indices originaux de df_train.\n",
    "    # Nous récupérons le texte BERT correspondant à ces indices.\n",
    "    X_train_dl_tokens = df_train.loc[X_train.index, 'Tokens_DL']\n",
    "    X_test_dl_tokens = df_train.loc[X_test.index, 'Tokens_DL']\n",
    "\n",
    "    # On s'assure que c'est bien une liste de chaînes de caractères (format attendu par le tokenizer)\n",
    "    X_train_dl_list = X_train_dl_tokens.tolist()\n",
    "    X_test_dl_list = X_test_dl_tokens.tolist()\n",
    "\n",
    "    # Création des Features BERT\n",
    "    start_time = time.time()\n",
    "    print(\"\\n Génération des embeddings pour le jeu d'ENTRAÎNEMENT...\")\n",
    "    X_train_bert = get_bert_embeddings(X_train_dl_list)\n",
    "    \n",
    "    print(\"\\n Génération des embeddings pour le jeu de TEST...\")\n",
    "    X_test_bert = get_bert_embeddings(X_test_dl_list)\n",
    "    \n",
    "    bert_embed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"\\n Extraction BERT terminée en {bert_embed_time:.2f} secondes ({bert_embed_time/60:.2f} minutes).\")\n",
    "    print(f\"   - Forme des features BERT (train) : {X_train_bert.shape}\")\n",
    "    print(f\"   - Forme des features BERT (test) : {X_test_bert.shape}\")\n",
    "    \n",
    "    # Sauvegarder les embeddings pour les prochaines exécutions\n",
    "    print(f\"\\n Sauvegarde des embeddings BERT dans '{BERT_EMBEDDINGS_DIR}'...\")\n",
    "    np.save(BERT_TRAIN_PATH, X_train_bert)\n",
    "    np.save(BERT_TEST_PATH, X_test_bert)\n",
    "    print(f\" Embeddings sauvegardés avec succès!\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89199a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Démarrage de l'entraînement LogisticRegression avec BERT (C=0.1) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/04 18:08:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Entraînement BERT terminé.\n",
      "F1-Score Micro (BERT) : 0.2607\n",
      "Taux de Couverture (Top 5) : 0.5804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/04 18:08:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run MLFlow ID : e8145289c8bc4d14873c9688e011c051\n"
     ]
    }
   ],
   "source": [
    "# DÉFINIR LA FONCTION EN PREMIER\n",
    "\n",
    "\n",
    "def coverage_rate_top_k(Y_true, Y_probas, mlb, k=5):\n",
    "    \"\"\"\n",
    "    Calcule le taux de couverture des tags : \n",
    "    (Nombre de vrais tags présents dans le top K des tags prédits) / (Nombre total de vrais tags)\n",
    "    \"\"\"\n",
    "    top_k_indices = np.argsort(Y_probas, axis=1)[:, -k:]\n",
    "    \n",
    "    total_coverage = 0\n",
    "    total_relevant_tags = 0\n",
    "    \n",
    "    for i in range(Y_true.shape[0]):\n",
    "        true_tags_indices = np.where(Y_true[i] == 1)[0]\n",
    "        predicted_top_k_indices = set(top_k_indices[i])\n",
    "        correctly_covered = len(set(true_tags_indices).intersection(predicted_top_k_indices))\n",
    "        num_true_tags = len(true_tags_indices)\n",
    "        \n",
    "        if num_true_tags > 0:\n",
    "            total_coverage += correctly_covered / num_true_tags\n",
    "            total_relevant_tags += 1\n",
    "            \n",
    "    if total_relevant_tags == 0:\n",
    "        return 0.0\n",
    "    return total_coverage / total_relevant_tags\n",
    "\n",
    "=\n",
    "# TRAINING MLFLOW \n",
    "\n",
    "EXPERIMENT_NAME = \"Approche_Supervisee_Features\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "MODEL_NAME = \"LogisticRegression\"\n",
    "C_PARAM = 0.1\n",
    "FEATURE_TYPE = \"BERT\"\n",
    "K_SUGGEST = 5\n",
    "\n",
    "print(f\"\\n--- Démarrage de l'entraînement {MODEL_NAME} avec {FEATURE_TYPE} (C={C_PARAM}) ---\")\n",
    "\n",
    "try:\n",
    "    _ = bert_embed_time \n",
    "except NameError:\n",
    "    bert_embed_time = 0 \n",
    "\n",
    "with mlflow.start_run(run_name=f\"{FEATURE_TYPE}_{MODEL_NAME}_C{C_PARAM}\") as run:\n",
    "    \n",
    "    mlflow.log_params({\n",
    "        \"feature_type\": FEATURE_TYPE,\n",
    "        \"C_param\": C_PARAM,\n",
    "        \"top_k_suggested\": K_SUGGEST\n",
    "    })\n",
    "    \n",
    "    if bert_embed_time > 0:\n",
    "        mlflow.log_metric(\"embedding_time_sec\", bert_embed_time) \n",
    "\n",
    "    classifier_bert = OneVsRestClassifier(LogisticRegression(\n",
    "        C=C_PARAM, \n",
    "        solver='saga', \n",
    "        random_state=42,\n",
    "        ),\n",
    "        n_jobs=-1 \n",
    "    )\n",
    "    \n",
    "    start_time_fit = time.time()\n",
    "    classifier_bert.fit(X_train_bert, Y_train) \n",
    "    fit_time = time.time() - start_time_fit\n",
    "    \n",
    "    Y_pred_bert = classifier_bert.predict(X_test_bert)\n",
    "    f1_micro = f1_score(Y_test, Y_pred_bert, average='micro')\n",
    "\n",
    "    Y_probas_bert = classifier_bert.predict_proba(X_test_bert)\n",
    "    tctp_score = coverage_rate_top_k(Y_test, Y_probas_bert, mlb, k=K_SUGGEST)\n",
    "    \n",
    "    mlflow.log_metric(\"f1_micro\", f1_micro)\n",
    "    mlflow.log_metric(f\"tctp_top_{K_SUGGEST}\", tctp_score) \n",
    "    mlflow.log_metric(\"fit_time_sec\", fit_time)\n",
    "    \n",
    "    print(f\"\\n Entraînement BERT terminé.\")\n",
    "    print(f\"F1-Score Micro (BERT) : {f1_micro:.4f}\")\n",
    "    print(f\"Taux de Couverture (Top {K_SUGGEST}) : {tctp_score:.4f}\")\n",
    "    \n",
    "    mlflow.sklearn.log_model(sk_model=classifier_bert, name=\"bert_classifier\")\n",
    "    \n",
    "    print(f\"\\nRun MLFlow ID : {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b4d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chargement des embeddings USE sauvegardés...\n",
      " Embeddings USE chargés : (37565, 512)\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "USE_MODEL_URL = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "USE_BATCH_SIZE = 100  # Traitement par batch de 100 textes\n",
    "\n",
    "# Dossier pour sauvegarder les embeddings USE\n",
    "USE_EMBEDDINGS_DIR = './data/use_embeddings'\n",
    "os.makedirs(USE_EMBEDDINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Chemins des fichiers de sauvegarde\n",
    "USE_TRAIN_PATH = os.path.join(USE_EMBEDDINGS_DIR, 'X_train_use.npy')\n",
    "USE_TEST_PATH = os.path.join(USE_EMBEDDINGS_DIR, 'X_test_use.npy')\n",
    "\n",
    "# Vérifier si les embeddings USE existent déjà\n",
    "if os.path.exists(USE_TRAIN_PATH) and os.path.exists(USE_TEST_PATH):\n",
    "    print(\" Chargement des embeddings USE sauvegardés...\")\n",
    "    X_train_use = np.load(USE_TRAIN_PATH)\n",
    "    X_test_use = np.load(USE_TEST_PATH)\n",
    "    use_embed_time = 0\n",
    "    print(f\" Embeddings USE chargés : {X_train_use.shape}\")\n",
    "else:\n",
    "    print(\" Génération des embeddings USE (traitement par batch)...\")\n",
    "    \n",
    "    # Chargement du modèle USE\n",
    "    use_model = hub.load(USE_MODEL_URL)\n",
    "    print(\" Modèle USE chargé!\")\n",
    "    \n",
    "    def get_use_embeddings_batch(texts, model, batch_size=100):\n",
    "        \"\"\"Génère les embeddings USE par batch.\"\"\"\n",
    "        embeddings = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"   Progression : {i}/{len(texts)} textes...\")\n",
    "            batch_embeddings = model(batch).numpy()\n",
    "            embeddings.append(batch_embeddings)\n",
    "        return np.vstack(embeddings)\n",
    "    \n",
    "    # Récupération des données\n",
    "    X_train_dl_tokens = df_train.loc[X_train.index, 'Tokens_DL']\n",
    "    X_test_dl_tokens = df_train.loc[X_test.index, 'Tokens_DL']\n",
    "    X_train_dl_list = X_train_dl_tokens.tolist()\n",
    "    X_test_dl_list = X_test_dl_tokens.tolist()\n",
    "    \n",
    "    # Génération des embeddings\n",
    "    start_time = time.time()\n",
    "    print(\"\\n Train...\")\n",
    "    X_train_use = get_use_embeddings_batch(X_train_dl_list, use_model, USE_BATCH_SIZE)\n",
    "    print(\"\\n Test...\")\n",
    "    X_test_use = get_use_embeddings_batch(X_test_dl_list, use_model, USE_BATCH_SIZE)\n",
    "    use_embed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n Terminé en {use_embed_time/60:.2f} minutes\")\n",
    "    print(f\"   Train: {X_train_use.shape}, Test: {X_test_use.shape}\")\n",
    "    \n",
    "    # Sauvegarde\n",
    "    print(f\"\\n Sauvegarde...\")\n",
    "    np.save(USE_TRAIN_PATH, X_train_use)\n",
    "    np.save(USE_TEST_PATH, X_test_use)\n",
    "    print(f\" Embeddings sauvegardés!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc1928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Démarrage de l'entraînement LogisticRegression avec USE (C=0.1) ---\n",
      "F1-Score Micro (USE) : 0.2590\n",
      "Taux de Couverture (Top 5) : 0.6293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f51a5f85b14e9e948333f0f65aa9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run MLFlow ID : ea06f6d5fbc94716876a1a57b7cf4d10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Configuration MLFlow ---\n",
    "EXPERIMENT_NAME = \"Approche_Supervisee_Features\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# --- Hyperparamètres ---\n",
    "MODEL_NAME = \"LogisticRegression\"\n",
    "C_PARAM = 0.1\n",
    "FEATURE_TYPE = \"USE\"\n",
    "K_SUGGEST = 5 # Nombre de tags suggérés pour la métrique métier\n",
    "\n",
    "print(f\"\\n--- Démarrage de l'entraînement {MODEL_NAME} avec {FEATURE_TYPE} (C={C_PARAM}) ---\")\n",
    "\n",
    "# On récupère le temps d'embedding s'il a été calculé (pour le tracking)\n",
    "try:\n",
    "    _ = use_embed_time \n",
    "except NameError:\n",
    "    use_embed_time = 0 \n",
    "\n",
    "RUN_NAME = f\"{FEATURE_TYPE}_{MODEL_NAME}_TCTP_Fix\" \n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    \n",
    "    # 1. Enregistrement des paramètres\n",
    "    params = {\n",
    "        \"feature_type\": FEATURE_TYPE,\n",
    "        \"C_param\": C_PARAM,\n",
    "        \"top_k_suggested\": K_SUGGEST\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    if use_embed_time > 0:\n",
    "        mlflow.log_metric(\"embedding_time_sec\", use_embed_time) \n",
    "\n",
    "    # 2. Définition et Entraînement\n",
    "    classifier = OneVsRestClassifier(LogisticRegression(C=C_PARAM, solver='liblinear', random_state=42))\n",
    "    start_time = time.time()\n",
    "    classifier.fit(X_train_use, Y_train)\n",
    "    fit_time = time.time() - start_time\n",
    "    \n",
    "    # 3. Prédiction et Métriques\n",
    "    \n",
    "    # a) Prédiction des probabilités (ESSENTIEL POUR TCTP)\n",
    "    Y_pred_probas = classifier.predict_proba(X_test_use)\n",
    "    \n",
    "    # b) Prédiction binaire pour F1\n",
    "    Y_pred_use = classifier.predict(X_test_use)\n",
    "    f1_micro = f1_score(Y_test, Y_pred_use, average='micro')\n",
    "    \n",
    "    # c) Calcul de la métrique métier (TCTP)\n",
    "    tctp_score = coverage_rate_top_k(Y_test, Y_pred_probas, mlb, k=K_SUGGEST)\n",
    "    \n",
    "    # 4. Enregistrement des métriques dans MLFlow\n",
    "    mlflow.log_metric(\"f1_micro\", f1_micro)\n",
    "    mlflow.log_metric(f\"tctp_top_{K_SUGGEST}\", tctp_score)\n",
    "    mlflow.log_metric(\"fit_time_sec\", fit_time)\n",
    "    \n",
    "    print(f\"F1-Score Micro (USE) : {f1_micro:.4f}\")\n",
    "    print(f\"Taux de Couverture (Top {K_SUGGEST}) : {tctp_score:.4f}\")\n",
    "    \n",
    "    # 5. Sauvegarde complète du modèle (avec bonne pratique MLOps)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=classifier, \n",
    "        name=\"use_classifier_tctp_fix\",\n",
    "        input_example=X_test_use[:1]\n",
    "    )\n",
    "\n",
    "    print(f\"\\nRun MLFlow ID : {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76ba188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Run: data=<RunData: metrics={'f1_micro': 0.26068759342301945,\n",
      " 'fit_time_sec': 2169.288969039917,\n",
      " 'tctp_top_5': 0.5803573963657009}, params={'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}, tags={'mlflow.runName': 'BERT_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/e8145289c8bc4d14873c9688e011c051/artifacts', end_time=1764868129991, experiment_id='282807502113289851', lifecycle_stage='active', run_id='e8145289c8bc4d14873c9688e011c051', run_name='BERT_LogisticRegression_C0.1', start_time=1764865920468, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[<LoggedModelOutput: model_id='m-26653bd7df1e448e874ed39516ac09a6', step=0>]>>, <Run: data=<RunData: metrics={}, params={'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}, tags={'mlflow.runName': 'BERT_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/d18c0b3561574de6a220592188cfd1e1/artifacts', end_time=1764865547179, experiment_id='282807502113289851', lifecycle_stage='active', run_id='d18c0b3561574de6a220592188cfd1e1', run_name='BERT_LogisticRegression_C0.1', start_time=1764863314553, status='FAILED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={}, params={'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}, tags={'mlflow.runName': 'BERT_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/150033c205474564b306fcf5e7115319/artifacts', end_time=1764863210795, experiment_id='282807502113289851', lifecycle_stage='active', run_id='150033c205474564b306fcf5e7115319', run_name='BERT_LogisticRegression_C0.1', start_time=1764862309406, status='FAILED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={}, params={'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}, tags={'mlflow.runName': 'BERT_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/42e69469671241ff8c0ddb5558dac790/artifacts', end_time=1764862174350, experiment_id='282807502113289851', lifecycle_stage='active', run_id='42e69469671241ff8c0ddb5558dac790', run_name='BERT_LogisticRegression_C0.1', start_time=1764860044383, status='FAILED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={'f1_micro': 0.10660520766929829,\n",
      " 'fit_time_sec': 78.44549679756165,\n",
      " 'hamming_loss': 0.004898591967373909,\n",
      " 'precision_micro': 0.8823051948051948,\n",
      " 'recall_micro': 0.05672981577161944}, params={'C_param': '0.1',\n",
      " 'feature_type': 'TF-IDF (BoW)',\n",
      " 'max_features_tfidf': '20000',\n",
      " 'model': 'LogisticRegression'}, tags={'mlflow.runName': 'TF-IDF (BoW)_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/7ecdccfb5cad4f0fbd0cf4869ce8ca84/artifacts', end_time=1764847747582, experiment_id='282807502113289851', lifecycle_stage='active', run_id='7ecdccfb5cad4f0fbd0cf4869ce8ca84', run_name='TF-IDF (BoW)_LogisticRegression_C0.1', start_time=1764847668047, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={}, params={}, tags={'mlflow.runName': 'TF-IDF (BoW)_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/375a085d2a964a6f91815f41f855186a/artifacts', end_time=1764847500741, experiment_id='282807502113289851', lifecycle_stage='active', run_id='375a085d2a964a6f91815f41f855186a', run_name='TF-IDF (BoW)_LogisticRegression_C0.1', start_time=1764847500665, status='FAILED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={}, params={'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}, tags={'mlflow.runName': 'BERT_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/d4358e642c79417091ffa42d81503873/artifacts', end_time=1764845535152, experiment_id='282807502113289851', lifecycle_stage='active', run_id='d4358e642c79417091ffa42d81503873', run_name='BERT_LogisticRegression_C0.1', start_time=1764845535087, status='FAILED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={}, params={'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}, tags={'mlflow.runName': 'BERT_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/519a78bf3d784161ac0eeef4945f2718/artifacts', end_time=1764845166869, experiment_id='282807502113289851', lifecycle_stage='active', run_id='519a78bf3d784161ac0eeef4945f2718', run_name='BERT_LogisticRegression_C0.1', start_time=1764845166789, status='FAILED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={'embedding_time_sec': 53.00649952888489,\n",
      " 'f1_micro': 0.25897379431843204,\n",
      " 'fit_time_sec': 726.1925277709961}, params={'C_param': '0.1', 'feature_type': 'USE'}, tags={'mlflow.runName': 'USE_LogisticRegression',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/96d312bd96a74882a1b58c821cd651e0/artifacts', end_time=1764329448525, experiment_id='282807502113289851', lifecycle_stage='active', run_id='96d312bd96a74882a1b58c821cd651e0', run_name='USE_LogisticRegression', start_time=1764328694068, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[<LoggedModelOutput: model_id='m-09421745df49416d82fb4a34777cde45', step=0>]>>, <Run: data=<RunData: metrics={'f1_micro': 0.30660586739841006, 'fit_time_sec': 264.4144322872162}, params={'C_param': '0.1',\n",
      " 'feature_type': 'Word2Vec_Mean',\n",
      " 'model': 'LogisticRegression',\n",
      " 'w2v_vector_size': '100',\n",
      " 'w2v_window': '5'}, tags={'mlflow.runName': 'Word2Vec_Mean_LogisticRegression_V100',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/adab6eead21748aabef90e9232bee797/artifacts', end_time=1764254265126, experiment_id='282807502113289851', lifecycle_stage='active', run_id='adab6eead21748aabef90e9232bee797', run_name='Word2Vec_Mean_LogisticRegression_V100', start_time=1764253978955, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[<LoggedModelOutput: model_id='m-9aeeed6183254fd7bcb97d712500e52b', step=0>]>>, <Run: data=<RunData: metrics={'f1_micro': 0.10660520766929829,\n",
      " 'fit_time_sec': 90.97752141952515,\n",
      " 'hamming_loss': 0.004898591967373909,\n",
      " 'precision_micro': 0.8823051948051948,\n",
      " 'recall_micro': 0.05672981577161944}, params={'C_param': '0.1',\n",
      " 'feature_type': 'TF-IDF (BoW)',\n",
      " 'max_features_tfidf': '20000',\n",
      " 'model': 'LogisticRegression'}, tags={'mlflow.runName': 'TF-IDF (BoW)_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/d3f6645f13ff4624bbf0eabfb34277b4/artifacts', end_time=1764253671948, experiment_id='282807502113289851', lifecycle_stage='active', run_id='d3f6645f13ff4624bbf0eabfb34277b4', run_name='TF-IDF (BoW)_LogisticRegression_C0.1', start_time=1764253579839, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={'f1_micro': 0.10660520766929829,\n",
      " 'fit_time_sec': 92.31606650352478,\n",
      " 'hamming_loss': 0.004898591967373909,\n",
      " 'precision_micro': 0.8823051948051948,\n",
      " 'recall_micro': 0.05672981577161944}, params={'C_param': '0.1',\n",
      " 'feature_type': 'TF-IDF (BoW)',\n",
      " 'max_features_tfidf': '20000',\n",
      " 'model': 'LogisticRegression'}, tags={'mlflow.runName': 'TF-IDF (BoW)_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/fdaea784ff5342a0859c11e4c0f1e0f8/artifacts', end_time=1764252815843, experiment_id='282807502113289851', lifecycle_stage='active', run_id='fdaea784ff5342a0859c11e4c0f1e0f8', run_name='TF-IDF (BoW)_LogisticRegression_C0.1', start_time=1764252722170, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={'f1_micro': 0.10660520766929829,\n",
      " 'fit_time_sec': 83.714923620224,\n",
      " 'hamming_loss': 0.004898591967373909,\n",
      " 'precision_micro': 0.8823051948051948,\n",
      " 'recall_micro': 0.05672981577161944}, params={'C_param': '0.1',\n",
      " 'feature_type': 'TF-IDF (BoW)',\n",
      " 'max_features_tfidf': '20000',\n",
      " 'model': 'LogisticRegression'}, tags={'mlflow.runName': 'TF-IDF (BoW)_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/c74c14c1130946f0a02a76cac9d33545/artifacts', end_time=1764251920489, experiment_id='282807502113289851', lifecycle_stage='active', run_id='c74c14c1130946f0a02a76cac9d33545', run_name='TF-IDF (BoW)_LogisticRegression_C0.1', start_time=1764251835667, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={}, params={'C_param': '0.1',\n",
      " 'feature_type': 'TF-IDF (BoW)',\n",
      " 'max_features_tfidf': '20000',\n",
      " 'model': 'LogisticRegression'}, tags={'mlflow.runName': 'TF-IDF (BoW)_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/289073ca90db45618ca1d9b6c9c30212/artifacts', end_time=1764251342625, experiment_id='282807502113289851', lifecycle_stage='active', run_id='289073ca90db45618ca1d9b6c9c30212', run_name='TF-IDF (BoW)_LogisticRegression_C0.1', start_time=1764251342529, status='FAILED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={'f1_micro': 0.10660520766929829,\n",
      " 'fit_time_sec': 73.08911418914795,\n",
      " 'hamming_loss': 0.004898591967373909,\n",
      " 'precision_micro': 0.8823051948051948,\n",
      " 'recall_micro': 0.05672981577161944}, params={'C_param': '0.1',\n",
      " 'feature_type': 'TF-IDF (BoW)',\n",
      " 'max_features_tfidf': '20000',\n",
      " 'model': 'LogisticRegression'}, tags={'mlflow.runName': 'TF-IDF (BoW)_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/f3a78a5c0a304b65999860d05c6cb219/artifacts', end_time=1764247767652, experiment_id='282807502113289851', lifecycle_stage='active', run_id='f3a78a5c0a304b65999860d05c6cb219', run_name='TF-IDF (BoW)_LogisticRegression_C0.1', start_time=1764247693529, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "K_SUGGEST = 5 \n",
    "EXPERIMENT_NAME = \"Approche_Supervisee_Features\"\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "if experiment:\n",
    "    # Récupérer tous les runs (sans filtre problématique)\n",
    "    runs_data = client.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        order_by=[f\"metrics.tctp_top_{K_SUGGEST} DESC\"]\n",
    "    )\n",
    "print(runs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b68d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tableau Récapitulatif des Performances :\n",
      "\n",
      "| Modèle   |   F1_Micro |   TCTP_Top5 |   Temps_Entrainement_sec |\n",
      "|:---------|-----------:|------------:|-------------------------:|\n",
      "| Word2Vec |   0.308207 |    0.654152 |                 236.91   |\n",
      "| BERT     |   0.260688 |    0.580357 |                2169.29   |\n",
      "| USE      |   0.258974 |    0.629332 |                 571.681  |\n",
      "| TF-IDF   |   0.106605 |    0.505522 |                  91.8235 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lza\\AppData\\Local\\Temp\\ipykernel_22864\\2252098073.py:54: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Modèle', y='F1_Micro', data=df_results, ax=ax[0], palette=\"Blues_d\")\n",
      "C:\\Users\\lza\\AppData\\Local\\Temp\\ipykernel_22864\\2252098073.py:60: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Modèle', y='Temps_Entrainement_sec', data=df_results, ax=ax[1], palette=\"Oranges_d\")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABW4AAAHvCAYAAADEl0ZwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAfwZJREFUeJzt3Qd4FOX2+PETCCG00LtA6E2aIL0pSBEVBLyASokUQVAE6QIBUekICILoRQFBEAuoIOWCiPQmUkQEL0jvTQKEtv/nvL//7N1NNpg+k+T7eZ4h2dnZ2Xcnk83h7Jnz+rlcLpcAAAAAAAAAABwjld0DAAAAAAAAAAB4I3ELAAAAAAAAAA5D4hYAAAAAAAAAHIbELQAAAAAAAAA4DIlbAAAAAAAAAHAYErcAAAAAAAAA4DAkbgEAAAAAAADAYUjcAgAAAAAAAIDDkLgFAAAAAAAAAIchcQsAAADEs+vXr0vlypXloYcekvPnz9s9HDjEpUuXJDg4WB5++GG5fPmy3cMBAAAOR+IWAAAgnn366afi5+dnviYX69atM69pxIgRdg/FUerXr2+OS0QZM2aU5cuXS0BAgLRr107u3buXos6X5EKTrLrEB5fLJe3btzfnwooVKyRr1qzxsl8AAJB8kbgFACAF27lzp3Tu3FmKFy8uGTJkkHTp0knRokVNcmH16tV2Dw+IRBPHmuTUpV+/flFuN3DgQPd2diWbc+fOLStXrpRff/1Vhg0bJknBvn37pGPHjiZZmTZtWsmcObMUK1ZMWrZsKVOmTDHJR8TOO++8I5s2bZIffvjBVGIDAAD8ExK3AACkQPfv35e+fftKlSpVZO7cuVKkSBHp3r279O7d21zevWzZMmnUqJGMGjXK7qEmSc8++6wcOHDAfEXC8Pf3l88++0zu3r0b6T5dp+e1bmM3/VBEk7eBgYFy7do1cTL9sEZ///W4lixZUl555RWzPPLII7Jx40Z5/fXXH1g5nBytWbPGLHF148YNk/TWpK22SQAAAIgO+6NZAACQ6IYOHSrvvfeeVKxYUb788ktTZevp5s2bMm3aNLl48aJtY0zKtEpRFyScpk2bynfffSfff/+9tGjRwus+bVFw5swZeeaZZ+Tbb78Vu2niUxen69Gjh0nM/uc//5HHHnvM6z5NOq5atUpSp04tKUnE98bYSp8+fZKpugYAAM5BxS0AACnM4cOHZdy4cZI9e3bTZ9FXYkJbJvTv319Gjhzptf7ChQum6q5w4cLmMupcuXLJv/71L3N5dUSdOnUyl6n/97//lQkTJkiJEiXMfsuUKSMLFy4029y+fVvefPNNc1m2ViSWL1/eVKRF1Uf01q1bMmjQIClYsKDZvnTp0vL+++9Hunz76tWrMnbsWKlXr57ky5fP9BnVrx06dJA///wzysvvtY+r9hnVJJsmWvR5Y7O/qHqW7tq1S1q3bm3Gr8cvZ86c8uijj5pLqCPSY6rHVo+xbqvHXI+9r2S61YdTJ8TSqmkdmz5Gj6cm5mNCk/Z6jAsUKGCOsVYHfvTRRw98zJEjR6RLly7u15U3b17z8//rr78ibRuTY/Ageul+lixZZPbs2ZHu03XaP/RBFc8xOb5qw4YN5uevLUX0d6dNmzZy/PjxKPev56SOo1atWhIUFGTOff15jB8/3meVsN3H9ty5c+Zc1p93xKSt0vO5cePGXv18H9SbN6qeyLpOf69OnDhhev/myJHD/K7pcdKEsS/6PjFp0iTze6nHP1OmTFKnTh2fSXnP952JEyea9xs9FrperyDQ+7Qa25evv/7a3K/vSQ/qcavvQ7rvChUqmA9odEy6jZ5P2hYjoqVLl0qDBg3MOWn9Tul7YsTqZb0S4uOPP5aqVatKtmzZzDmjLRWefvppczwBAEDKQ8UtAAApjCZZNGHw8ssvmx6cD6IJD8v58+elRo0aJrmjiZe2bduapJImBrW1gl4OXrt27Uj70JYMW7duNckHrdbTpO3zzz9vkhiadP3tt9+kWbNmJhmyYMECad68uWkz4CuhrImRX375RVq1amVuf/XVV/Laa6/J0aNHTSLFoo8fPny4SUBp8k4TK7///rvZv45VE1yFChWKtH9Nqv34449mDNoqwqoujO3+PO3evVtq1qxp9qn71+2vXLliXv+sWbO8kkWaJNQkmSasNBGnSaHNmzebHqNaYbplyxaT8PJ0584dM2adqV6Pj16arcdaj5km6PW+f6KJI61S1QRauXLlzM9JE5l9+vTxmcxT+rPVsYaFhclTTz1lWgPoz2P+/PkmCa/j1lYcMT0G/0QTYJr406Ty2bNn3eeyfq8/k27dupltfInp8dVL5bXCN1WqVCZhq4lxXafJRl8TTGnS9oUXXpDPP//ctB7QnrFp0qQxzztgwACThNNqYd3fgyTmsdUEpLaWOH36tHk+PccTip6jeuw0saxJaX1vWbRokTRp0sS8n3hWUIeHh5v1esz0CgHtya3nuv6M9XXqe0ivXr0iPcerr75qfo763qLvPZqg12R/aGioaQWhH7pENG/ePPNVe3w/iP48v/jiC5OIDwkJMe+TmsTX947t27ebhK5l8ODBMmbMGMmfP795fj3OP//8s/lgTH++ixcv9tpWP1TT9z793dME9cmTJ815o7+T1gdJAAAgBXEBAIAUpX79+lqe6vrPf/4To8eFhISYxw0ePNhr/bJly8z6YsWKue7du+de37FjR7O+RIkSrnPnzrnXb9261azPkiWLq3bt2q7r16+771u0aJG579VXX/V6jnr16pn1JUuWdF25csW9Xr/XdX5+fq7t27d7rb948WKk17B27VpXqlSpXF26dPFaHxoaavafIUMG1549eyI9Lqb7++STT8z+9Kulb9++Zt2SJUsi7efChQvu7/UYFi1a1Gy7YsUKr+369+9v1r/00kte6wsVKmTWN2/e3BUeHu5erz9jXd+4cWNXdFjjbtKkievu3bvu9XpMAgICzH16rCy3b992BQcHuzJlyuTatWuX175+/vlnV+rUqV1PPfVUjI/Bg1g/q88//9y1Y8cO8/24cePc9+v3um7nzp1mm4hjjunx1e2LFClizjF9TZb79++7nn/+ebN9xJB61qxZZt2UKVMijb9fv37u8T/ofLHj2LZs2dLso1y5cq6pU6ea4+t5PkXka9yWH3/8MdKxV9bx0mOnx9Dy66+/mnMsZ86crhs3brjXDxkyxGw/bNgwr+2vXbvmqlKlinnMyZMnI73vPPTQQ66//vor0rj0PUeP3alTp7zW6++37kv3GfF3SxfP9wI9FypXruz1O6L09uXLl923V61a5f7983yf09fRvXt3c9+XX37pXp8tWzZXvnz5XGFhYZHG7ev9BwAAJH+0SgAAIIXR3p8qJrOaa2WiVg/qJeLaH9fTk08+KU888YRpwaATGEWklX5aWWfRy4C1SlCrAfUSbs/KPq0U1cpEX5cbK+0R6dk7Vr/X8Wg+aM6cOV7r9VLjiLRqtGzZslFekq1VmlppGlFs9+eLXv4ckR5Xix5DrWrWCk+ttvSkVb86Dq301Z9JRNq3WNs4WPTybK281CrA6LAuIdefi2cvUz0mvqoQtTpVK0C1erBSpUpe92n1tVZEar/ZiJNy/dMxiC6tZtWqx08++cS9Tr/XiseoesrG9PhqtaNedq8Vr54V5XpJ/bvvvuuz56v2h9bjrlWT2l7Ec9EKTevYPYgdx1Yrc7U6de/evaaSXScv1KpPrY6dOnWqaaMRH/SY6bHzbLugP0c9x7T6Vl+XVQE+Y8YMU4GqbVs8t9dx6c9Lf07a4iAiPW7aMiIifQ694kDfzzxpxa/u68UXX3zg2HUM+n6j1dwRK6b1dWn7Ds/zwDqunu9zug+twtWvEcehv7++zilf7z8AACD5o1UCAAD4R9oWQFsZaKJS+1FGpOt1Rnq9XFt7T3rSy5sj0j6dmgyLeJ8mLPSS5lOnTvkcR8R9e67TFgqe9NLqyZMnm8uRNWHm2VfUM7npSZPKUYnN/jxpywJ9vLZa0MvtNdldt25dcwm1J+t1+LosOmPGjCaZppNEHTx40CvJrAkj7dMakSbo9ZL66NCEuSaYfCU99Tj/+9//9lqnl6IrHUvEXqbWhwSafPvjjz/MuKN7DGLipZdeMr1prdeobS205UFUYnp8rQ8RfJ17mpzVXsCaYLVoiwpNfGpyz/MDi4i0JcGD2HFsNcGrfWMPHTpk2mts27bNjGPTpk1m0bYUP/30U5yTiJpQ9dVaxDrHrHYo+tq1rYK2pojYb1tpktd6f4ru77IeJ01Ka1sEbeNi0fYJ2ipC2288iPYr1g+rNLmsvyfPPfecOZe0l7B+6ORJj53+Pvnqw2wl2T3Hru1nPvjgA9MDV7/X91VtT+MrGQ8AAFIGErcAAKQwefLkMckC7Z1YsmTJaD3GquqLqieuJmI9t4uY6IhIEyQPuk97WPri6/mtdTqBmEX7RmryShNxWlWpPUw14WxNpORrYqcHvb7Y7s9TtWrVTPJXKw21otOqEtWEj058ZvWQje2x9qxEjng8NcEXHXoMNRHpi6/xXLp0yXzVnqsPoj1TY3IMYkIrJLVvrJUc0yS69peNSkyPr3Ve6QcKvuh+PBO3mmjUpK1WYmsiNSq+euM65dhqL11dLPqBjB5nndBNE6gPSoxHR1THPuLvsnUM9u/fb5Z/OgbReQ79gEOrp7U/tvb/1cnLtAJbE9OakI3q5xzx/cA6zlbvYH0v02pqXW99uKXj1w94fCWdfY1dj6t++KI/u7ffftssWtmryWbt4R2xrzUAAEj+SNwCAJDC6GXPmuDRyZUef/zxaD3GSrDqxE8Par/gKxEbn/T5I17+bI3JM3GpFYqa8Ni5c6dXAkrphF1R8bwU21Ns9+erolAnldJLzrVyVyeo0go7nUBJk2LaQsLOY63H0KpijMjXeKwx6OvQZFh8HYOY0CpRbRugl7orndjqQa0BYnp8rfPq3LlzPrePuB/rcZr4bdiwYYxei9OOrUUr43USMH2/WLt2rXu91SrAs/rc4vlBSkRRHfuIv8vWMdDqW520LCai+l222iVo4larbkePHm2qba310aGJWSuxqhM06qRkM2fONIlXPfYffvihe/w6Dq3Qjw79kKVfv35m0asOtLpZk7jawkTPS50AEgAApCz0uAUAIIXp1KmTaUmgfRejStJ5zuiuSpUqZRKX2itVLwWPSBPBUbVFiE86G3tU6zz7gGoFXenSpSMlWfXydG3REFPxvT+99Fkvr9YquiFDhphkj7aa8Hwd1jGNWJ23Y8cO8/joVkvHhPaG1efYtWtXtI69Vnmq6LZiiO4xiE27hL///tss+v2DxPT46jGJ6vVrpfXx48e91mnvVT1XTpw4Eal9R0w45dhatNo8qqphrd6P6EGv/dixYz6r1CP+Lutx1OSn/kyiqsKPDa2s1eS+VsxqNbpWNevPTT8AiCmtkNVzTpOseoy01YTnz/DixYum9URMaXsIbdugLSuKFStm+mjHV49hAACQdJC4BQAghdEkgF5arlVgOkGTVoxFpP1sJ02a5O6tqZefaxJBH6MVap40saCVYLpfreZNSKNGjfKq5NPvtepNq9o6duzoXq/9M3WyNM/KPn1NPXr0iFUCKD72pwk4fUxE1j41Ma70GOpkTFo5GXHSM32tmgjSn0V0+urGlFVxqJd/6wROFu3ZqtWJEWmiSyug9VxZv359pPv12OjkXjE9BjHVqFEjWbJkiVm0t+uDxPT46kRgmpzTycI8X4u2Q9CkqOdxsmgPVb2/e/fuZhK+iDQxHtUEfHYdW01a66R0vqpDtaJ2/Pjx5nvPCdp0cjj93dOqc8/n1kTlg9op6DHTY6fHyLJnzx5zjmlfYE2sWhWo+jumSV6tQvX1u6aVxFFVQ0dFe9Fq6xNNII8bN86MV6t6o9NLVj/s0ueMSFtk6AddnsdZzwOliV09ryLSKlrtyaz0sdquwdfP5fr162bMESdDAwAAyR+tEgAASIE0QaWJlvfee89UFuol0DohjiYHNJGrCS1NNOh2Fu2TqVVluk4TDFpNpr09td+jXjqsl/QmdGKhRIkSZpyaZFF6ubNWNuokQzpBk+XVV181i1butW7d2iSetOJQE0VaQflPSbOI4mN/evz0kmqdMEoTgZrg0QSetqzQS9h1Uimlx1D75movXU1g6eRHmjjWxJxWiWrSUWekTwia/NYqRE3G62vVxL726dSZ7zU5qslLT2nTpjWXsOt29erVM+eRTuilyTxNtmkFpVY2WhMwRfcYxJQes+hWS8b0+Or2Wp2u22rrA034aTWktgzQiuvy5cubpKOnl19+2UxMNWfOHPOBho5Ne+fq75T+7uj2ekytal5fEvvYalJ06NCh5sManRBLx6bVrpr41Q9m9PdM9xsaGhqpKlTPGU3iNmnSxCRRv/nmG/O9/n76osdMk87af1ePqSZDtdWF/l7psfZMoGp/WH0dU6dOlWXLlpnXp31otcpXP1DQ3z392UWnN23EDym0jcTw4cPdt6NDn1d/N/T46OvQyd/057p06VJzDDXBbNFjMGzYMPOBk54HelvPNd1ePwjSn6G+n2plsVbT6ocK+h6nx1KT9pqw1d85TfDqfvWcAAAAKYwLAACkWNu3b3e99NJLrmLFirnSpUvnSps2rSs4ONj1/PPPu1avXh1p+/Pnz7tee+01V6FChVxp0qRx5ciRw9W6dWvX3r17I23bsWNHLadzHTlyJNJ99erVM/f5ovvWxdf2N2/edA0YMMBVoEABV0BAgKtkyZKuqVOnuu7fv++1vd6eOXOmq2zZsq7AwEBXnjx5XJ07d3adO3fO53OHhoaadT/++KPPMcV0f5988olZp18tK1ascHXo0MGMOVOmTK6MGTO6ypQp4xoyZIg5rhHt2bPHHFs9xnqs9Zj07t3b57a+jll0jrUvYWFh5hjnz5/fnA86xlmzZpljo/vRYxXRiRMnzNiKFy9uHhMUFOQqXbq0q0uXLq41a9bE+hj4Yv2sPv/883/cVreJaswxOb5q/fr1rrp165rfk2zZsrmee+45119//fXA47to0SJXw4YNXVmzZjXPoce0fv36rokTJ3o9j6/zJbGP7b1791zLly83z1W5cmVX7ty5Xf7+/ub5qlSp4ho5cqTrypUrkR5348YN856g2+v4ypcv75o/f36U54uu02N2/PhxV5s2bcyx1N+pGjVquFatWuVzbHfv3nV9+OGHrlq1apnx6PMULFjQ1aRJE9eMGTNc169fj9b7TkR6THXbhx56yLx+XyL+bl2+fNk1YsQIcy7kzZvXvA/ly5fPjOWHH37wuQ99L3366addOXPmNOeBvn/o6x01apTr2LFjZpvbt2+7xo4d62rUqJEZj+5Xj6k+z4IFCyK9xwEAgJTBT/+xO3kMAADwINqvU6t9CVuApE0rhrWC2FePYQAAAHijURIAAAAAAAAAOAyJWwAAAAAAAABwGBK3AAAAAAAAAOAw9LgFAAAAAAAAAIeh4hYAAAAAAAAAHIbELQAAAAAAAAA4DIlbAAAAAAAAAHAYErcAAAAAAAAA4DAkbgEAAAAAAADAYUjcAgAAAAAAAIDDkLgFAAAAAAAAAIchcQsAAAAAAAAADkPiFgAAAAAAAAAchsQtAAAAAAAAADgMiVsAAAAAAAAAcBgStwAAAAAAAADgMCRuAQAAAAAAAMBhSNwCAAAAAAAAgMOQuAUAAAAAAAAAhyFxCwAAAAAAAAAOQ+IWAAAAAAAAAByGxC0AAAAAAAAAOAyJWwAAAAAAgP9vyZIlMmXKFLuHAQAkbgEACWfdunXi5+dnvgIAACB5OXr0qIn1Pv30U0kuTp8+Le3bt5ehQ4fK999/b/dwAKRwJG4BpCgaVGpw6WsZNGiQe7tVq1ZJ586d5eGHH5bUqVNLcHBwjJ9r79690rp1aylUqJAEBgZK/vz55YknnpD3339fkppOnTqZYxQUFCQ3b96MdP+hQ4fcx3HChAm2jBEAACAxRRVTRlxS2gfYI0aMiFXsHBOnTp0yz7N79+543/ebb74pzz33nEybNk369esnd+/elZTit99+M8dVE/IAnMHf7gEAgB3eeustKVy4sNc6TdJaFixYIIsWLZJHHnlE8uXLF+P9b9q0SR577DEpWLCgdO3aVfLkySPHjx+XLVu2mMuuXn31VUlq/P395caNG/Ldd9/Jv/71L6/75s+fb5LTt27d8lpft25dk+gNCAhI5NECAAAkrHnz5nndnjt3rqxevTrS+tKlSyfyyJI/TdyOHDnSJIgrVqwYb/v95ZdfZMWKFbJ//37JmjWriXGnT58uvXv3lpSSuNXjWr9+/QRPvgOIHhK3AFKkpk2bSpUqVaK8/91335WPPvpI0qRJI0899ZTs27cvRvt/5513JHPmzLJ9+3bJkiWL133nzp2TxKTJ1vTp08d5P2nTppVatWrJ559/Hilxq4nuZs2ayVdffeW1PlWqVCahGx/CwsIkQ4YM8bIvAACAuHrxxRe9busH9Jq4jbge9otuPFypUiWTFPa8Cg8A7ESrBADwQatsNWkbW3/++aeULVs2UtJW5cqVK9K6zz77TKpWrWoCSv10XytVIwaKH3zwgdmnJlB1fD179pQrV654baOfjmvl8M6dO80+dH9Dhgwx94WHh0toaKgUK1bM7KNAgQIyYMAAsz66nn/+efnhhx+8nleT09oqQe+Lbo/brVu3ypNPPmleqyZjy5cv7zUBhLZmyJgxozmOul2mTJnkhRdecCdw33jjDTN+fR0lS5Y07RlcLle0XwcAAEBiuH//vkyePNnEcPphdu7cueXll1+Wy5cve22n1Y1aLKAxkxYXpEuXTsqVK+eOob7++mtzW/dRuXJlUxnqyYqd/vvf/0rjxo1NfKXxol5lFjFGWrhwodmHxlfaBkv3G52JuDT+0+fR4gSNcTt27BgpFn0QjXf1efW1ZcuWTdq2bWuuSPMVy2rlp169prGsthsbN26cexs9Jo8++qj5PiQkxN2Swuqz+6B4eOnSpabYQI+NxpFFixaVUaNGyb179yIdT8+KU6uXr8acs2bNMo/Tx+s4NBaO6Pfffzct0/R16s9Mf6bffvutzxZuGzZskNdee01y5sxpjqueH7dv3zbHtkOHDiZe1kXj9og/y5ieX/pc+n8O3bZIkSKmStxzPNoiQumxT6mtPgCnIXELIEW6evWqXLhwwWuJT9rXVoPF6FTq6uVIOgGCJoo1uNbbmpRcu3atexvtNaWJWg0yJ06cKK1atZIPP/xQGjVqJHfu3PHa38WLF01FsV42poGcBl4a1D3zzDMm2Hz66adNn90WLVrIe++9J23atIn262rZsqUJ4PQ/D57VtqVKlTJtJaJDK1E0iNaAXC8709ejY4w4+YP2E9P/eGiiW8etr1mDVX0dOu4mTZrIpEmTTOK2f//+0rdv32i/DgAAgMSgSTSNU/SqJU2OaqJRL7/XGCdiDHf48GHzQbjGaqNHjzbJN/1et+/Tp4+p5NU4UT/Y1qufNL7zpMlHjY80eaeJTk2S6of2unjGYe3atTOJwLFjx8qYMWNMonPjxo0PfB0agzVv3ty0gdBxvP3223LixAmTvI3u1WiahCxevLiJ315//XVZs2aNiQkjJn/1devrqFChgokTNc4cOHCgKR6wWk9ozKy6detmxqSL7utB8bCVnNQEt8aN+vPQYzR8+HCvuS4eROPe8ePHm5+rHgNN6Gp87Pmz1DYL1atXlwMHDpj96mvQRLrG3t98802kfWoLNS2C0J+txrmaGB42bJj52evPVK8ErF27tnneiG04Ynp+aTJZ59zQMek5oAlqHa/S46cJZKWJbuu40uoDsJkLAFKQTz75RD+m9rlEpVmzZq5ChQrF6HlWrVrlSp06tVlq1KjhGjBggGvlypWu27dve2136NAhV6pUqVzPPvus6969e1733b9/33w9d+6cKyAgwNWoUSOvbaZNm2bGPXv2bPe6evXqmXUzZ8702te8efPM8/z8889e63U73X7jxo0PfD0dO3Z0ZciQwXzfunVrV4MGDcz3Op48efK4Ro4c6Tpy5IjZ1/jx492P+/HHH806/aru3r3rKly4sDmely9f9vl6refTxw0aNMhrmyVLlpj1b7/9ttd6HZOfn5/r8OHDD3wdAAAACaVnz55eMaXGXXp7/vz5XtutWLEi0nqNjXTdpk2b3Os0dtR16dKlc/3111/u9R9++KFXfOUZO7366qtesZXGsRpHnj9/3qzr3bu3KygoyMRkMWHFYOPGjXOv033UqVPHrNcYOypHjx41MfE777zjtX7v3r0uf39/r/VWLDt37lz3uvDwcBNvtmrVyr1u+/btUT5vVPGwunHjRqR1L7/8sit9+vSuW7dueR1Pz/jfinOzZ8/uunTpknv90qVLzfrvvvvOvU7j5HLlynntT38WNWvWdBUvXjzS/0saN27sFQfr/x00ru3evbvXsX7ooYfMa4vL+bV+/Xr3Ov0/Rtq0aV1vvPGGe93ixYsjnVsA7EXFLYAUSScZ0IoDzyU+6SfZmzdvNp+a//rrr6bqQT/51ku9PC+TWrJkiamW0E/6tR+sJ61sVf/5z3/M5VJameC5jU56ppe3LVu2zOtxetmWftruafHixebTcq1Y8Kwyfvzxx839P/74Y7Rfm1aC6CVTZ86cMVXB+tVXmwRf9LK+I0eOmNcSsY2E9Xo99ejRw+v28uXLJXXq1O5qAIu2TtBKEKsSAwAAwG4af2lbAY0LPeMvrfLUqs+I8VeZMmWkRo0a7tvVqlUzXzVe0wlvI67XtggR9erVyyu20tsaR2o8qTT+0rZTMY19NQbTiWo9YzONyaIz4a5eqaXxrlYJex4HnbxXK3AjHgc9Np59gnWSW72839frjYqveFhpmwbL33//bcZRp04d0wNX2xv8E71STStVLfpYZY3t0qVLJj7W12rtXxetANb/C2hl7cmTJ7322blzZ684WH++Gtfqes9jre0WPI9BbM4va7xKWzPolWsxOa4AEh+TkwFIkTT4e9DkZNGhly6dP3/ea532sdLgUmnPKw1UNVjW5K1eGqWX+OslSrt37zbBk17qpslY/T4qf/31l/mqgZUnfR7tTWXdb9HksDUGiwaJermWBmi+xGTCNKvn7KJFi8zr0NepfXP1UrF/oq9Xad+xf6L/OXjooYe81ulr1XYR+vyerEu4Ih4LAAAAu2j8pe25fM1v4Cv+8kzOKk3KKW2h5Wt9xD6mGlNqbOipRIkS5qsVp73yyivyxRdfmDYCGjNq2y1NMmprggfRGCtv3rwmIegpYnwa1XHQRKQmaX2JOK+Exn8RP9DXZOmePXskunzFw0rbAgwdOtQkV69du+Z1n/6s/knEn5GVxLV+FtqOQF+rtjrQJaqfu44vNj93z595XM8va/wRzyMAzkLiFgBiSSdTKFy4sNc6/WRb+4R50qBRk5u6aPCsn/7rJ+Se/cbik2clgUWrHHTiCe0p5kvEwPCfKhi0l9ecOXPMJ/Tafzch6PNErEIGAABIKjT+0qSa9hz1JeIH6lpV6UtU62MzMauORz94X7lypblSSZdPPvnE9J/V2C6hjoMmYvW5fL2WiMng+Hi9vuJh7aVbr149c8Wa9sjVCcZ0kq5du3aZHroRewb78k9js/bRr18/U2HrixY8RGefvtZ7HoP4Or+Y4BdwNhK3ABBLenlXxMvMdBKFB7GqfE+fPm2+asCoQZdO1KWTJ0Q10Zk6ePCgVxWFVvJq24GGDRv+41j1ebTqt0GDBj5bEsSUtkaYPXu2SazqjMDRpeNQOmlbdMbt61jopX566Zln1a11aZt1rAAAAOymcY/GLTpxlK9EYnzTmFI/VLeqbNUff/xhvgYHB3sVFejEV7roY7QKVye91QrRiElFi8ZYOpnY9evXvRKtGp9G5zhoclALHjzHFhexiWe11Ze2LNAr4jwnMtN4Or5YsbpWEccm1rX7/IqP/ycAiF+UMgFALOkn9BqQeS7W5VJaeevr02vtD+Z5WZnOLqvJT/3UP+Kn/Nbjdb8aYE+dOtVrn//+97/N5VHNmjX7x7HqJXDaT+ujjz6KdN/NmzdNr7OY0Jl5R40aJdOmTTMJ7Oh65JFHTNCus/tGnEE4Op/2a5sGbVGhz+tJW1BooKmX/QEAADiBxl8at2jMFNHdu3cjxULxwTNG0thKb2sSUT+8V5q49KRxaPny5c334eHhD4zBdMwzZsxwr9PX9v777//jmPRKLa32HDlyZKR4T29HHFN0ZMiQwXyNyTG0Kk49x6CFEB988IHEF62A1avvNBFuFWp4ithmzWnnV2yOK4CERcUtAPigPbSsScS0V5UmSN9++213Va1WKDyITtSgkxw8++yzZkIwDQo3bdpk+sJqxYM1WYJWNbz55psm4NLJAjSw1RYB27dvN71cR48ebS5zGjx4sAl2tf+YTnim1Q0aZGr7Bc/JG6LSvn1708+se/fuJqmsn8xroKeVqrpeL5eLSc9fDfK1P1hM6eM04NfjpxXGehy0X5qOQ3uO6TgeRB+nSWM9ZtqrTX8Wq1atkqVLl5oJz6yKXgAAALvpZfkvv/yyiee0PYH2k9UkqvYm1bZZU6ZMMXMfxGdRwYoVK6Rjx45mgittTaCT2A4ZMsR92XyXLl3MBFo64Zn2ktXetZp81bjMmjMgqhhM48dBgwaZGEznZ9DK1ej0hdX4TONojWf1sVq4oFdOaaWrzgHRrVs301ogJnSfOtHazJkzzb404aivOWIbM081a9Y0RRZ6fHSiW/3Qf968efHeKkAnQa5du7ZpU6aTCWsV7tmzZ83ExSdOnDBXwTn1/NLzQBPcY8eONT9b/X+JnitR9dEFkPBI3AKAD9rrKuKEAtZtDfb+KXE7YcIEEzBphe2sWbNM4lYnBNBL0TThqYGmRattNcjUoFkTkunTpzeVD5pstWgfWQ24tWqiT58+ZhI0DXLffffdSBM6RJUwXbJkialMnTt3rgmS9Xk0kOzdu3e8XbYWHdrvS5PHmoieOHGiqTTW4FsD2+i8Dk2oDx8+3CTBtSebJsLHjx8vb7zxRqKMHwAAILo0sVi5cmVTgakJVJ18VWMX/eBdE6HxSRNumrjt0aOH9O/f3yQ0dU4FjZss+rwam2oBgFZV6pVTbdq0MbHmg+YWsGIw/aD8s88+M0lPLSbQWK5SpUr/ODZN+Gq8qbGoxoDWHAuabNT9xJTGv9qTV5PBWpigFaYaFz4ocZs9e3b5/vvvTcyo8bgmcfV4aDVyVP1oY0OT2jt27DCv89NPPzUVxZr41OPk+bNw4vml54PuU5PBnTt3NoUeGreTuAXs4+eiEzUAAAAAAElWp06d5MsvvzQ9aAEAyQc9bgEAAAAAAADAYUjcAgAAAAAAAIDDkLgFAAAAAAAAAIehxy0AAAAAAAAAOAwVtwAAAAAAAADgMCRuAQAAAAAAAMBhSNwCAAAAAAAAgMP42z0AJ7p//76cOnVKMmXKJH5+fnYPBwAAIEXTKRn+/vtvyZcvn6RKRd1BTBHbAgAAJM3YlsStDxrYFihQwO5hAAAAwMPx48floYcesnsYSQ6xLQAAQNKMbUnc+qDVCNYBDAoKsns4AAAAKdq1a9dM4tGK0RAzxLYAAABJM7YlceuDdQmZBrYEtwAAAM7AZf6xQ2wLAACQNGNbmoQBAAAAAAAAgMOQuAUAAAAAAAAAhyFxCwAAAAAAAAAOQ+IWAAAAAAAAAByGxC0AAAAAAAAAOAyJWwAAAAAAAABwGBK3AAAAAAAAAOAwJG4BAAAAAAAAwGFI3AIAAAAAAACAw5C4BQAAAAAAAACHcUTidvr06RIcHCyBgYFSrVo12bZtW5Tbfv3111KlShXJkiWLZMiQQSpWrCjz5s3z2qZTp07i5+fntTRp0iQRXgkAAAAAAAAAxJ2/2GzRokXSt29fmTlzpknaTp48WRo3biwHDx6UXLlyRdo+W7Zs8uabb0qpUqUkICBAvv/+ewkJCTHb6uMsmqj95JNP3LfTpk2baK8JAAAAAAAAAJJ04nbSpEnStWtXk3xVmsBdtmyZzJ49WwYNGhRp+/r163vd7t27t8yZM0c2bNjglbjVRG2ePHkS4RUAAAAAAOJi/8C6dg8BiaTs2PV2DwEAkgxbWyXcvn1bdu7cKQ0bNvzfgFKlMrc3b978j493uVyyZs0aU51bt673H/p169aZKtySJUtKjx495OLFi1HuJzw8XK5du+a1AAAAAAAAAECKrLi9cOGC3Lt3T3Lnzu21Xm///vvvUT7u6tWrkj9/fpNwTZ06tXzwwQfyxBNPeLVJaNmypRQuXFj+/PNPGTJkiDRt2tQkg3X7iEaPHi0jR46M51cHAAAAAAAAAEm0VUJsZMqUSXbv3i3Xr183FbfaI7dIkSLuNgpt27Z1b1uuXDkpX768FC1a1FThNmjQINL+Bg8ebPZh0YrbAgUKJNKrAQAAAAAAAAAHJW5z5MhhKmDPnj3rtV5vP6g/rbZTKFasmPm+YsWKcuDAAVM1G7H/rUWTuvpchw8f9pm41X64TF4GAAAAAAAAwCls7XEbEBAglStXNlWzlvv375vbNWrUiPZ+9DHaNiEqJ06cMD1u8+bNG+cxAwAAAAAAAECyb5WgLQo6duwoVapUkapVq8rkyZMlLCxMQkJCzP0dOnQw/Wy1olbpV91WWx9osnb58uUyb948mTFjhrlf2ydov9pWrVqZql3tcTtgwABTodu4cWNbXysAAAAAAAAAJInEbZs2beT8+fMyfPhwOXPmjGl9sGLFCveEZceOHTOtESya1H3llVdMFW26dOmkVKlS8tlnn5n9KG29sGfPHpkzZ45cuXJF8uXLJ40aNZJRo0bRDgEAAAAAAABAkuDncrlcdg/CaXRyssyZM8vVq1clKCjI7uEAAACkaMRmccPxQ1Kwf2Bdu4eARFJ27Hq7hwAASSY2s7XHLQAAAAAAAAAgMhK3AAAAAAAAAOAwJG4BAAAAAAAAwGFI3AIAAAAAAACAw5C4BQAAAAAAAACHIXELAAAAAAAAAA5D4hYAAAAAAAAAHIbELQAAAAAAAAA4DIlbAAAAAAAAAHAYErcAAAAAAAAA4DAkbgEAAAAAAADAYUjcAgAAADE0evRoefTRRyVTpkySK1cuadGihRw8eNBrm1u3bknPnj0le/bskjFjRmnVqpWcPXvWa5tjx45Js2bNJH369GY//fv3l7t373pts27dOnnkkUckbdq0UqxYMfn0008T5TUCAADAXiRuAQAAgBj66aefTFJ2y5Ytsnr1arlz5440atRIwsLC3Nv06dNHvvvuO1m8eLHZ/tSpU9KyZUv3/ffu3TNJ29u3b8umTZtkzpw5Jik7fPhw9zZHjhwx2zz22GOye/duef3116VLly6ycuXKRH/NAAAASFx+LpfLlcjP6XjXrl2TzJkzy9WrVyUoKMju4QAAAKRoSSE2O3/+vKmY1QRt3bp1zVhz5swpCxYskNatW5ttfv/9dyldurRs3rxZqlevLj/88IM89dRTJqGbO3dus83MmTNl4MCBZn8BAQHm+2XLlsm+ffvcz9W2bVu5cuWKrFixItkcP2D/wLp2DwGJpOzY9XYPAQBsFZPYjIpbAAAAII408FbZsmUzX3fu3GmqcBs2bOjeplSpUlKwYEGTuFX6tVy5cu6krWrcuLEJ5vfv3+/exnMf1jbWPnwJDw83+/BcAAAAkPSQuAUAAADi4P79+6aFQa1ateThhx82686cOWMqZrNkyeK1rSZp9T5rG8+krXW/dd+DttFk7M2bN6Psv6tVHNZSoECBeHy1AAAASCwkbgEAAIA40F632spg4cKF4gSDBw82FcDWcvz4cbuHBAAAgFjwj82DAAAAAIj06tVLvv/+e1m/fr089NBD7vV58uQxk45pL1rPqtuzZ8+a+6xttm3b5rU/vd+6z/pqrfPcRvuhpUuXzueY0qZNaxYAAAAkbVTcAgAAADGk8/tq0vabb76RtWvXSuHChb3ur1y5sqRJk0bWrFnjXnfw4EE5duyY1KhRw9zWr3v37pVz5865t1m9erVJypYpU8a9jec+rG2sfQAAACD5ouIWAAAAiEV7hAULFsjSpUslU6ZM7p602lNWK2H1a+fOnaVv375mwjJNxr766qsm4Vq9enWzbaNGjUyCtn379jJu3Dizj6FDh5p9WxWz3bt3l2nTpsmAAQPkpZdeMkniL774QpYtW2br6wcAAEDCo+IWAAAAiKEZM2aY/rH169eXvHnzupdFixa5t3nvvffkqaeeklatWkndunVN24Ovv/7afX/q1KlNmwX9qgndF198UTp06CBvvfWWexut5NUkrVbZVqhQQSZOnCgff/yxNG7cONFfMwAAABKXn0uv84IXnaVXqyQ0GNfqCAAAANiH2CxuOH5ICvYPrGv3EJBIyo5db/cQACDJxGZU3AIAAAAAAACAw5C4BQAAAAAAAACHIXELAAAAAAAAAA5D4hYAAAAAAAAAHIbELQAAAAAAAAA4DIlbAAAAAAAAAHAYErcAAAAAAAAA4DAkbgEAAAAAAADAYfztHkByNHbpDruHgEQysHkVu4cAAAAAAACAZIiKWwAAAAAAAABwGBK3AAAAAAAAAOAwjkjcTp8+XYKDgyUwMFCqVasm27Zti3Lbr7/+WqpUqSJZsmSRDBkySMWKFWXevHle27hcLhk+fLjkzZtX0qVLJw0bNpRDhw4lwisBAAAAAAAAgGSQuF20aJH07dtXQkNDZdeuXVKhQgVp3LixnDt3zuf22bJlkzfffFM2b94se/bskZCQELOsXLnSvc24ceNk6tSpMnPmTNm6datJ8Oo+b926lYivDAAAAAAAAACSaOJ20qRJ0rVrV5N8LVOmjEm2pk+fXmbPnu1z+/r168uzzz4rpUuXlqJFi0rv3r2lfPnysmHDBne17eTJk2Xo0KHSvHlzc9/cuXPl1KlTsmTJkkR+dQAAAAAAAACQxBK3t2/flp07d5pWBu4BpUplbmtF7T/RJO2aNWvk4MGDUrduXbPuyJEjcubMGa99Zs6c2bRgiGqf4eHhcu3aNa8FAAAAAAAAAFJk4vbChQty7949yZ07t9d6va3J16hcvXpVMmbMKAEBAdKsWTN5//335YknnjD3WY+LyT5Hjx5tkrvWUqBAgXh4dQAAAAAAAACQRFslxEamTJlk9+7dsn37dnnnnXdMj9x169bFen+DBw82yWBrOX78eLyOFwAAAAAAAABiwl9slCNHDkmdOrWcPXvWa73ezpMnT5SP03YKxYoVM99XrFhRDhw4YKpmtf+t9TjdR968eb32qdv6kjZtWrMAAAAAAAAAgKT0ilttdVC5cmXTp9Zy//59c7tGjRrR3o8+RvvUqsKFC5vkrec+tWft1q1bY7RPAAAAAAAAAEiRFbdK2xx07NhRqlSpIlWrVpXJkydLWFiYhISEmPs7dOgg+fPnNxW1Sr/qtkWLFjXJ2uXLl8u8efNkxowZ5n4/Pz95/fXX5e2335bixYubRO6wYcMkX7580qJFC1tfKwAAAAAAAAAkicRtmzZt5Pz58zJ8+HAzeZi2M1ixYoV7crFjx46Z1ggWTeq+8sorcuLECUmXLp2UKlVKPvvsM7Mfy4ABA8x23bp1kytXrkjt2rXNPgMDA215jQAAAAAAAAAQE34ul8sVo0ekANpaIXPmzGaisqCgoBg/fuzSHQkyLjjPwOZV7B4CAADJXlxjs5SO44ekYP/AunYPAYmk7Nj1dg8BAJJMbGZrj1sAAAAAAAAAQGQkbgEAAAAAAADAYUjcAgAAAAAAAIDDkLgFAAAAAAAAAIchcQsAAAAAAAAADkPiFgAAAAAAAAAchsQtAAAAAAAAADgMiVsAAAAAAAAAcBgStwAAAAAAAADgMCRuAQAAAAAAAMBhSNwCAAAAAAAAgMOQuAUAAAAAAAAAhyFxCwAAAAAAAAAOQ+IWAAAAAAAAAByGxC0AAAAAAAAAOAyJWwAAAAAAAABwGBK3AAAAAAAAAOAwJG4BAAAAAAAAwGFI3AIAAAAAAACAw5C4BQAAAAAAAACHIXELAAAAAAAAAA5D4hYAAAAAAAAAHIbELQAAAAAAAAA4DIlbAAAAAAAAAHAYErcAAAAAAAAA4DAkbgEAAAAAAADAYUjcAgAAAAAAAIDD+Ns9AACx02HaKruHgEQyt1cju4cAAAAAAAASGRW3AAAAAAAAAOAwVNwCAKL0RP8Zdg8BiWT1+B52DwEAAAAA4IGKWwAAAAAAAABwGBK3AAAAAAAAAOAwjkjcTp8+XYKDgyUwMFCqVasm27Zti3Lbjz76SOrUqSNZs2Y1S8OGDSNt36lTJ/Hz8/NamjRpkgivBAAAAAAAAACSQeJ20aJF0rdvXwkNDZVdu3ZJhQoVpHHjxnLu3Dmf269bt07atWsnP/74o2zevFkKFCggjRo1kpMnT3ptp4na06dPu5fPP/88kV4RAAAAAAAAACTxxO2kSZOka9euEhISImXKlJGZM2dK+vTpZfbs2T63nz9/vrzyyitSsWJFKVWqlHz88cdy//59WbNmjdd2adOmlTx58rgXrc4FAAAAAAAAgKTA1sTt7du3ZefOnabdgXtAqVKZ21pNGx03btyQO3fuSLZs2SJV5ubKlUtKliwpPXr0kIsXL8b7+AEAAAAAAAAgIfiLjS5cuCD37t2T3Llze63X27///nu09jFw4EDJly+fV/JX2yS0bNlSChcuLH/++acMGTJEmjZtapLBqVOnjrSP8PBws1iuXbsWp9cFAAAAAAAAAEk2cRtXY8aMkYULF5rqWp3YzNK2bVv39+XKlZPy5ctL0aJFzXYNGjSItJ/Ro0fLyJEjE23cAAAAAAAAAODYVgk5cuQwFbBnz571Wq+3tS/tg0yYMMEkbletWmUSsw9SpEgR81yHDx/2ef/gwYPl6tWr7uX48eOxeDUAAABIKdavXy9PP/20ufLLz89PlixZ4nV/p06dzHrPRa8K83Tp0iV54YUXJCgoSLJkySKdO3eW69eve22zZ88eqVOnjilS0El5x40blyivDwAAACk8cRsQECCVK1f2mljMmmisRo0aUT5OA9ZRo0bJihUrpEqVKv/4PCdOnDA9bvPmzevzfp3ITANmzwUAAACISlhYmFSoUEGmT58e5TaaqD19+rR7+fzzz73u16Tt/v37ZfXq1fL999+bZHC3bt282nc1atRIChUqZOaFGD9+vIwYMUJmzZqVoK8NAAAAzmB7q4S+fftKx44dTQK2atWqMnnyZBMIh4SEmPs7dOgg+fPnN+0M1NixY2X48OGyYMECCQ4OljNnzpj1GTNmNItWKWjbg1atWpmqXe1xO2DAAClWrJg0btzY1tcKAACA5EHnT9DlQbQ4IKqryA4cOGCKELZv3+4uRHj//fflySefNFeWaSXv/PnzzWS+s2fPNgUPZcuWld27d8ukSZO8ErwAAABInmytuFVt2rQxwakmYytWrGiCUQ1irQnLjh07ZioULDNmzDABbOvWrU0FrbXoPpS2XtBLyp555hkpUaKEueRMq3p//vlnEzwDAAAAiUHnV8iVK5eULFlSevToYa4As+ikudoewfPqMZ1sN1WqVLJ161b3NnXr1jVJW4sWIhw8eFAuX76cyK8GAAAAKa7iVvXq1cssUQW8no4ePfrAfaVLl05WrlwZr+MDAAAAYkLbJLRs2VIKFy5srgAbMmSIqdDVZKwWGuhVY5rU9eTv7y/ZsmVzX1GmX/XxnqziBr0va9asPp87PDzcLJ4tFwAAAJD0OCJxCwAAACQnbdu2dX9frlw5M5lu0aJFTVFCgwYNEvS5tcWYtg4DAABA0mZ7qwQAAAAguStSpIjkyJFDDh8+bG5r79tz5855bXP37l25dOmSuy+ufj179qzXNtbtqHrnqsGDB8vVq1fdy/HjxxPgFQEAACChkbgFAAAAEtiJEydMj1udm0HVqFFDrly5Ijt37nRvs3btWrl//75Uq1bNvc369evlzp077m1Wr15teuZG1SZB6bwOQUFBXgsAAACSHhK3AAAAQAxdv37dTKqrizpy5Ij5XifW1fv69+8vW7ZsMfMzrFmzRpo3by7FihUzk4up0qVLmz64Xbt2lW3btsnGjRvNnA/aYiFfvnxmm+eff95MTKaT7e7fv18WLVokU6ZMkb59+9r62gEAAJA4SNwCAAAAMbRjxw6pVKmSWZQmU/X74cOHm8nH9uzZI88884yUKFHCJF4rV64sP//8s6mGtcyfP19KlSplet4++eSTUrt2bZk1a5b7/syZM8uqVatMUlgf/8Ybb5j9d+vWzZbXDAAAgMTF5GQAAABADNWvX19cLleU969cufIf95EtWzZZsGDBA7fRSc004QsAAICUh4pbAAAAAAAAAHAYErcAAAAAAAAA4DAkbgEAAAAAAADAYUjcAgAAAAAAAIDDkLgFAAAAAAAAAIchcQsAAAAAAAAADkPiFgAAAAAAAAAchsQtAAAAAAAAADgMiVsAAAAAAAAAcBgStwAAAAAAAADgMCRuAQAAAAAAAMBhSNwCAAAAAAAAgMOQuAUAAAAAAAAAhyFxCwAAAAAAAAAOQ+IWAAAAKcacOXNk2bJl7tsDBgyQLFmySM2aNeWvv/6ydWwAAACAJxK3AAAASDHeffddSZcunfl+8+bNMn36dBk3bpzkyJFD+vTpY/fwAAAAADf//30LAAAAJG/Hjx+XYsWKme+XLFkirVq1km7dukmtWrWkfv36dg8PAAAAcKPiFgAAAClGxowZ5eLFi+b7VatWyRNPPGG+DwwMlJs3b9o8OgAAACAeErfz5s0zlQn58uVz9wObPHmyLF26NLa7BAAAABKUJmq7dOlilj/++EOefPJJs37//v0SHBxs9/AAAACAuCVuZ8yYIX379jWB7pUrV+TevXtmvU7soMlbAAAAwIm0p22NGjXk/Pnz8tVXX0n27NnN+p07d0q7du3sHh4AAAAQtx6377//vnz00UfSokULGTNmjHt9lSpVpF+/frHZJQAAAJDgtNBg2rRpkdaPHDnSlvEAAAAA8Vpxe+TIEalUqVKk9WnTppWwsLDY7BIAAABIFD///LO8+OKLUrNmTTl58qS7DdiGDRvsHhoAAAAQt8Rt4cKFZffu3ZHWr1ixQkqXLh2bXQIAAAAJTtsjNG7cWNKlSye7du2S8PBws/7q1avy7rvv2j08AAAAIG6JW+1v27NnT1m0aJG4XC7Ztm2bvPPOOzJ48GAZMGBAbHYJAAAAJLi3335bZs6cadp+pUmTxr1eJ93VRC4AAACQpHvc6iy8WqUwdOhQuXHjhjz//POSL18+mTJlirRt2zb+RwkAAADEg4MHD0rdunUjrc+cObOZdBcAAABIsonbu3fvyoIFC8wlZi+88IJJ3F6/fl1y5cqVMCMEAAAA4kmePHnk8OHDEhwc7LVe+9sWKVLEtnEBAAAAcW6V4O/vL927d5dbt26Z2+nTpydpCwAAgCSha9eu0rt3b9m6dav4+fnJqVOnZP78+dKvXz/p0aOH3cMDAAAA4tbjtmrVqvLLL79IfJk+fbqpeggMDJRq1aqZnrlR0X5kderUkaxZs5qlYcOGkbbXvrvDhw+XvHnzmpYOus2hQ4fibbwAAABImgYNGmTafDVo0MBcNaZtE7QN2Msvvyyvvvqq3cMDAAAA4pa4feWVV+SNN96QadOmyebNm2XPnj1eS0zoBGc62VloaKiZEKJChQqmDcO5c+d8br9u3Tpp166d/Pjjj+a5CxQoII0aNZKTJ0+6txk3bpxMnTrVTDyh1RQZMmQw+7SqhAEAAJAyaZXtm2++KZcuXZJ9+/bJli1b5Pz58zJq1Ci7hwYAAADEfXIyawKy1157zSsI1kpX/Xrv3r1o72vSpEnmkrWQkBBzW5Oty5Ytk9mzZ5uKiIj0UjZPH3/8sXz11VeyZs0a6dChgxnD5MmTzcRpzZs3N9vMnTtXcufOLUuWLGHyNAAAAEhAQICUKVPG7mEAAAAA8Zu4PXLkiMSH27dvy86dO2Xw4MHudalSpTKtDbSaNjp0crQ7d+5ItmzZ3GM7c+aM2YfnLMHagkH3SeIWAAAgZWnZsmW0t/36668TdCwAAABAgiZuCxUqJPHhwoULpjpXq2E96e3ff/89WvsYOHCg5MuXz52o1aSttY+I+7Tuiyg8PNwslmvXrsX4tQAAAMCZ9EN8i16d9c0335h1VapUMeu0kODKlSsxSvACAAAAjkzcqj///NO0JDhw4IC5rZea6Qy9RYsWlcQyZswYWbhwoel7qxObxdbo0aNl5MiR8To2AAAAOMMnn3zi9aH/v/71L9OeK3Xq1GadFhLoHA5BQUE2jhIAAACIh8nJVq5caRK127Ztk/Lly5tFJwErW7asrF69Otr7yZEjhwmYz54967Veb+fJk+eBj50wYYJJ3K5atco8v8V6XEz2qa0arl696l6OHz8e7dcAAACApEPnUejXr587aav0e50sV+8DAAAAknTiVicN69Onj0nW6uRiuuj3r7/+uqliiMmkEJUrVzYTi1nu379vbteoUSPKx40bN87M/LtixQr3JW6WwoULmwSt5z619YGOL6p9pk2b1lRYeC4AAABIfu7eveuzJZeu0zgUAAAASNKtErQ9whdffBFp/UsvvWTaJ8SEVjd07NjRJGCrVq1qHh8WFiYhISHm/g4dOkj+/PlNOwM1duxYGT58uCxYsECCg4PdfWszZsxoFj8/P5NAfvvtt6V48eImkTts2DDTB7dFixaxebkAAABIJjTG7Ny5s2n7pbGn0g/49UouK/4EAAAAkmziNmfOnLJ7926TGPWk63LlyhWjfbVp00bOnz9vkrGahK1YsaKppLUmFzt27JikSvW/wuAZM2bI7du3pXXr1l77CQ0NlREjRpjvBwwYYJK/3bp1MxNN1K5d2+wzLn1wAQAAkPRpuy29OmvixIly+vRpsy5v3rzSv39/eeONN+weHgAAABC3xG3Xrl1NUvS///2v1KxZ06zbuHGjqYbVCtqY6tWrl1l80YnHPB09evQf96dVt2+99ZZZAAAAAIsWBOiH/LpoOy1FmywAAAAkm8Stth7IlCmTqVTQib2UtiLQitfXXnstvscIAAAAxDsStgAAAEh2k5NpRatOTnbixAm5evWqWfT73r17m/sAAAAAJzp79qy0b9/eFB34+/tL6tSpvRYAAAAgSVfcHjlyxMzIqz1utfLWcujQIUmTJo2ZNAwAAABwmk6dOpk5FPQKMu1tS9EBAAAAklXiVgPel156KdLkZDoj78cffxypLy0AAADgBBs2bJCff/7ZTIgLAAAAJLtWCb/88ovUqlUr0vrq1avL7t2742NcAAAAQLwrUKCAuFwuu4cBAAAAJFyP27///jvSeu11e+/evdjsEgAAAEhwkydPlkGDBsnRo0ftHgoAAAAQ/60S6tatK6NHj5bPP//cPYmDJmx1Xe3atWOzSwAAACDBtWnTRm7cuCFFixaV9OnTm/kZPF26dMm2sQEAAABxTtyOHTvWJG9LliwpderUMeu0V9i1a9dk7dq1sdklAAAAkCgVtwAAAECyTdyWKVNG9uzZI9OmTZNff/1V0qVLJx06dJBevXpJtmzZ4n+UAAAAQDzo2LGj3UMAAAAAEi5xq/LlyyfvvvtubB8OAAAA2EJbfC1ZskQOHDhgbpctW1aeeeYZdwswAAAAIMklbi9cuCBhYWFSqFAh97r9+/fLhAkTzPoWLVrI888/nxDjBAAAAOLs8OHD8uSTT8rJkydN2y+l8zQUKFBAli1bZnrfAgAAAE6QKiYbv/rqqzJ16lT37XPnzpket9u3b5fw8HDp1KmTzJs3LyHGCQAAAMTZa6+9ZpKzx48fl127dpnl2LFjUrhwYXMfAAAAkCQrbrds2SKffvqp+/bcuXNNT9vdu3eLv7+/qbydPn26tG/fPiHGCgAAAMTJTz/9ZGJaz3kZsmfPLmPGjJFatWrZOjYAAAAg1hW3Z86ckeDgYPfttWvXSsuWLU3SVmlvsEOHDsVklwAAAECiSZs2rfz999+R1l+/fl0CAgJsGRMAAAAQ58RtUFCQXLlyxX1727ZtUq1aNfdtPz8/0zIBAAAAcKKnnnpKunXrJlu3bhWXy2UWrcDt3r27KUIAAAAAkmTitnr16qbH7f379+XLL7801QqPP/64+/4//vjDTOwAAAAAOJHGstrjtkaNGhIYGGgWbZFQrFgxmTJlit3DAwAAAGLX43bUqFHSoEED+eyzz+Tu3bsyZMgQyZo1q/v+hQsXSr169WKySwAAACDRZMmSRZYuXSqHDx+WAwcOmHWlS5c2iVsAAAAgySZuy5cvbwLcjRs3Sp48ebzaJKi2bdtKmTJl4nuMAAAAQLzSRC3JWgAAACSbVgkqR44c0rx5c3fS9sSJE6Z1gmrWrJkULlw4/kcJAAAAxINWrVrJ2LFjI60fN26cPPfcc7aMCQAAAIiXxG1EWmF79OjRuO4GAAAASHDr16+XJ598MtL6pk2bmvsAAACAZJO41Zl4AQAAgKTg+vXrEhAQEGl9mjRp5Nq1a7aMCQAAAEiQxC0AAACQVJQrV04WLVoUab1OsstcDQAAAEhWidshQ4ZItmzZ4mc0AAAAQAIaNmyYjBo1Sjp27Chz5swxS4cOHeSdd94x90WXtlV4+umnJV++fOLn5ydLliyJdFXa8OHDJW/evJIuXTpp2LChHDp0yGubS5cuyQsvvCBBQUGSJUsW6dy5s6kI9rRnzx6pU6eOBAYGSoECBUwvXgAAAKQMcU7cDh482ASaAAAAgNNpslWTrIcPH5ZXXnlF3njjDTPZ7n/+8x9p0aJFtPcTFhYmFSpUkOnTp/u8XxOsU6dOlZkzZ8rWrVslQ4YM0rhxY7l165Z7G03a7t+/X1avXi3ff/+9SQZ369bNfb+2bmjUqJEUKlRIdu7cKePHj5cRI0bIrFmz4ngUAAAAkBT4x+fOjh8/LqGhoTJ79uz43C0AAAAQb5o1a2aWuNDJzHTxRattJ0+eLEOHDpXmzZubdXPnzpXcuXObpHHbtm3lwIEDsmLFCtm+fbtUqVLFbPP++++bidMmTJhgKnnnz58vt2/fNrG19uUtW7as7N69WyZNmuSV4AUAAEDyFK89bvVyL73cDAAAAHCqK1euyMcff2xafmn8qnbt2iUnT56Ml/0fOXJEzpw5Y9ojWDJnzizVqlWTzZs3m9v6Va9as5K2SrdPlSqVqdC1tqlbt67XZGpatXvw4EG5fPlyvIwVAAAAyaTi9ttvv33g/f/973/jOh4AAAAgwWjPWE2QaiL16NGj0qVLFzNfw9dffy3Hjh0zlbFxpUlbpRW2nvS2dZ9+zZUrl9f9/v7+Ziye2xQuXDjSPqz7smbN6vP5w8PDzeLZcgEAAADJPHGrfb908gW9/Csqej8AAADgRH379pVOnTqZHrSZMmVyr9cWBc8//7wkB6NHj5aRI0faPQwAAAAkZqsEnRVXqxHu37/vc9FLzAAAAACn0p6yL7/8cqT1+fPnd1e6xlWePHnM17Nnz3qt19vWffr13LlzXvffvXvXtG7w3MbXPjyfI6rJg69evepedB4KAAAAJPPEbeXKlc2MtlH5p2pcAAAAwE5p06b12Trgjz/+kJw5c8bLc2h7A02srlmzxr1On1N719aoUcPc1q/aa9cztl67dq0phtBeuNY269evlzt37ri3Wb16tZQsWTLKNgnWawwKCvJaAAAAkMwTt/3795eaNWtGeX+xYsXkxx9/jI9xAQAAAPHumWeekbfeesudDNXCA+1tO3DgQGnVqlW093P9+nXZvXu3WawJyfR73Zfu8/XXX5e3337bzBGxd+9e6dChg+TLl8+0HlOlS5eWJk2aSNeuXWXbtm2yceNG6dWrl7Rt29Zsp7R1g05M1rlzZ9m/f78sWrRIpkyZYto9AAAAIPmLUY9bvYQs4gQJnjJkyCD16tWLj3EBAAAA8W7ixInSunVrMzHYzZs3Tex6+vRpU936zjvvRHs/O3bskMcee8x920qmduzYUT799FMZMGCAhIWFSbdu3Uxlbe3atWXFihUSGBjofsz8+fNNsrZBgwaSKlUqkzieOnWq+36dQG3VqlXSs2dPc+Vbjhw5ZPjw4WafAAAASP5ilLgtXry4CWytGXDbtGljgsuIM+YCAAAATqTJUG03sGHDBtmzZ4+pnNWkqCZPY6J+/fr/OGGvVvbqEpVs2bLJggULHvg85cuXl59//jlGYwMAAEAKbJUQMThdvny5qSSIi+nTp0twcLCpPtB+XnqpWFT0EjGtRNDtNRiePHlypG1GjBhh7vNcSpUqFacxAgAAIGnbvHmzfP/99+7bWgGrV4t98MEH0q5dO1PFGh4ebusYAQAAgFgnbuOb9unSy8pCQ0Nl165dUqFCBWncuHGkGXYtN27ckCJFisiYMWMeOJNu2bJlTWWwtWhFBQAAAFIurXzVIgCL9p3V/rJPPPGEDBo0SL777jsZPXq0rWMEAAAAYp24tSpYI66LrUmTJpmAOSQkRMqUKSMzZ86U9OnTy+zZs31u/+ijj8r48ePNpA06W25U/P39TWLXWrQfGAAAAFIunTjMsx3CwoULpWrVqvLRRx+ZQgJt//XFF1/YOkYAAAAg1j1utVVCp06d3EnTW7duSffu3c1lZp6+/vrrf9zX7du3ZefOnTJ48GD3Op2UoWHDhuZStrg4dOiQmY1X2y/oRBNaPVGwYMEot9fL4jwvjbt27Vqcnh8AAADOcvnyZa95GX766Sdp2rSpV4HA8ePHbRodAAAAEMeKW50lVycm00kddHnxxRdNgtS6bS3RceHCBbl3716kic309pkzZyS2tE+uzuSrs/bOmDFDjhw5InXq1JG///47ysdoYtdz/AUKFIj18wMAAMB5NMbUuNAqINA2XdWrV3ffr7FimjRpbBwhAAAAEIeK208++USczrNyQmfh1URuoUKFzKVvnTt39vkYrfrVS+Q8K25J3gIAACQfTz75pOllO3bsWFmyZIlpz6Uf7lv27NkjRYsWtXWMAAAAQKwTt/FJ+86mTp1azp4967Vebz9o4rGYypIli5QoUUIOHz4c5Tba+uFBPXMBAACQtI0aNUpatmwp9erVk4wZM8qcOXMkICDAfb/OsdCoUSNbxwgAAAA4InGrgXLlypVlzZo10qJFC7Pu/v375navXr3i7XmuX78uf/75p7Rv3z7e9gkAAICkRYsG1q9fL1evXjWJWy0g8LR48WKzHgAAAJCUnrhV2p5A++ZWqVLFzOo7efJkCQsLk5CQEHN/hw4dJH/+/KYHrdWP7LfffnN/f/LkSTNDsAbZxYoVM+v79esnTz/9tGmPcOrUKQkNDTWBebt27Wx8pQAAAHCCqOZjyJYtW6KPBQAAAHBs4rZNmzZy/vx5GT58uJmQrGLFimZSMWvCsmPHjkmqVP+bP00TsZUqVXLfnjBhgln0krd169aZdSdOnDBJ2osXL0rOnDmldu3asmXLFvM9AAAAAAAAACQFtiZulbZFiKo1gpWMtQQHB4vL5Xrg/hYuXBiv4wMAAAAAAACAxPa/clYAAAAAAAAAgCOQuAUAAAAAAAAAhyFxCwAAAAAAAAAOQ+IWAAAAAAAAAByGxC0AAAAAAAAAOAyJWwAAAAAAAABwGBK3AAAAAAAAAOAwJG4BAAAAAAAAwGFI3AIAAAAAAACAw5C4BQAAAAAAAACHIXELAAAAAAAAAA5D4hYAAAAAAAAAHIbELQAAAAAAAAA4DIlbAAAAAAAAAHAYErcAAAAAAAAA4DAkbgEAAAAAAADAYUjcAgAAAAAAAIDDkLgFAAAAAAAAAIchcQsAAAAAAAAADkPiFgAAAAAAAAAchsQtAAAAAAAAADgMiVsAAAAAAAAAcBgStwAAAAAAAADgMCRuAQAAAAAAAMBhSNwCAAAAAAAAgMOQuAUAAAAAAAAAhyFxCwAAAAAAAAAOQ+IWAAAAAAAAAByGxC0AAAAAAAAAOAyJWwAAAAAAAABwGBK3AAAAAAAAAOAwJG4BAAAAAAAAwGH87R4AAABI2Wq37mb3EJBINnw5y+4hAAAAAEmG7RW306dPl+DgYAkMDJRq1arJtm3botx2//790qpVK7O9n5+fTJ48Oc77BAAAAAAAAACnsTVxu2jRIunbt6+EhobKrl27pEKFCtK4cWM5d+6cz+1v3LghRYoUkTFjxkiePHniZZ8AAAAAAAAA4DS2Jm4nTZokXbt2lZCQEClTpozMnDlT0qdPL7Nnz/a5/aOPPirjx4+Xtm3bStq0aeNlnwAAAAAAAADgNLYlbm/fvi07d+6Uhg0b/m8wqVKZ25s3b07UfYaHh8u1a9e8FgAAAAAAAABIcYnbCxcuyL179yR37txe6/X2mTNnEnWfo0ePlsyZM7uXAgUKxOr5AQAAAAAAACBZTE7mBIMHD5arV6+6l+PHj9s9JAAAAAAAAAApmL9dT5wjRw5JnTq1nD171mu93o5q4rGE2qf2y42qZy4AAAAAAAAApJiK24CAAKlcubKsWbPGve7+/fvmdo0aNRyzTwAAAAAAAABIMRW3qm/fvtKxY0epUqWKVK1aVSZPnixhYWESEhJi7u/QoYPkz5/f9KC1Jh/77bff3N+fPHlSdu/eLRkzZpRixYpFa58AAAAAAAAA4HS2Jm7btGkj58+fl+HDh5vJwypWrCgrVqxwTy527NgxSZXqf0XBp06dkkqVKrlvT5gwwSz16tWTdevWRWufAAAAAAAAAOB0tiZuVa9evczii5WMtQQHB4vL5YrTPgEAAAAAAADA6WxP3AIAAAAAACS0JS8+bPcQkEhafLbP7iEASXtyMgAAAAAAAACAbyRuAQAAAAAAAMBhSNwCAAAAAAAAgMOQuAUAAAAAAAAAhyFxCwAAACSAESNGiJ+fn9dSqlQp9/23bt2Snj17Svbs2SVjxozSqlUrOXv2rNc+jh07Js2aNZP06dNLrly5pH///nL37l0bXg0AAAASm3+iPyMAAACQQpQtW1b+85//uG/7+/8v/O7Tp48sW7ZMFi9eLJkzZ5ZevXpJy5YtZePGjeb+e/fumaRtnjx5ZNOmTXL69Gnp0KGDpEmTRt59911bXg8AAAASD4lbAAAAIIFoolYTrxFdvXpV/v3vf8uCBQvk8ccfN+s++eQTKV26tGzZskWqV68uq1atkt9++80kfnPnzi0VK1aUUaNGycCBA001b0BAgA2vCAAAAImFVgkAAABAAjl06JDky5dPihQpIi+88IJpfaB27twpd+7ckYYNG7q31TYKBQsWlM2bN5vb+rVcuXImaWtp3LixXLt2Tfbv32/DqwEAAEBiouIWAAAASADVqlWTTz/9VEqWLGnaHIwcOVLq1Kkj+/btkzNnzpiK2SxZsng9RpO0ep/Sr55JW+t+676ohIeHm8WiiV4AAAAkPSRuAQAAgATQtGlT9/fly5c3idxChQrJF198IenSpUuw5x09erRJEgMAACBpo1UCAAAAkAi0urZEiRJy+PBh0/f29u3bcuXKFa9tzp496+6Jq1/1dsT7rfuiMnjwYNND11qOHz+eIK8HAAAACYvELQAAAJAIrl+/Ln/++afkzZtXKleuLGnSpJE1a9a47z948KDpgVujRg1zW7/u3btXzp07595m9erVEhQUJGXKlInyedKmTWu28VwAAACQ9NAqAQAAAEgA/fr1k6efftq0Rzh16pSEhoZK6tSppV27dpI5c2bp3Lmz9O3bV7Jly2aSq6+++qpJ1lavXt08vlGjRiZB2759exk3bpzpazt06FDp2bOnSc4CAAAgeSNxCwAAACSAEydOmCTtxYsXJWfOnFK7dm3ZsmWL+V699957kipVKmnVqpWZTKxx48bywQcfuB+vSd7vv/9eevToYRK6GTJkkI4dO8pbb71l46sCAABAYiFxCwAAACSAhQsXPvD+wMBAmT59ulmiotW6y5cvT4DRAQAAwOnocQsAAAAAAAAADkPiFgAAAAAAAAAchsQtAAAAAAAAADgMiVsAAAAAAAAAcBgStwAAAAAAAADgMCRuAQAAAAAAAMBhSNwCAAAAAAAAgMOQuAUAAAAAAAAAhyFxCwAAAAAAAAAOQ+IWAAAAAAAAAByGxC0AAAAAAAAAOAyJWwAAAAAAAABwGBK3AAAAAAAAAOAwJG4BAAAAAAAAwGFI3AIAAAAAAACAw5C4BQAAAAAAAACHIXELAAAAAAAAAA7jiMTt9OnTJTg4WAIDA6VatWqybdu2B26/ePFiKVWqlNm+XLlysnz5cq/7O3XqJH5+fl5LkyZNEvhVAAAAAAAAAEAySdwuWrRI+vbtK6GhobJr1y6pUKGCNG7cWM6dO+dz+02bNkm7du2kc+fO8ssvv0iLFi3Msm/fPq/tNFF7+vRp9/L5558n0isCAAAAAAAAgCSeuJ00aZJ07dpVQkJCpEyZMjJz5kxJnz69zJ492+f2U6ZMMUnZ/v37S+nSpWXUqFHyyCOPyLRp07y2S5s2reTJk8e9ZM2aNZFeEQAAAAAAAAAk4cTt7du3ZefOndKwYcP/DShVKnN78+bNPh+j6z23V1qhG3H7devWSa5cuaRkyZLSo0cPuXjxYpTjCA8Pl2vXrnktAAAAAAAAAJAiE7cXLlyQe/fuSe7cub3W6+0zZ874fIyu/6fttSJ37ty5smbNGhk7dqz89NNP0rRpU/NcvowePVoyZ87sXgoUKBAvrw8AAAAAAAAAYsNfkqG2bdu6v9fJy8qXLy9FixY1VbgNGjSItP3gwYNNn12LVtySvAUAAAAAAACQIituc+TIIalTp5azZ896rdfb2pfWF10fk+1VkSJFzHMdPnzY5/3aDzcoKMhrAQAAAAAAAIAUmbgNCAiQypUrm5YGlvv375vbNWrU8PkYXe+5vVq9enWU26sTJ06YHrd58+aNx9EDAAAAAAAAQDJM3CptUfDRRx/JnDlz5MCBA2YisbCwMAkJCTH3d+jQwbQysPTu3VtWrFghEydOlN9//11GjBghO3bskF69epn7r1+/Lv3795ctW7bI0aNHTZK3efPmUqxYMTOJGQAAAAAAAAA4ne09btu0aSPnz5+X4cOHmwnGKlasaBKz1gRkx44dk1Sp/pdfrlmzpixYsECGDh0qQ4YMkeLFi8uSJUvk4YcfNvdr64U9e/aYRPCVK1ckX7580qhRIxk1apRpiQAAAAAAAAAATmd74lZptaxVMRuRTigW0XPPPWcWX9KlSycrV66M9zECAAAAAAAAQIpplQAAAAAAAAAA8EbiFgAAAAAAAAAchsQtAAAAAAAAADiMI3rcAgAAAHCmvz7sZvcQkEgKvTzL7iEAAAAPVNwCAAAAAAAAgMOQuAUAAAAAAAAAhyFxCwAAAAAAAAAOQ+IWAAAAAAAAAByGxC0AAAAAAAAAOAyJWwAAAAAAAABwGBK3AAAAAAAAAOAwJG4BAAAAAAAAwGFI3AIAAAAAAACAw5C4BQAAAAAAAACHIXELAAAAAAAAAA5D4hYAAAAAAAAAHIbELQAAAAAAAAA4DIlbAAAAAAAAAHAYErcAAAAAAAAA4DAkbgEAAAAAAADAYUjcAgAAAAAAAIDDkLgFAAAAAAAAAIchcQsAAAAAAAAADkPiFgAAAAAAAAAcxt/uAQAAAAAAAADJQd8mFe0eAhLJpBW7E/w5qLgFAAAAAAAAAIchcQsAAAAAAAAADkPiFgAAAAAAAAAchsQtAAAAAAAAADgMiVsAAAAAAAAAcBgStwAAAAAAAADgMCRuAQAAAAAAAMBhHJG4nT59ugQHB0tgYKBUq1ZNtm3b9sDtFy9eLKVKlTLblytXTpYvX+51v8vlkuHDh0vevHklXbp00rBhQzl06FACvwoAAADAGfEyAAAAkj7bE7eLFi2Svn37SmhoqOzatUsqVKggjRs3lnPnzvncftOmTdKuXTvp3Lmz/PLLL9KiRQuz7Nu3z73NuHHjZOrUqTJz5kzZunWrZMiQwezz1q1bifjKAAAAgMSPlwEAAJA82J64nTRpknTt2lVCQkKkTJkyJtmaPn16mT17ts/tp0yZIk2aNJH+/ftL6dKlZdSoUfLII4/ItGnT3NW2kydPlqFDh0rz5s2lfPnyMnfuXDl16pQsWbIkkV8dAAAAkLjxMgAAAJIHWxO3t2/flp07d5pWBu4BpUplbm/evNnnY3S95/ZKKw6s7Y8cOSJnzpzx2iZz5szmkrKo9gkAAAA4UWziZQAAACQP/nY++YULF+TevXuSO3dur/V6+/fff/f5GE3K+tpe11v3W+ui2iai8PBws1iuXr1qvl67di1Wr+vWjeuxehySntieI/Hh9s0w254bKec8uxt+07bnRgo6z+7ctu25kTTOM+txemVVShObeDm+Y9u/b/I7mlLY+bfgevhd254bKec8u3Hnnm3PjZRznoXf5TxLKa4lQmxra+LWKUaPHi0jR46MtL5AgQK2jAdJxwi7B4AUYdEAu0eAlCDz+2/YPQSkAJkzz4nT4//++29zJRUejNgWsdYnbr+jQLRM4X0cieALzjMkvA/iGJdGJ7a1NXGbI0cOSZ06tZw9e9Zrvd7OkyePz8fo+gdtb33VdXnz5vXapmLFij73OXjwYDPhg+X+/fty6dIlyZ49u/j5+cXhFaYc+mmB/mfg+PHjEhQUZPdwkExxniExcJ4hoXGOxZxWI2hgmy9fPklpYhMvE9vGHb+nSGicY0gMnGdIDJxnCRvb2pq4DQgIkMqVK8uaNWukRYsW7sBSb/fq1cvnY2rUqGHuf/31193rVq9ebdarwoULmyBWt7EStXoSbd26VXr06OFzn2nTpjWLpyxZssTb60xJ9JeUX1QkNM4zJAbOMyQ0zrGYSamVtrGJl4lt4w+/p0honGNIDJxnSAycZwkT29reKkGrATp27ChVqlSRqlWryuTJkyUsLMzMmqs6dOgg+fPnN5d8qd69e0u9evVk4sSJ0qxZM1m4cKHs2LFDZs2aZe7XKgJN6r799ttSvHhxk8gdNmyYyWJbwS4AAACQVPxTvAwAAIDkyfbEbZs2beT8+fMyfPhwM3mYVsmuWLHCPQHDsWPHzMy5lpo1a8qCBQtk6NChMmTIEJOcXbJkiTz88MPubQYMGGCC2W7dusmVK1ekdu3aZp+BgYG2vEYAAAAgoeJlAAAAJE+2J26VXuYV1aVe69ati7TuueeeM0tUtOr2rbfeMgsSh16OFxoaGumyPCA+cZ4hMXCeIaFxjiG+42XEP35PkdA4x5AYOM+QGDjPEpafSzviAgAAAAAAAAAc4389CAAAAAAAAAAAjkDiFgAAAAAAAAAchsQtAAAAAAAAADgMiVsAAAAAAAAAcBgStwAARANzecIOp0+fljNnztg9DAAAkMwQ2yKxEdfGDolbOA5/QBAbf/31l2zZssXuYSAZunjxoty/f1/8/PzsHgpSmF9++UUeeugh2b17t91DARBLxLWILWJbJBRiW9iBuDb2SNzCccGt/gHZsGGDfPPNN3L16lW7h4Qk8kegbNmycvToUbuHgmRGA4snnnhCtm3bZvdQkML8+uuvUq9ePenXr580adLErCMBBCQtxLWILWJbJBRiW9iBuDZuSNzCccHtV199Jc8884wJci9fvmz3sJAE/gjUrl1bunfvLm3btrV7OEhm51b16tWlUaNG5iuQWPbu3Ss1a9aUvn37ytixY93rjx07Zuu4AEQfcS1ii9gWCYXYFnYgro07PxdpbjjI1q1b5cknn5RJkyZJu3btJCAgwO4hwcF+//13E9i2b99e3nvvPbl79674+/vbPSwkk8C2Ro0a8vrrr8u7777rXn/y5EnJnz+/rWND8nbp0iWpX7++eT/77bff3OtHjx4tixcvljVr1kjWrFltHSOA6CGuRUwR2yKhENvCDsS18YOKWzjuD0rFihXlueeek9SpU5t12n8H8HWuPProo3Lr1i3ZuHGjqWLRwFb/KABxcfDgQalVq5b5VFgDW+vzzVGjRsmgQYPk2rVrdg8RyZj+zXvqqackTZo0MmTIELNOkz7jx4+XMWPGENwCSQhxLWKC2BYJhdgWdiGujR8kbuG4MnqdZTB9+vQmwNVf9FSpUrn/4PBHBWrnzp1St25d6dWrl/z000/mXNFP8qwA9969e3YPEUmUnjt6CU9gYKCUL1/erNNLXTWwmDBhgrzwwgsSFBRk9zCRjOXIkUNee+01k+hZunSpqbzSqgTtj6mXNgJIOohrEV3EtkgoxLawE3Ft/CBxC0dp2rSpCWIXLVpkbmtwq0Hu9evXzR8W7Q+GlEs/Hb5x44Y0aNBAOnbsaN70H3nkEROM6H+KNMC9cuWKCXYJcBEbeu6MGDHCnEvTp0+Xb7/91h3YfvHFF+5m+ha6DSE+6fmklVV58uSRl156SZ5//nnT/+uxxx4zEzoo3tuApIO4Fv+E2BYJjdgWdiGujT/0uIWtEzYcOnRITp8+LenSpZOCBQuar9oDTO/XT/90uXjxorz//vvy0Ucfyfr166Vo0aJ2Dx82sSpV/v77b8mUKZPXer2kbMCAASb41UqFLFmymD8E1qWJwINoRZT2ldMZnHPmzGn6ffXs2dP0Yjpx4oT5hFhn4PU8p/Q/Vfof8nfeecfu4SMJ0wBWkzqrVq0y7236tzA0NNScixcuXJAPP/xQ5s+fLy1atHD3pOO9DXAW4lrEFrEtEgqxLexAXJswSNwi0YNa6xfz66+/Ns3RtXz+5s2b5pMY/fQvc+bM5lPBTZs2mcfpen0D+OGHH6RSpUp2vwzYRP8zpJM06LmglQgDBw6UDBkyuM8nPb+0coUAFzG1f/9+U+VSoUIF859qrUjQ/0SdOnVKevfuLYcPH5b+/fubT4ktw4cPN+9X27dvN48DYmPfvn3Spk0bKVasmGTPnl3u3Llj/vadO3dOPv74Y3Pf2bNnTYJnwYIF0qpVK9OPDoD9iGsRV8S2SCjEtrADcW0C0sQtkJDu3btnvl6+fNm9buPGja4sWbK4pk2bZm4vWrTI5efn5xozZoy5feLECdf27dtdb731luvzzz93/fe//7Vp9HCC3bt3u3LmzOlq3ry5q2XLlq60adO6unTp4r7//v377q/r16931a5d21WgQAHXlStXbBw1koK9e/e6smbN6urTp4/rl19+iXROHT9+3Jx3devWdX366adm3ahRo1zp0qVz7dixw7ZxI3m8r2XIkME1cOBA17lz57zOSX2fy5gxo2v16tVm3cmTJ13vvvuuK0+ePObvIgD7ENciPhDbIqEQ28IOxLUJi8QtEsWZM2dclSpVcq1cudLcHj9+vKt169bm+7/++ssVHBzs6t69u9f2gPr111/NH4EhQ4aY22FhYa6uXbu6UqdO7dq6dat7u7t377qDkjVr1rieeOIJ159//mnbuOF8Fy9edNWoUcM1YMCASPfdunXL/Z8jfY/SAFfPqUaNGpn/XBHYIi4OHDjg8vf3d40ePdrn/UeOHHE1aNDA/Cf9/PnzZt3p06ddEyZMcB0+fDiRRwsgIuJaxAWxLRIKsS3sQFyb8JicDInWY0f76uhlGUovIStQoIBZX7NmTTOjoDZLVytWrJDFixdLWFiYzaOG3bTH0rPPPitFihRx91rSiRpu375tLhHTZudHjx41661LxvSyRb0cSPs26eOAqGgfQu29pD2WLFu2bDGTNej70lNPPWX6M2lvpqlTp5p+c3v27DHbVK5c2daxI+nSS1x1MhD9qpMzKD23POk517VrV7l06ZLpRWddXt2nTx/6YQIOQFyL2CK2RUIitkViI65NHCRukSi0T05ISIi89dZbpil14cKF5ZNPPjG9vTR40SbV1ky7X375pemPoreRsmkgq/3itAfY22+/bdZp76WFCxea4GPy5MlSp04dad68uQl+NfDQYEXPHZ0QBPDl+PHjpm9cQECAmSTm8uXLZv2sWbNMAPHdd9/Jww8/bPoUPv3007Jjxw4TcGgvJv2+YsWKdr8EJGH6H3ENXnXR/4ivWbPGvGdZUw5YE9Xo+5omgzQ5ZOHvIuAMxLWILWJbJARiW9iFuDaRJEJVL1I4q5+OXn5RtmxZdy+d559/3hUQEODatWuXuUTo2rVrrkGDBrly585tyu2Rch08eND1/fffm3MnPDzcNWPGDNMrTnsxaS+cH374wWyn58wff/xhLkcsV66cq2DBguYSISAq+l5Ts2ZNV5UqVcztf/3rX6YvYYkSJVyBgYHmEp89e/a4exLq5a7vvfeezaNGcnlfGzZsmPu2XirWuXNnc97pJbCevTP1q16CrX8zuSwWcBbiWsQGsS0SCrEt7EBcm7j8EytBjJTB+kTF16y7evmFXt4zbdo0M8ulXrKhMwzqJzN6eZnOPPjnn3+aWXZLlSpl22uAvX799VdTsTJlyhRz3ugnx507dxZ/f3/p16+fNGvWTJo0aWK21cqD4sWLm3NKP+3Ty4OyZctm90uAg+n5pLM2DxkyxFRFffPNN/LVV1/JiRMnpGnTplKiRAmv7bUyQd+fgPh4b9PqqvDwcBk7dqw5t7TKSun72rJly+Txxx93/x1duXKlqeLjPQ2wD3Et4gOxLRISsS3sQFybyBI5UYwUQKsKRo4c6Vq7dm2k+3RWQa08mDt3rnvd/PnzXVOnTjWz7GqjdKRcOvNp+vTp3ZM1eLp+/brrww8/dKVKlcpr9kn9BM+qfgEexPrU986dO6aypXjx4q4mTZpEuf3QoUNdpUqVMrPvAnGl553+vdOKvDfeeCNShYJODGJVKOi5lz17dte+fftsHDEARVyLuCC2RUIitoVdiGsTF4lbxDsNQLJly+YqVKiQ67nnnjO/sDdu3DD36aU+OqNgx44d7R4mHEYv4dEZdvWN3dPChQtdFy5cMN/fvn3bXFqms+6+8847No0USY2eN74C3OXLl7tKly7tqlevXqT/ZL3++uuurFmzmu+B+KLn3bx586IMcjNlymRmptf/5O/cudPWsQL4P8S1iC1iWyQUYls4AXFt4iFxiziz/lh4OnTokGvx4sWmN1OxYsVcFStWdC1ZssQEuuvXrzfByYYNG7wewyfLKZf2W9I+X9ofztOYMWPMeu0jZ9G+YPqfKF0/fvx4G0aLpOTo0aMmUP3111+jrE54+OGHXa1atTLr9NyqVKmS6TmnlVRAfNP3MK3OS5MmTaQgt1OnTgS3gM2IaxEfiG2RUIht4STEtYnDT/9J7PYMSD6sniWnTp0ys57qLIHPPPOM5MyZ09yvp5fOYqkzpa5atUqCg4NND6e1a9fKo48+KuPGjZO0adPa/TLgAOXLl5d79+6Z2U9r1aplzo3x48eb2U6feOIJd085pd/Pnj3bzL5bunRpu4cOB9u7d6+ZxbRx48bSq1cvKVu2rNd7161bt+SLL76QiRMnmlnAq1evbt6rdMbw3Llz2z18JFF37941vQt9rbPOvXnz5pkZeHv27GnOP3X27Flzn/U3FEDiIq5FfCK2RUIgtkViI651gERKECMZsj7Z08uAtFdOhQoVXDlz5jQzox4+fDjS9jqToNXfRD9R1k/+rEvNkDJZM+taqlatai7v6dGjhzlPrL44nrZs2WJm3AWiSy8Je+SRR1xdunTx6q109+5d8/XKlSuuXLlyuSZNmmTjKJFcaDVLz549vd6nrHNNq2R0tuczZ86YdZ999pkrY8aMrm7dutk4YgCKuBbxgdgWiYHYFomFuNYZvKdJBWJAPz3R2XK10qBly5ayfPly2b9/v5k1VWdK1U+YlVXU3ahRIxk1apT5lFBnHtRqBZ05FSnTH3/8Ia+99pq0bdtWRo8ebdZt3brVzEg5c+ZMGTp0qJmJ0tPgwYMlJCTEfJIMRFfFihXl448/ll27dsnkyZPlt99+M+t1tmb9tFi/6vuWznQKxHWGXT3f8uTJI5kyZXKv13Psr7/+MpVU+h6XK1cus65NmzbmnFy6dKmpSgBgH+JaxBWxLRILsS0SA3Gtg9idOUbSFRYW5nrllVdM7xLPT5b1kxbtq6M9diKyPp2h71fKtnv3blPF0qJFC1fbtm1NT5x3333XfX+tWrVcRYsWNX3jrAqYYcOGuQIDA13btm2zceRIynbt2mWqE0JCQsz31uQOoaGhrsKFCzP7N+L8vuZr5nD9e6d/L7Uv5ssvvxzp75/+Xbx69WoijxZARMS1iAtiW9iB2BYJhbjWWbwbVQDRcOTIEfPpXfr06c2nKyogIMB9/yOPPCLnz5+XM2fOmE9nPPuh6CcxyurnhJRHe8bVqFFD+vTpI++8847pi6Of1J07d06uXbsmQUFBsmHDBnnsscekQ4cO8vXXX8s333xj+oJt3LhRKleubPdLQBKllQfaP+7VV1+VF198UUqWLGnek7Zs2WJ6FhYsWNDuISKJOnDggFSpUsVUTr311lvu9drHUNeXKFFCPv30U1OZEPHvn56D+r4HwB7EtYgrYlvYhdgWCYG41nlolYAY0abTnTp1MpePqdDQULN40kvI0qRJYy4Xs4JbvXTozp07towZznH8+HFp0KCBPPXUUyawtS5N1P8QrVu3TqpVqyYNGzY0gcaPP/5ogg0NZvWSi02bNhHYIs50YobPPvtMunXrZs49vfxnzZo15isQG3pJor4/6WXU+h8oi146rf+Junz5srmtE9OQ3AGchbgWcUVsC7sR2yI+Edc6ExW3iJFChQqZQFVnR9Vf1KZNm3rNKqjBrTWzoDWr7oABA0ywoj2eNPBFyqV/ALSqJTw83FQY6Bv+mDFjzPmhn+jlzZvXzEKp/cE0CPnpp5+kdevWpicYwQfii/6nqXfv3mYB4kL7X2rlVN++feXw4cOmt5e+n2n11YQJE2TlypXmP+0AnIm4FnFFbAsnILZFfCCudS4/7Zdg9yCQNFiBqzZB79evn2TNmlVefvllMzmD0lNJg95Dhw5JnTp15Pfffze/4PqJsn7qxy85lJ4fGrzqZYh6SeK3335rKl6s8+jYsWMSHBwsU6dOlV69etk9XACIcsIGrUTQCiv9z7mV0NG/e3qZ2IoVK0wVFgBnIq5FfCG2BZDUEdc6G60SEG1Wjj9fvnxSt25d2bZtm4wfP95c9qOsUnn9mi1bNtPnSe/XT5YJbmEpXry4TJkyRW7evCnz5883fxA0sNXzS6te9A9D+fLlTR85xWdLAJxGZ2/WfobDhw93B7dK+xVqwKsVWNalZACcibgW8YXYFkBSRlzrfCRuEW0adHz55ZdSpkwZ07epatWqpvG59jtZtWqVezv9pdaqhKVLl5rLyOjdhIi0ofmMGTNMBYtWrfz888/mP0Z6yeGHH35oJnKw/lNE7xwATrJv3z6pV6+eqZ4aMWKEWefZ61ID3v79+8vzzz8vn3/+uY0jBfAgxLWIT8S2AJIi4tqkgVYJiLZTp05J/fr1pWfPnu7+OevXrze/yFmyZJFBgwaZ2VJVly5dzCVD+uky8E+Xlunb0OjRo2X16tVmUhBtiO7ZDB0AnHIZmc6gqwkenZxI+xRqlZXSagRrhnmlfxOnTZsm77//voSEhNg4agC+ENciIRDbAkgqiGuTDhK3eCCrv5f+4l69elUeffRRGTVqlPnExbpPP1Fu0qSJ+aRGe4M1b97cfR8QnQBXG6DrJYpa1bJ582aqWQA4zo4dO0xw++abb5pJZf7973+b7/XvYVRBrvYyXLx4sXmfCwoKsnH0ABRxLRIDsS0ApyOuTVpolYAH0iBVfznfeustOXfunAQGBsrJkyfdM+5qIKuXBOkMqnp52VdffSVhYWEEt4hRXzBtel69enX55ZdfCGwBONKNGzekR48epnJKg1idaVf7fi1YsMBdrafrNci1aGXC3r17CW4BhyCuRWIgtgXgdMS1SQsVt/DJqizQWVD1sjC91Ed/sSdNmiQDBw40s6U2bdrUvX3Xrl2ldOnS8txzz0mBAgVsHTuSJu2lo33AACCp/I3UnoULFy6MVKGgCSB/f3+7hwng/yOuhR2IbQEkBcS1zkfiFlFau3atHD9+3HyqojMKpkqVSu7fvy+vv/66TJ8+3cw6mCtXLtMPRRtVa4+U3Llz2z1sAAASjWeQ2759e5MIAuA8xLUAADwYca0zkTZHlJ8Qz5o1S7744gvT+0QDWw1wdZk6daq5BGju3LmmxD59+vTyww8/ENwCAFIcvVysbdu25u9jt27dJG3atKaaD4BzENcCAPDPiGudiYpbREmrEsaMGWMaVWsAqzPrWoGuunTpkvlF1tL5zJkz2z1cAABsoxMdLVmyRGrUqCElSpSwezgAIiCuBQAgeohrnYXELUxPE6V9TbQiQRetNlA6E6rOqLtixQpZs2aNmX3Xml2QGXYBAPgf/i4C9iOuBQAg7vi76Bz/9xEzUjz9hVy+fLmZTVAvIdOy+O+//16yZs1qKhMaN24sDRo0kB07dhDcAgDgA38XAWcgrgUAIG74u+gcJG5TIL0sTIWHh7t/ITWYffbZZ6VgwYLSqlUr+eWXX0wvk8mTJ0umTJnko48+kqefflqqVq1q7uOXGAAAAHYjrgUAAMkZidsUSHt5nThxQh555BE5duyYWTdhwgQZOnSoCWiHDRtmqhQqVapkJnH4z3/+I1myZJHx48dLSEiI+3IzAAAAwE7EtQAAIDkjcZtC6SVht27dktDQULl586bp/+VZuZAzZ04ZOXKkXL9+XZYtW2bW58uXz8zIW7JkSRtHDgAAAPwPcS0AAEiuSNymEBHnoNNgVSdn0N5e3377raRJk0YOHz7sFeRmz57d9P/au3evOwDWPmAAAACAXYhrAQBASkHiNgXQYFV7d+lMuhYNVDXAVTqz7pgxY2TBggUybtw4c8mZLurUqVOmPxiBLQAAAOxGXAsAAFISf7sHgISnweqff/4p1atXl1q1apnLwjJmzCiZM2eWjz/+WGrXri0VK1aUefPmyQsvvGAmadDKhbCwMNMTbPPmze6AFwAAALALcS0AAEhJiFpSUHXC3bt3zeVj7du3N7Pp7tu3T6pVqyavvvqqzJ8/X0qVKiU//fST3LhxwwS558+fl02bNsnDDz9s9/ABAAAAg7gWAACkFH6uiE2ikKyCWq0o0MDW399fpk6dKkePHjWz5168eFF27twpb731lmTLlk06dOggbdq0MRM3aEVChgwZzCQPgYGBdr8MAAAApHDEtQAAICWi4jYZsnLxWmGgNLhVFSpUkAMHDpjLyiZNmmSC2nbt2snGjRslODhYpkyZInv27DHBrUqbNq2NrwIAAAApHXEtAABIyUjcJkM6YcOZM2ekTJky8uabb8qxY8fM+nr16pngVgPbS5cuSa9eveS7774zl5ZpEHzt2jUZOnSo3Lt3z70fAAAAwC7EtQAAICWjVUIydeXKFXMJmVYgVK5cWZ5++ml5/fXXzX2dOnUyX7USQSdyOHv2rPz2228yceJEGT16tJQrV87m0QMAAAD/h7gWAACkVCRukzkNXENDQ2X37t3y0EMPycyZM81lY8uWLZMXX3xRGjZs6N5WTwWqEQAAAOBExLUAACClIXGbAujlY5s3b5Zhw4bJ1atX5V//+pesXr3aVCx8+OGHdg8PAAAAiBbiWgAAkJKQuE1h+vTpI7///rvs3btXTp06JbNmzZIuXbrYPSwAAAAgRohrAQBAckfiNoXwvFxs3bp1smLFCvnggw9k27ZtUqpUKbuHBwAAAEQLcS0AAEgpSNymIBF7felsu0FBQbaOCQAAAIgp4loAAJASkLgFAAAAAAAAAIdJZfcAAAAAAAAAAADeSNwCAAAAAAAAgMOQuAUAAAAAAAAAhyFxCwAAAAAAAAAOQ+IWAAAAAAAAAByGxC0AAAAAAAAAOAyJWwAAAAAAAABwGBK3AJAC7d27V8aNGyf37t2zeygAAABAnBDbAkiuSNwCQDK3bt068fPzkytXrrjXlS1bVjZv3izDhg3z+Zjg4GCZPHlyIo4SAAAA+GfEtgBSEhK3AGCzTp06meCze/fuke7r2bOnuU+3iU+pUqWSBQsWyM8//yzLli2L130DAAAg5SK2BYD4Q+IWABygQIECsnDhQrl586Z73a1bt0wAWrBgwQR5znTp0pngtlmzZgmyfwAAAKRMxLYAED9I3AKAAzzyyCMmwP3666/d6/R7DWwrVarkXhceHi6vvfaa5MqVSwIDA6V27dqyfft2r30tX75cSpQoYYLXxx57TI4ePRrp+TZs2CB16tQx2zz00EOm+uHvv/+Ocnx6KVqXLl0kZ86cEhQUJI8//rj8+uuv8fb6AQAAkHwQ2wJA/CBxCwAO8dJLL8knn3zivj179mwJCQnx2mbAgAHy1VdfyZw5c2TXrl1SrFgxady4sVy6dMncf/z4cWnZsqU8/fTTsnv3bhOQDho0yGsff/75pzRt2lSee+45M5HD4sWLZdu2bfLyyy9HOTbd9ty5c/LDDz/Izp07TTDeoEED9/MCAAAAnohtASDuSNwCgEO8+OKLplrgr7/+MsvGjRvNOktYWJjMmDFDxo8fb4LTMmXKyEcffWQqC/7973+bbfT+okWLysSJE6VkyZLywgsvROohNnr0aGnfvr2pbtDguEaNGjJlyhRzOZs+R0Q6Jg1+NQiuUqWKFC9eXCZMmCBZsmSRL7/8MhGODAAAAJIaYlsAiDv/eNgHACAe6KVa2pPr008/FZfLZb7PkSOHVzXBnTt3pFatWu51adKkkapVq8qBAwfMbf1arVo1r/1q8OpJLwPbsWOHCYQjOnLkiDz88MORtr9+/bpkz57da732LNMxAQAAABER2wJA3JG4BQCHXVLWq1cv8/306dMT5Dk0UB0+fLiMHDky2tvnzZtX1q1bF+k+rUwAAAAAfCG2BYC4oVUCADhIkyZN5Pbt26b6QPt7edLLxAICAsxlZhbdTidw0EvLVOnSpc2lX562bNnidVt7eK1duzbaY9Ltz5w5I/7+/ubyM8/Fs2oCAAAA8ERsCwBxQ+IWABwkderU5pKw3377zXzvKUOGDNKjRw/p37+/rFixwmzTtWtXuXHjhnTu3Nls0717dzl06JDZ5uDBg7JgwQJzeZqngQMHmkkYunXrJr/88ovZfsmSJWZfvjRs2NBcktaiRQtZtWqVmcl306ZN8uabb5rL0gAAAABfiG0BIG5I3AKAwwQFBZnFlzFjxkirVq3MBAxaLXD48GFZuXKlZM2a1dxfsGBBMzOvBqsVKlSQmTNnyrvvvuu1j/Lly8tPP/1kgtS6detKpUqVJDQ0VAoXLuzzOf38/GT58uVmW50JuESJEtK2bVszyUTu3LkT4AgAAAAguSC2BYDY83Npl3AAAAAAAAAAgGNQcQsAAAAAAAAADkPiFgAAAAAAAAAchsQtAAAAAAAAADgMiVsAAAAAAAAAcBgStwAAAAAAAADgMCRuAQAAAAAAAMBhSNwCAAAAAAAAgMOQuAUAAAAAAAAAhyFxCwAAAAAAAAAOQ+IWAAAAAAAAAByGxC0AAAAAAAAAOAyJWwAAAAAAAAAQZ/l/xaohJJQ5lEoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "EXPERIMENT_NAME = \"Approche_Supervisee_Features\"\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "if experiment:\n",
    "    runs_data = client.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        order_by=[\"metrics.f1_micro DESC\"]\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    seen_features = set()  # Pour éviter les doublons\n",
    "    \n",
    "    for run in runs_data:\n",
    "        # Vérifier que le run a f1_micro ET un feature_type\n",
    "        if 'f1_micro' in run.data.metrics and run.data.params.get('feature_type'):\n",
    "            \n",
    "            feature_type = run.data.params.get('feature_type')\n",
    "            \n",
    "            # Éviter les doublons (garder le meilleur de chaque type)\n",
    "            if feature_type in seen_features:\n",
    "                continue\n",
    "            seen_features.add(feature_type)\n",
    "            \n",
    "            # Nettoyage des noms\n",
    "            display_name = feature_type\n",
    "            if feature_type == 'TF-IDF (BoW)':\n",
    "                display_name = 'TF-IDF'\n",
    "            elif feature_type == 'Word2Vec_Mean':\n",
    "                display_name = 'Word2Vec'\n",
    "            \n",
    "            results.append({\n",
    "                'Modèle': display_name,\n",
    "                'F1_Micro': run.data.metrics.get('f1_micro', 0),\n",
    "                'TCTP_Top5': run.data.metrics.get('tctp_top_5', None),  # None si absent\n",
    "                'Temps_Entrainement_sec': run.data.metrics.get('fit_time_sec', 0),\n",
    "            })\n",
    "\n",
    "    if results:\n",
    "        df_results = pd.DataFrame(results).sort_values(by='F1_Micro', ascending=False)\n",
    "        \n",
    "        print(\"\\n Tableau Récapitulatif des Performances :\\n\")\n",
    "        print(df_results.to_markdown(index=False))\n",
    "\n",
    "        # --- Graphique ---\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        sns.barplot(x='Modèle', y='F1_Micro', data=df_results, ax=ax[0], palette=\"Blues_d\")\n",
    "        ax[0].set_title('F1-Score Micro')\n",
    "        ax[0].set_ylabel('F1-Score')\n",
    "        ax[0].set_ylim(0, max(df_results['F1_Micro']) * 1.2)\n",
    "        ax[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        sns.barplot(x='Modèle', y='Temps_Entrainement_sec', data=df_results, ax=ax[1], palette=\"Oranges_d\")\n",
    "        ax[1].set_title('Temps d\\'entraînement')\n",
    "        ax[1].set_ylabel('Secondes')\n",
    "        ax[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        plt.suptitle('Comparaison des Modèles Supervisés', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('comparaison_modeles.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\" Aucun run trouvé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f2f85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: b1343e403d7c4678bf1b0aebc06f7c85\n",
      "   Name: Word2Vec_Mean_LogisticRegression_V100_TCTP_Fix\n",
      "   F1: 0.3082070299903257\n",
      "\n",
      "Run ID: 41a8478233024a54863b6a011cc30255\n",
      "   Name: Word2Vec_Mean_LogisticRegression_V100\n",
      "   F1: N/A\n",
      "\n",
      "Run ID: 9f2a69b11b1c46bf81d07b7e3aa25219\n",
      "   Name: Word2Vec_Mean_LogisticRegression_V100\n",
      "   F1: N/A\n",
      "\n",
      "Run ID: adab6eead21748aabef90e9232bee797\n",
      "   Name: Word2Vec_Mean_LogisticRegression_V100\n",
      "   F1: 0.30660586739841006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(\"Approche_Supervisee_Features\")\n",
    "\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    filter_string=\"params.feature_type = 'Word2Vec_Mean'\",\n",
    ")\n",
    "\n",
    "for run in runs:\n",
    "    print(f\"Run ID: {run.info.run_id}\")\n",
    "    print(f\"   Name: {run.info.run_name}\")\n",
    "    print(f\"   F1: {run.data.metrics.get('f1_micro', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb9a26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2186e7a463d4e28a2ff02ea714aefca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5696039b1c7a41e089176d27e1362d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features attendues : 100\n"
     ]
    }
   ],
   "source": [
    "run_id = \"b1343e403d7c4678bf1b0aebc06f7c85\"\n",
    "\n",
    "model_uri = f\"runs:/{run_id}/w2v_classifier\"\n",
    "classifier_w2v = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# Vérifie que c'est bien 100 features\n",
    "print(f\"Features attendues : {classifier_w2v.estimators_[0].coef_.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146dd897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bon modèle sauvegardé !\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(classifier_w2v, 'stackoverflow-tags-api/models/w2v_classifier.pkl')\n",
    "print(\" Bon modèle sauvegardé !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f433fd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "\n",
      "Nombre total de tags : 396\n",
      "\n",
      "Exemples de tags disponibles :\n",
      "['.htaccess', '.net', '.net-2.0', '.net-3.5', '64-bit', 'actionscript', 'actionscript-3', 'active-directory', 'activerecord', 'ado.net', 'air', 'ajax', 'algorithm', 'amazon-ec2', 'amazon-web-services', 'android', 'android-activity', 'android-intent', 'android-layout', 'animation', 'ant', 'apache', 'apache-flex', 'architecture', 'arraylist', 'arrays', 'asp-classic', 'asp.net', 'asp.net-mvc', 'asp.net-mvc-3', 'assembly', 'asynchronous', 'audio', 'authentication', 'automation', 'azure', 'backbone.js', 'background', 'bash', 'batch-file', 'binding', 'blackberry', 'boost', 'browser', 'build', 'button', 'c', 'c#', 'c#-4.0', 'c++']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "mlb = joblib.load('stackoverflow-tags-api/models/mlb.pkl')\n",
    "\n",
    "# Vérifie les tags disponibles\n",
    "print(\"pandas\" in mlb.classes_)\n",
    "print(\"pip\" in mlb.classes_)\n",
    "print(\"installation\" in mlb.classes_)\n",
    "\n",
    "# Pour voir tous les tags disponibles\n",
    "print(f\"\\nNombre total de tags : {len(mlb.classes_)}\")\n",
    "print(\"\\nExemples de tags disponibles :\")\n",
    "print(list(mlb.classes_[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56ceb2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"pandas\" in mlb.classes_)\n",
    "print(\"pip\" in mlb.classes_)\n",
    "print(\"installation\" in mlb.classes_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

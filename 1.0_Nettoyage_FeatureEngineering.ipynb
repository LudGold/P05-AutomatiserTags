{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b280b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MISE EN PLACE DES BIBLIOTHEQUES\n",
    "# ===============================================\n",
    "# IMPORTS STANDARD ET DE BASE\n",
    "# ===============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "# ===============================================\n",
    "# IMPORTS VISUALISATION ET API EXTERNE\n",
    "# ===============================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from stackapi import StackAPI \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ===============================================\n",
    "# IMPORTS MLOPS ET TRACKING\n",
    "# ===============================================\n",
    "import mlflow\n",
    "from mlflow.exceptions import MlflowException\n",
    "# from mlflow.tracking import MlflowClient # Peut être ajouté si nécessaire pour la fin du projet\n",
    "\n",
    "# ===============================================\n",
    "# IMPORTS NLP ET PRÉTRAITEMENT\n",
    "# ===============================================\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "# Téléchargements NLTK (à laisser en début de notebook)\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "# ===============================================\n",
    "# IMPORTS SCIKIT-LEARN\n",
    "# ===============================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # <-- AJOUT CRUCIAL MANQUANT !\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, hamming_loss\n",
    "\n",
    "# ===============================================\n",
    "# IMPORTS EMBEDDINGS (GENSIM, HUGGING FACE, TF-HUB)\n",
    "# ===============================================\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fb21d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MLFlow Tracking URI configuré : file:///C:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuration MLFlow - définir le chemin de tracking\n",
    "mlflow.set_tracking_uri(\"file:///C:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns\")\n",
    "print(f\" MLFlow Tracking URI configuré : {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa4218",
   "metadata": {},
   "source": [
    "# test  qualité API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c155314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recherche de 50 questions avec le tag 'python' et un score > 8 sur les 90 derniers jours...\n",
      "\n",
      "--- Résultat du Test API ---\n",
      "Questions récupérées : 56/50 (Succès de l'appel).\n",
      "         date_creation                                              titre  \\\n",
      "0  2025-01-09 22:04:59      How to add requirements.txt to uv environment   \n",
      "1  2024-12-18 12:45:52  &#39;super&#39; object has no attribute &#39;_...   \n",
      "2  2025-01-13 16:24:07  How/why are {2,3,10} and {x,3,10} with x=2 ord...   \n",
      "3  2025-08-02 18:59:55  How to set up a simple hello-world example whe...   \n",
      "4  2025-04-02 11:41:54  import numpy failed after upgrading MacOS to 15.4   \n",
      "\n",
      "                                              tags  score body_snippet  \n",
      "0                          python, python-venv, uv     48       N/A...  \n",
      "1  python, machine-learning, scikit-learn, xgboost     32       N/A...  \n",
      "2                python, cpython, python-internals     21       N/A...  \n",
      "3                    python, c, python-3.x, cython     20       N/A...  \n",
      "4                             python, macos, numpy     18       N/A...  \n"
     ]
    }
   ],
   "source": [
    "# --- Critères de la Requête ---\n",
    "TAG = 'python'\n",
    "MIN_SCORE = 8\n",
    "PAGE_SIZE = 50 # Le maximum par requête non authentifiée\n",
    "\n",
    "# Période définie : Nous prenons les 3 derniers mois comme exemple de \"période définie\"\n",
    "to_date = int(time.time()) # Aujourd'hui (timestamp UNIX)\n",
    "from_date = int((datetime.now() - timedelta(days=365)).timestamp()) # Il y a 90 jours\n",
    "\n",
    "# 1. Initialiser le client de l'API pour Stack Overflow\n",
    "SITE = StackAPI('stackoverflow')\n",
    "\n",
    "# 2. Effectuer la requête\n",
    "print(f\"Recherche de {PAGE_SIZE} questions avec le tag '{TAG}' et un score > {MIN_SCORE} sur les 90 derniers jours...\")\n",
    "\n",
    "try:\n",
    "    # La méthode fetch utilise l'endpoint 'questions' par défaut\n",
    "    questions_data = SITE.fetch(\n",
    "        'questions', \n",
    "        pagesize=PAGE_SIZE, \n",
    "        tagged=TAG, \n",
    "        sort='votes',   # Trier par votes pour appliquer le filtre 'min'\n",
    "        min=MIN_SCORE,  # Filtrer sur le score minimal (votes)\n",
    "        fromdate=from_date, \n",
    "        todate=to_date,\n",
    "\n",
    "    )\n",
    "\n",
    "    # 3. Préparer les données pour le DataFrame\n",
    "    data_list = []\n",
    "    items = questions_data.get('items', [])\n",
    "    \n",
    "    for q in items:\n",
    "                # Nous ne prenons que les données nécessaires (RGPD)\n",
    "        data_list.append({\n",
    "            'date_creation': datetime.fromtimestamp(q['creation_date']).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'titre': q['title'],\n",
    "            'tags': \", \".join(q['tags']) if 'tags' in q else 'N/A',\n",
    "            'score': q['score'],\n",
    "            'body_snippet': q.get('body', 'N/A')[:100] + '...' \n",
    "        })\n",
    "\n",
    "    # 4. Afficher le DataFrame\n",
    "    df_api_test = pd.DataFrame(data_list)\n",
    "    print(f\"\\n--- Résultat du Test API ---\")\n",
    "    print(f\"Questions récupérées : {len(df_api_test)}/{PAGE_SIZE} (Succès de l'appel).\")\n",
    "    print(df_api_test.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nErreur lors de l'appel à l'API : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6afe2e",
   "metadata": {},
   "source": [
    "# Préparation et Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d07e799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame d'entraînement chargé avec succès.\n",
      "\n",
      "Nettoyage du HTML en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lza\\AppData\\Local\\Temp\\ipykernel_22864\\842519030.py:20: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  soup = BeautifulSoup(text, 'html.parser')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu du texte nettoyé :\n",
      "Paging a collection with LINQ  How do you page through a collection in LINQ given that you have a  startIndex  and a  count ?  \n"
     ]
    }
   ],
   "source": [
    "# Simulation du chargement du fichier CSV des 50 000 questions\n",
    "try:\n",
    "    df_train = pd.read_csv('./data/stack_overflow_brut.csv', encoding='utf-8')\n",
    "    # On va créer une colonne de texte combiné pour l'analyse\n",
    "    df_train['Text_Raw'] = df_train['Title'] + \" \" + df_train['Body']\n",
    "    print(\"DataFrame d'entraînement chargé avec succès.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Erreur : Fichier d'entraînement 50k non trouvé. Passez à la simulation.\")\n",
    "\n",
    "# --- Fonctions de Nettoyage ---\n",
    "\n",
    "def clean_html_and_code(text):\n",
    "    \"\"\"\n",
    "    Supprime les balises HTML et extrait le texte brut.\n",
    "    Ceci est VITAL car le 'Body' Stack Overflow est en HTML.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Utilise BeautifulSoup pour parser et extraire le texte\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    cleaned_text = soup.get_text(separator=' ')\n",
    "    \n",
    "    # Optionnel : Remplacer les retours à la ligne par des espaces\n",
    "    cleaned_text = re.sub('\\n', ' ', cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Application de la première étape de nettoyage\n",
    "print(\"\\nNettoyage du HTML en cours...\")\n",
    "df_train['Text_Cleaned'] = df_train['Text_Raw'].apply(clean_html_and_code)\n",
    "\n",
    "# Affichage des 5 premières lignes pour valider le nettoyage\n",
    "print(\"Aperçu du texte nettoyé :\")\n",
    "print(df_train[['Text_Raw', 'Text_Cleaned']].head(1)['Text_Cleaned'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b657dad0",
   "metadata": {},
   "source": [
    "# Nettoyage linguistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac1916c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Vérification du Pipeline de Nettoyage ---\n",
      "                                        Text_Cleaned  \\\n",
      "0  Paging a collection with LINQ  How do you page...   \n",
      "1  How do I add existing comments to RDoc in Ruby...   \n",
      "\n",
      "                                          Tokens_LDA  \\\n",
      "0  paging collection linq how page collection lin...   \n",
      "1  how add existing comment rdoc ruby want format...   \n",
      "\n",
      "                                           Tokens_DL  \n",
      "0  paging a collection with linq how do you page ...  \n",
      "1  how do i add existing comments to rdoc in ruby...  \n"
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "def tokenizer_fct(sentence) :\n",
    "    # print(sentence)\n",
    "    sentence_clean = sentence.replace('-', ' ').replace('+', ' ').replace('/', ' ').replace('#', ' ')\n",
    "    word_tokens = word_tokenize(sentence_clean)\n",
    "    return word_tokens\n",
    "\n",
    "# Stop words\n",
    "\n",
    "stop_w = list(set(stopwords.words('english'))) + ['[', ']', ',', '.', ':', '?', '(', ')']\n",
    "\n",
    "def stop_word_filter_fct(list_words) :\n",
    "    filtered_w = [w for w in list_words if not w in stop_w]\n",
    "    filtered_w2 = [w for w in filtered_w if len(w) > 2]\n",
    "    return filtered_w2\n",
    "\n",
    "# lower case et alpha\n",
    "def lower_start_fct(list_words) :\n",
    "    lw = [w.lower() for w in list_words if (not w.startswith(\"@\")) \n",
    "    #                                   and (not w.startswith(\"#\"))\n",
    "                                       and (not w.startswith(\"http\"))]\n",
    "    return lw\n",
    "\n",
    "# Lemmatizer (base d'un mot)\n",
    "def lemma_fct(list_words) :\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_w = [lemmatizer.lemmatize(w) for w in list_words]\n",
    "    return lem_w\n",
    "\n",
    "# Fonction de préparation du texte pour le bag of words (Countvectorizer et Tf_idf, Word2Vec)\n",
    "def transform_bow_fct(desc_text) :\n",
    "    word_tokens = tokenizer_fct(desc_text)\n",
    "    sw = stop_word_filter_fct(word_tokens)\n",
    "    lw = lower_start_fct(sw)\n",
    "    # lem_w = lemma_fct(lw)    \n",
    "    transf_desc_text = ' '.join(lw)\n",
    "    return transf_desc_text\n",
    "\n",
    "# Fonction de préparation du texte pour le bag of words avec lemmatization\n",
    "def transform_bow_lem_fct(desc_text) :\n",
    "    word_tokens = tokenizer_fct(desc_text)\n",
    "    sw = stop_word_filter_fct(word_tokens)\n",
    "    lw = lower_start_fct(sw)\n",
    "    lem_w = lemma_fct(lw)    \n",
    "    transf_desc_text = ' '.join(lem_w)\n",
    "    return transf_desc_text\n",
    "\n",
    "# Fonction de préparation du texte pour le Deep learning (USE et BERT)\n",
    "def transform_dl_fct(desc_text) :\n",
    "    word_tokens = tokenizer_fct(desc_text)\n",
    "#    sw = stop_word_filter_fct(word_tokens)\n",
    "    lw = lower_start_fct(word_tokens)\n",
    "    # lem_w = lemma_fct(lw)    \n",
    "    transf_desc_text = ' '.join(lw)\n",
    "    return transf_desc_text\n",
    "\n",
    "# Assurez-vous que votre colonne 'Text_Cleaned' est bien le texte sans HTML\n",
    "\n",
    "# 1. Création de la colonne pour LDA / Bag-of-Words (avec lemmatisation)\n",
    "# C'est la préparation la plus complète et la plus efficace pour les méthodes classiques\n",
    "df_train['Tokens_LDA'] = df_train['Text_Cleaned'].apply(lambda x : transform_bow_lem_fct(x))\n",
    "\n",
    "# 2. Création de la colonne pour le Deep Learning (sans lemmatisation ni stop words)\n",
    "# Les modèles comme BERT et USE préfèrent garder le contexte intact\n",
    "df_train['Tokens_DL'] = df_train['Text_Cleaned'].apply(lambda x : transform_dl_fct(x))\n",
    "\n",
    "# Affichage pour la validation\n",
    "print(\"--- Vérification du Pipeline de Nettoyage ---\")\n",
    "print(df_train[['Text_Cleaned', 'Tokens_LDA', 'Tokens_DL']].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69047561",
   "metadata": {},
   "source": [
    "# Création du dictionnaire et du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8ad8fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage de la création du Dictionnaire et du Corpus...\n",
      "\n",
      "--- Préparation du Corpus LDA Terminé ---\n",
      "Taille du vocabulaire final : 24054 mots\n",
      "Nombre de documents analysés : 50000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Note : Votre fonction transform_bow_lem_fct retourne une CHAÎNE de caractères.\n",
    "# Gensim a besoin d'une LISTE de listes de mots. Nous utilisons .apply(str.split) \n",
    "# pour convertir chaque chaîne en liste de mots.\n",
    "print(\"Démarrage de la création du Dictionnaire et du Corpus...\")\n",
    "\n",
    "# 1. Création du Dictionnaire\n",
    "# Cette ligne identifie et numérote tous les mots uniques (le vocabulaire)\n",
    "dictionary = corpora.Dictionary(df_train['Tokens_LDA'].apply(str.split))\n",
    "\n",
    "# 2. Filtrage des Extrêmes (Crucial pour le bruit)\n",
    "# On garde un vocabulaire pertinent pour le modèle (mots ni trop rares, ni trop fréquents)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5) \n",
    "\n",
    "# 3. Création du Corpus (Format Bag-of-Words)\n",
    "# Chaque document est transformé en une liste de (id_mot, fréquence)\n",
    "corpus = [dictionary.doc2bow(tokens.split()) for tokens in df_train['Tokens_LDA']]\n",
    "\n",
    "print(f\"\\n--- Préparation du Corpus LDA Terminé ---\")\n",
    "#topic modeling\n",
    "print(f\"Taille du vocabulaire final : {len(dictionary)} mots\")\n",
    "print(f\"Nombre de documents analysés : {len(corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb39cc",
   "metadata": {},
   "source": [
    "# Lancement du LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cada6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Démarrage de l'entraînement LDA avec 10 thèmes ---\n",
      "\n",
      "Suggestions de Tags (Mots-Clés par Thème, Coherence: 0.5785) :\n",
      "Thème 1: 0.061*\"public\" + 0.044*\"new\" + 0.043*\"int\" + 0.042*\"string\" + 0.034*\"android\"\n",
      "Thème 2: 0.033*\"image\" + 0.024*\"event\" + 0.018*\"item\" + 0.018*\"button\" + 0.017*\"new\"\n",
      "Thème 3: 0.014*\"n't\" + 0.013*\"would\" + 0.013*\"like\" + 0.012*\"way\" + 0.012*\"using\"\n",
      "Thème 4: 0.025*\"value\" + 0.024*\"string\" + 0.020*\"array\" + 0.015*\"list\" + 0.012*\"number\"\n",
      "Thème 5: 0.042*\"file\" + 0.022*\"error\" + 0.020*\"server\" + 0.009*\"project\" + 0.009*\"using\"\n",
      "Thème 6: 0.023*\"class\" + 0.019*\"object\" + 0.015*\"function\" + 0.015*\"method\" + 0.014*\"code\"\n",
      "Thème 7: 0.036*\"table\" + 0.025*\"database\" + 0.021*\"query\" + 0.019*\"select\" + 0.018*\"sql\"\n",
      "Thème 8: 0.027*\"page\" + 0.025*\"view\" + 0.014*\"url\" + 0.012*\"form\" + 0.011*\"model\"\n",
      "Thème 9: 0.056*\"user\" + 0.030*\"2012\" + 0.029*\"lib\" + 0.028*\"gem\" + 0.026*\"ruby\"\n",
      "Thème 10: 0.037*\"div\" + 0.022*\"function\" + 0.021*\"class=\" + 0.020*\"text\" + 0.018*\"id=\"\n",
      "\n",
      "Run MLFlow ID : 6720c83c396f4ce6945a607a48fda422\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Définition de l'Expérience MLFlow\n",
    "EXPERIMENT_NAME = \"Approche_Non_Supervisee_LDA\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# --- Hyperparamètres ---\n",
    "NUM_TOPICS = 10 \n",
    "PASSES = 15 # Nombre d'itérations, impacte le temps de calcul\n",
    "\n",
    "print(f\"\\n--- Démarrage de l'entraînement LDA avec {NUM_TOPICS} thèmes ---\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"LDA_Topics_{NUM_TOPICS}_V1\") as run:\n",
    "    \n",
    "    # 1. Enregistrement des paramètres dans MLFlow\n",
    "    mlflow.log_param(\"num_topics\", NUM_TOPICS)\n",
    "    mlflow.log_param(\"pass_iterations\", PASSES)\n",
    "    mlflow.log_param(\"model\", \"LDA\")\n",
    "    mlflow.log_param(\"dataset\", \"df_train\")\n",
    "    \n",
    "    # 2. Entraînement du modèle\n",
    "    lda_model = LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=NUM_TOPICS,\n",
    "        random_state=42, \n",
    "        passes=PASSES \n",
    "    )\n",
    "\n",
    "    # 3. Évaluation (Coherence Score - Mesure de la qualité des thèmes)\n",
    "    coherence_model_lda = CoherenceModel(\n",
    "        model=lda_model, \n",
    "        texts=df_train['Tokens_LDA'].apply(str.split), # Utilisation des tokens pour la cohérence\n",
    "        dictionary=dictionary, \n",
    "        coherence='c_v'\n",
    "    )\n",
    "    coherence_score = coherence_model_lda.get_coherence()\n",
    "    mlflow.log_metric(\"coherence_score\", coherence_score) # La métrique est envoyée à MLFlow\n",
    "    \n",
    "    # 4. Affichage des 5 meilleurs mots-clés (suggestions de tags)\n",
    "    print(f\"\\nSuggestions de Tags (Mots-Clés par Thème, Coherence: {coherence_score:.4f}) :\")\n",
    "    for idx, topic in lda_model.print_topics(-1, num_words=5):\n",
    "        print(f\"Thème {idx+1}: {topic}\")\n",
    "\n",
    "    print(f\"\\nRun MLFlow ID : {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94f135b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre total de tags: 10974. Nombre de tags fréquents retenus: 396.\n",
      "Forme de la matrice des étiquettes Y (Questions x Tags): (50000, 396)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Extraction des Tags de la chaîne HTML (<tag1><tag2>...)\n",
    "def extract_tags(tags_str):\n",
    "    \"\"\"Extrait la liste de tags à partir de la chaîne HTML.\"\"\"\n",
    "    if not isinstance(tags_str, str):\n",
    "        return []\n",
    "    # On retire les chevrons et on split par le séparateur '><'\n",
    "    return [tag.strip() for tag in tags_str.strip('<>').split('><') if tag.strip()]\n",
    "\n",
    "df_train['Tags_List'] = df_train['Tags'].apply(extract_tags)\n",
    "\n",
    "# 2. Filtrage des Tags Rares (Essentiel pour la classification Multi-label)\n",
    "# On ne peut pas classifier des milliers de tags qui apparaissent une seule fois.\n",
    "all_tags = list(itertools.chain.from_iterable(df_train['Tags_List']))\n",
    "tags_counts = pd.Series(all_tags).value_counts()\n",
    "\n",
    "# Nous gardons uniquement les tags qui apparaissent au moins 50 fois\n",
    "TAG_MIN_COUNT = 50 \n",
    "frequent_tags = tags_counts[tags_counts >= TAG_MIN_COUNT].index.tolist()\n",
    "print(f\"\\nNombre total de tags: {len(tags_counts)}. Nombre de tags fréquents retenus: {len(frequent_tags)}.\")\n",
    "\n",
    "# 3. Filtrer les listes de Tags pour ne garder que les tags fréquents\n",
    "df_train['Tags_Filtered'] = df_train['Tags_List'].apply(\n",
    "    lambda tags: [tag for tag in tags if tag in frequent_tags]\n",
    ")\n",
    "\n",
    "# 4. Création du MultiLabelBinarizer (Matrice Y)\n",
    "mlb = MultiLabelBinarizer()\n",
    "# Y_labels est votre matrice d'étiquettes binaire (0 ou 1 pour chaque tag)\n",
    "Y_labels = mlb.fit_transform(df_train['Tags_Filtered']) \n",
    "label_names = mlb.classes_ # Nom des colonnes de Y\n",
    "\n",
    "print(f\"Forme de la matrice des étiquettes Y (Questions x Tags): {Y_labels.shape}\")\n",
    "#la matrice des cibles Y est prête"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99f0b6",
   "metadata": {},
   "source": [
    "# Modélisation Supervisée : approche Bag-of-Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c54bd773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du jeu d'entraînement (X_train) : 37565 questions\n",
      "Taille du jeu de test (X_test) : 9392 questions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# X = Texte propre pour le BoW (chaîne de caractères)\n",
    "X = df_train['Tokens_LDA']\n",
    "# Y = Matrice des labels (MultiLabelBinarizer)\n",
    "# Y_labels a été créé à l'étape précédente\n",
    "# Nous devons nous assurer que les données sans tags fréquents sont exclues\n",
    "X = X[df_train['Tags_Filtered'].apply(lambda x: len(x) > 0)]\n",
    "Y = Y_labels[df_train['Tags_Filtered'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# Séparation des données : 80% Entraînement, 20% Test\n",
    "# La variable 'stratify' n'est pas utilisée pour la multi-label classification par défaut de sklearn\n",
    "# Nous gardons un random_state pour la reproductibilité\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Taille du jeu d'entraînement (X_train) : {X_train.shape[0]} questions\")\n",
    "print(f\"Taille du jeu de test (X_test) : {X_test.shape[0]} questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae85d593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de la matrice TF-IDF d'entraînement (Questions x Features) : (37565, 20000)\n",
      "Forme de la matrice TF-IDF de test : (9392, 20000)\n"
     ]
    }
   ],
   "source": [
    "# Nous allons transformer le texte de $X$ en une matrice de nombres (la matrice TF-IDF).\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. Initialisation du TfidfVectorizer\n",
    "# max_features = 20000 : On limite le vocabulaire à 20 000 mots les plus fréquents pour réduire la dimension et le bruit\n",
    "vectorizer = TfidfVectorizer(max_features=20000)\n",
    "\n",
    "# 2. Entraînement du Vectorizer sur les données d'ENTRAÎNEMENT SEULEMENT\n",
    "X_train_features = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# 3. Transformation des données de TEST\n",
    "# Le Vectorizer entraîné est appliqué aux données de test\n",
    "X_test_features = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Forme de la matrice TF-IDF d'entraînement (Questions x Features) : {X_train_features.shape}\")\n",
    "print(f\"Forme de la matrice TF-IDF de test : {X_test_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943bd9a",
   "metadata": {},
   "source": [
    "Entraînement du Classifieur et Tracking MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17adfdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'expérience MLFlow active est maintenant : Approche_Supervisee_Features (existante)\n"
     ]
    }
   ],
   "source": [
    "from mlflow.exceptions import MlflowException\n",
    "\n",
    "EXPERIMENT_NAME = \"Approche_Supervisee_Features\"\n",
    "\n",
    "try:\n",
    "    # 1. Tente de définir l'expérience comme active. \n",
    "    # Si elle existe, cela fonctionne. Si elle n'existe pas, cela lève une MlflowException.\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    print(f\"L'expérience MLFlow active est maintenant : {EXPERIMENT_NAME} (existante)\")\n",
    "\n",
    "except MlflowException:\n",
    "    # 2. Si set_experiment échoue (car l'expérience n'existe pas), on la crée.\n",
    "    mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "    \n",
    "    # On la définit ensuite comme active.\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    print(f\"Nouvelle expérience créée et activée : {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb48b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Démarrage de l'entraînement LogisticRegression avec TF-IDF (BoW) ---\n",
      "F1-Score Micro (Baseline) : 0.1066\n",
      "Hamming Loss : 0.0049\n",
      "\n",
      "Run MLFlow ID : 7ecdccfb5cad4f0fbd0cf4869ce8ca84\n"
     ]
    }
   ],
   "source": [
    "# --- Hyperparamètres ---\n",
    "MODEL_NAME = \"LogisticRegression\"\n",
    "C_PARAM = 0.1 # Paramètre de régularisation pour LogReg\n",
    "FEATURE_TYPE = \"TF-IDF (BoW)\"\n",
    "\n",
    "print(f\"\\n--- Démarrage de l'entraînement {MODEL_NAME} avec {FEATURE_TYPE} ---\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"{FEATURE_TYPE}_{MODEL_NAME}_C{C_PARAM}\") as run:\n",
    "    \n",
    "    # 1. Enregistrement des paramètres\n",
    "    params = {\n",
    "        \"model\": MODEL_NAME, \n",
    "        \"feature_type\": FEATURE_TYPE,\n",
    "        \"C_param\": C_PARAM,\n",
    "        \"max_features_tfidf\": 20000\n",
    "    }\n",
    "    mlflow.log_params(params) # On passe le dictionnaire complet\n",
    "    # 2. Définition et Entraînement du modèle\n",
    "    classifier = OneVsRestClassifier(LogisticRegression(C=C_PARAM, solver='liblinear', random_state=42))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    classifier.fit(X_train_features, Y_train)\n",
    "    fit_time = time.time() - start_time\n",
    "    \n",
    "    # 3. Prédiction sur le jeu de test\n",
    "    Y_pred = classifier.predict(X_test_features)\n",
    "    \n",
    "    # 4. Calcul et enregistrement des métriques\n",
    "    # F1-score est souvent la métrique clé en classification multi-label\n",
    "    f1_micro = f1_score(Y_test, Y_pred, average='micro')\n",
    "    precision_micro = precision_score(Y_test, Y_pred, average='micro')\n",
    "    recall_micro = recall_score(Y_test, Y_pred, average='micro')\n",
    "    \n",
    "    # La Hamming Loss est une bonne mesure : c'est le pourcentage de labels mal prédits\n",
    "    h_loss = hamming_loss(Y_test, Y_pred)\n",
    "    mlflow.sklearn.log_model(sk_model=classifier, name=\"TF-IDF\")\n",
    "    mlflow.log_metric(\"f1_micro\", f1_micro)\n",
    "    mlflow.log_metric(\"precision_micro\", precision_micro)\n",
    "    mlflow.log_metric(\"recall_micro\", recall_micro)\n",
    "    mlflow.log_metric(\"hamming_loss\", h_loss)\n",
    "    mlflow.log_metric(\"fit_time_sec\", fit_time)\n",
    "\n",
    "    print(f\"F1-Score Micro (Baseline) : {f1_micro:.4f}\")\n",
    "    print(f\"Hamming Loss : {h_loss:.4f}\")\n",
    "    print(f\"\\nRun MLFlow ID : {run.info.run_id}\")\n",
    "    \n",
    "    # Vous pouvez maintenant comparer ce score avec l'approche non supervisée (LDA) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78be851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemin de travail actuel du Notebook : \n",
      "c:\\Users\\lza\\Documents\\P05_Projet_tags_StackOverflow\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Affiche le chemin complet du dossier où votre Notebook est exécuté\n",
    "notebook_path = os.getcwd() \n",
    "print(f\"Chemin de travail actuel du Notebook : \\n{notebook_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbce336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modèle Word2Vec entraîné. Taille des vecteurs : 100\n"
     ]
    }
   ],
   "source": [
    "# 1. Préparation des données pour Word2Vec\n",
    "# Word2Vec nécessite une liste de listes de mots (tokens)\n",
    "# df_train['Tokens_LDA'] est actuellement une chaîne, nous devons la séparer en listes de tokens.\n",
    "X_train_tokens = X_train.apply(str.split).tolist()\n",
    "X_test_tokens = X_test.apply(str.split).tolist()\n",
    "\n",
    "# 2. Entraînement du Modèle Word2Vec\n",
    "# Paramètres courants : \n",
    "# vector_size (dimension de l'embedding), window (taille du contexte), min_count (fréquence minimale)\n",
    "VECTOR_SIZE = 100 \n",
    "WINDOW = 5\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=X_train_tokens, # Entraîné uniquement sur le jeu d'entraînement\n",
    "    vector_size=VECTOR_SIZE, \n",
    "    window=WINDOW, \n",
    "    min_count=5, # Ignore les mots qui apparaissent moins de 5 fois\n",
    "    sg=0, # 0=CBOW (plus rapide), 1=Skip-Gram\n",
    "    workers=4 # Utilise 4 cœurs (ajustez selon votre machine)\n",
    ")\n",
    "w2v_model.train(X_train_tokens, total_examples=len(X_train_tokens), epochs=10)\n",
    "\n",
    "print(f\"\\nModèle Word2Vec entraîné. Taille des vecteurs : {VECTOR_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd6670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de la matrice Word2Vec d'entraînement : (37565, 100)\n"
     ]
    }
   ],
   "source": [
    "def document_vector_fct(word2vec_model, doc_tokens):\n",
    "    \"\"\"Calcule le vecteur d'un document en faisant la moyenne des vecteurs de ses mots.\"\"\"\n",
    "    \n",
    "    # On filtre les mots pour ne garder que ceux qui sont dans le vocabulaire de Word2Vec\n",
    "    words = [word for word in doc_tokens if word in word2vec_model.wv]\n",
    "    \n",
    "    if not words:\n",
    "        # Si la question est vide après filtrage, on retourne un vecteur de zéros\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    \n",
    "    # Retourne la moyenne des vecteurs des mots valides\n",
    "    return np.mean(word2vec_model.wv[words], axis=0)\n",
    "\n",
    "# 1. Création des Features d'Entraînement (X_train)\n",
    "X_train_w2v = np.array([document_vector_fct(w2v_model, tokens) for tokens in X_train_tokens])\n",
    "\n",
    "# 2. Création des Features de Test (X_test)\n",
    "X_test_w2v = np.array([document_vector_fct(w2v_model, tokens) for tokens in X_test_tokens])\n",
    "\n",
    "print(f\"Forme de la matrice Word2Vec d'entraînement : {X_train_w2v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1af846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Démarrage de l'entraînement LogisticRegression avec Word2Vec_Mean ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/27 15:37:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score Micro (Word2Vec) : 0.3066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/27 15:37:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run MLFlow ID : adab6eead21748aabef90e9232bee797\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EXPERIMENT_NAME = \"Approche_Supervisee_Features\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# --- Hyperparamètres ---\n",
    "MODEL_NAME = \"LogisticRegression\"\n",
    "C_PARAM = 0.1\n",
    "FEATURE_TYPE = \"Word2Vec_Mean\"\n",
    "\n",
    "print(f\"\\n--- Démarrage de l'entraînement {MODEL_NAME} avec {FEATURE_TYPE} ---\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"{FEATURE_TYPE}_{MODEL_NAME}_V{VECTOR_SIZE}\") as run:\n",
    "    \n",
    "    # 1. Enregistrement des paramètres spécifiques à Word2Vec\n",
    "    mlflow.log_param(\"model\", MODEL_NAME)\n",
    "    mlflow.log_param(\"feature_type\", FEATURE_TYPE)\n",
    "    mlflow.log_param(\"w2v_vector_size\", VECTOR_SIZE)\n",
    "    mlflow.log_param(\"w2v_window\", WINDOW)\n",
    "    mlflow.log_param(\"C_param\", C_PARAM)\n",
    "\n",
    "    # 2. Définition et Entraînement\n",
    "    classifier = OneVsRestClassifier(LogisticRegression(C=C_PARAM, solver='liblinear', random_state=42))\n",
    "    start_time = time.time()\n",
    "    classifier.fit(X_train_w2v, Y_train)\n",
    "    fit_time = time.time() - start_time\n",
    "    \n",
    "    # 3. Prédiction et Métriques\n",
    "    Y_pred_w2v = classifier.predict(X_test_w2v)\n",
    "    f1_micro = f1_score(Y_test, Y_pred_w2v, average='micro')\n",
    "    \n",
    "    mlflow.log_metric(\"f1_micro\", f1_micro)\n",
    "    mlflow.log_metric(\"fit_time_sec\", fit_time)\n",
    "    \n",
    "    print(f\"F1-Score Micro (Word2Vec) : {f1_micro:.4f}\")\n",
    "    \n",
    "    # 4. Sauvegarde du modèle dans MLFlow (Artefact)\n",
    "    mlflow.sklearn.log_model(sk_model=classifier, name=\"w2v_classifier\")\n",
    "\n",
    "    print(f\"\\nRun MLFlow ID : {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891530e5",
   "metadata": {},
   "source": [
    "# Approches Deap Learning BERT et USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f4a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chargement des embeddings BERT sauvegardés...\n",
      " Embeddings BERT chargés avec succès!\n",
      "   - Forme des features BERT (train) : (37565, 768)\n",
      "   - Forme des features BERT (test) : (9392, 768)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Choix du modèle (Bert de base, non entraîné sur Twitter)\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "MAX_LENGTH = 128 # Longueur maximale des séquences à traiter\n",
    "BATCH_SIZE = 64 # Taille du lot pour accélérer le traitement (ajuster selon votre GPU/RAM)\n",
    "\n",
    "# Dossier pour sauvegarder les embeddings BERT\n",
    "BERT_EMBEDDINGS_DIR = './data/bert_embeddings'\n",
    "os.makedirs(BERT_EMBEDDINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Chemins des fichiers de sauvegarde\n",
    "BERT_TRAIN_PATH = os.path.join(BERT_EMBEDDINGS_DIR, 'X_train_bert.npy')\n",
    "BERT_TEST_PATH = os.path.join(BERT_EMBEDDINGS_DIR, 'X_test_bert.npy')\n",
    "\n",
    "# Vérifier si les embeddings BERT existent déjà\n",
    "if os.path.exists(BERT_TRAIN_PATH) and os.path.exists(BERT_TEST_PATH):\n",
    "    print(\" Chargement des embeddings BERT sauvegardés...\")\n",
    "    X_train_bert = np.load(BERT_TRAIN_PATH)\n",
    "    X_test_bert = np.load(BERT_TEST_PATH)\n",
    "    print(f\" Embeddings BERT chargés avec succès!\")\n",
    "    print(f\"   - Forme des features BERT (train) : {X_train_bert.shape}\")\n",
    "    print(f\"   - Forme des features BERT (test) : {X_test_bert.shape}\")\n",
    "else:\n",
    "    print(\" Les embeddings BERT n'existent pas encore. Génération en cours...\")\n",
    "    print(\"   (Cette opération peut prendre plus de 2 heures la première fois)\")\n",
    "    \n",
    "    # Charger le Tokenizer et le Modèle\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model_bert = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    def get_bert_embeddings(texts):\n",
    "        \"\"\"Génère les embeddings BERT par batch.\"\"\"\n",
    "        embeddings = []\n",
    "        \n",
    "        text_data = texts  \n",
    "        for i in range(0, len(text_data), BATCH_SIZE):\n",
    "            batch = text_data[i:i + BATCH_SIZE]\n",
    "            \n",
    "            # Affichage de la progression\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"   Progression : {i}/{len(text_data)} textes traités...\")\n",
    "            \n",
    "            # 1. Tokenisation (avec paddings et attention mask)\n",
    "            encoded_input = tokenizer(\n",
    "                batch, \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                max_length=MAX_LENGTH, \n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            # 2. Passage dans le modèle\n",
    "            with torch.no_grad():\n",
    "                model_output = model_bert(**encoded_input)\n",
    "                \n",
    "            # 3. Extraction du vecteur [CLS] (représentation de la phrase entière)\n",
    "            # C'est la première position du last_hidden_state\n",
    "            batch_embeddings = model_output.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            embeddings.append(batch_embeddings)\n",
    "            \n",
    "        return np.vstack(embeddings)\n",
    "\n",
    "    print(f\"\\n Extraction des features BERT en cours (Modèle : {MODEL_NAME}, Taille : {MAX_LENGTH})...\")\n",
    "\n",
    "    #Récupération des données BERT en utilisant les indices du split existant.\n",
    "    # Les variables X_train et X_test conservent les indices originaux de df_train.\n",
    "    # Nous récupérons le texte BERT correspondant à ces indices.\n",
    "    X_train_dl_tokens = df_train.loc[X_train.index, 'Tokens_DL']\n",
    "    X_test_dl_tokens = df_train.loc[X_test.index, 'Tokens_DL']\n",
    "\n",
    "    # On s'assure que c'est bien une liste de chaînes de caractères (format attendu par le tokenizer)\n",
    "    X_train_dl_list = X_train_dl_tokens.tolist()\n",
    "    X_test_dl_list = X_test_dl_tokens.tolist()\n",
    "\n",
    "    # Création des Features BERT\n",
    "    start_time = time.time()\n",
    "    print(\"\\n Génération des embeddings pour le jeu d'ENTRAÎNEMENT...\")\n",
    "    X_train_bert = get_bert_embeddings(X_train_dl_list)\n",
    "    \n",
    "    print(\"\\n Génération des embeddings pour le jeu de TEST...\")\n",
    "    X_test_bert = get_bert_embeddings(X_test_dl_list)\n",
    "    \n",
    "    bert_embed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"\\n Extraction BERT terminée en {bert_embed_time:.2f} secondes ({bert_embed_time/60:.2f} minutes).\")\n",
    "    print(f\"   - Forme des features BERT (train) : {X_train_bert.shape}\")\n",
    "    print(f\"   - Forme des features BERT (test) : {X_test_bert.shape}\")\n",
    "    \n",
    "    # Sauvegarder les embeddings pour les prochaines exécutions\n",
    "    print(f\"\\n Sauvegarde des embeddings BERT dans '{BERT_EMBEDDINGS_DIR}'...\")\n",
    "    np.save(BERT_TRAIN_PATH, X_train_bert)\n",
    "    np.save(BERT_TEST_PATH, X_test_bert)\n",
    "    print(f\" Embeddings sauvegardés avec succès!\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89199a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Démarrage de l'entraînement LogisticRegression avec BERT (C=0.1) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/04 18:08:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Entraînement BERT terminé.\n",
      "F1-Score Micro (BERT) : 0.2607\n",
      "Taux de Couverture (Top 5) : 0.5804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/04 18:08:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run MLFlow ID : e8145289c8bc4d14873c9688e011c051\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import mlflow\n",
    "\n",
    "\n",
    "#1. DÉFINIR LA FONCTION EN PREMIER\n",
    "\n",
    "\n",
    "def coverage_rate_top_k(Y_true, Y_probas, mlb, k=5):\n",
    "    \"\"\"\n",
    "    Calcule le taux de couverture des tags : \n",
    "    (Nombre de vrais tags présents dans le top K des tags prédits) / (Nombre total de vrais tags)\n",
    "    \"\"\"\n",
    "    top_k_indices = np.argsort(Y_probas, axis=1)[:, -k:]\n",
    "    \n",
    "    total_coverage = 0\n",
    "    total_relevant_tags = 0\n",
    "    \n",
    "    for i in range(Y_true.shape[0]):\n",
    "        true_tags_indices = np.where(Y_true[i] == 1)[0]\n",
    "        predicted_top_k_indices = set(top_k_indices[i])\n",
    "        correctly_covered = len(set(true_tags_indices).intersection(predicted_top_k_indices))\n",
    "        num_true_tags = len(true_tags_indices)\n",
    "        \n",
    "        if num_true_tags > 0:\n",
    "            total_coverage += correctly_covered / num_true_tags\n",
    "            total_relevant_tags += 1\n",
    "            \n",
    "    if total_relevant_tags == 0:\n",
    "        return 0.0\n",
    "    return total_coverage / total_relevant_tags\n",
    "\n",
    "=\n",
    "# TRAINING MLFLOW \n",
    "\n",
    "EXPERIMENT_NAME = \"Approche_Supervisee_Features\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "MODEL_NAME = \"LogisticRegression\"\n",
    "C_PARAM = 0.1\n",
    "FEATURE_TYPE = \"BERT\"\n",
    "K_SUGGEST = 5\n",
    "\n",
    "print(f\"\\n--- Démarrage de l'entraînement {MODEL_NAME} avec {FEATURE_TYPE} (C={C_PARAM}) ---\")\n",
    "\n",
    "try:\n",
    "    _ = bert_embed_time \n",
    "except NameError:\n",
    "    bert_embed_time = 0 \n",
    "\n",
    "with mlflow.start_run(run_name=f\"{FEATURE_TYPE}_{MODEL_NAME}_C{C_PARAM}\") as run:\n",
    "    \n",
    "    mlflow.log_params({\n",
    "        \"feature_type\": FEATURE_TYPE,\n",
    "        \"C_param\": C_PARAM,\n",
    "        \"top_k_suggested\": K_SUGGEST\n",
    "    })\n",
    "    \n",
    "    if bert_embed_time > 0:\n",
    "        mlflow.log_metric(\"embedding_time_sec\", bert_embed_time) \n",
    "\n",
    "    classifier_bert = OneVsRestClassifier(LogisticRegression(\n",
    "        C=C_PARAM, \n",
    "        solver='saga', \n",
    "        random_state=42,\n",
    "        ),\n",
    "        n_jobs=-1 \n",
    "    )\n",
    "    \n",
    "    start_time_fit = time.time()\n",
    "    classifier_bert.fit(X_train_bert, Y_train) \n",
    "    fit_time = time.time() - start_time_fit\n",
    "    \n",
    "    Y_pred_bert = classifier_bert.predict(X_test_bert)\n",
    "    f1_micro = f1_score(Y_test, Y_pred_bert, average='micro')\n",
    "\n",
    "    Y_probas_bert = classifier_bert.predict_proba(X_test_bert)\n",
    "    tctp_score = coverage_rate_top_k(Y_test, Y_probas_bert, mlb, k=K_SUGGEST)\n",
    "    \n",
    "    mlflow.log_metric(\"f1_micro\", f1_micro)\n",
    "    mlflow.log_metric(f\"tctp_top_{K_SUGGEST}\", tctp_score) \n",
    "    mlflow.log_metric(\"fit_time_sec\", fit_time)\n",
    "    \n",
    "    print(f\"\\n Entraînement BERT terminé.\")\n",
    "    print(f\"F1-Score Micro (BERT) : {f1_micro:.4f}\")\n",
    "    print(f\"Taux de Couverture (Top {K_SUGGEST}) : {tctp_score:.4f}\")\n",
    "    \n",
    "    mlflow.sklearn.log_model(sk_model=classifier_bert, name=\"bert_classifier\")\n",
    "    \n",
    "    print(f\"\\nRun MLFlow ID : {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "281b4d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chargement des embeddings USE sauvegardés...\n",
      " Embeddings USE chargés : (37565, 512)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Configuration\n",
    "USE_MODEL_URL = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "USE_BATCH_SIZE = 100  # Traitement par batch de 100 textes\n",
    "\n",
    "# Dossier pour sauvegarder les embeddings USE\n",
    "USE_EMBEDDINGS_DIR = './data/use_embeddings'\n",
    "os.makedirs(USE_EMBEDDINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Chemins des fichiers de sauvegarde\n",
    "USE_TRAIN_PATH = os.path.join(USE_EMBEDDINGS_DIR, 'X_train_use.npy')\n",
    "USE_TEST_PATH = os.path.join(USE_EMBEDDINGS_DIR, 'X_test_use.npy')\n",
    "\n",
    "# Vérifier si les embeddings USE existent déjà\n",
    "if os.path.exists(USE_TRAIN_PATH) and os.path.exists(USE_TEST_PATH):\n",
    "    print(\" Chargement des embeddings USE sauvegardés...\")\n",
    "    X_train_use = np.load(USE_TRAIN_PATH)\n",
    "    X_test_use = np.load(USE_TEST_PATH)\n",
    "    use_embed_time = 0\n",
    "    print(f\" Embeddings USE chargés : {X_train_use.shape}\")\n",
    "else:\n",
    "    print(\" Génération des embeddings USE (traitement par batch)...\")\n",
    "    \n",
    "    # Chargement du modèle USE\n",
    "    use_model = hub.load(USE_MODEL_URL)\n",
    "    print(\" Modèle USE chargé!\")\n",
    "    \n",
    "    def get_use_embeddings_batch(texts, model, batch_size=100):\n",
    "        \"\"\"Génère les embeddings USE par batch.\"\"\"\n",
    "        embeddings = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"   Progression : {i}/{len(texts)} textes...\")\n",
    "            batch_embeddings = model(batch).numpy()\n",
    "            embeddings.append(batch_embeddings)\n",
    "        return np.vstack(embeddings)\n",
    "    \n",
    "    # Récupération des données\n",
    "    X_train_dl_tokens = df_train.loc[X_train.index, 'Tokens_DL']\n",
    "    X_test_dl_tokens = df_train.loc[X_test.index, 'Tokens_DL']\n",
    "    X_train_dl_list = X_train_dl_tokens.tolist()\n",
    "    X_test_dl_list = X_test_dl_tokens.tolist()\n",
    "    \n",
    "    # Génération des embeddings\n",
    "    start_time = time.time()\n",
    "    print(\"\\n Train...\")\n",
    "    X_train_use = get_use_embeddings_batch(X_train_dl_list, use_model, USE_BATCH_SIZE)\n",
    "    print(\"\\n Test...\")\n",
    "    X_test_use = get_use_embeddings_batch(X_test_dl_list, use_model, USE_BATCH_SIZE)\n",
    "    use_embed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n Terminé en {use_embed_time/60:.2f} minutes\")\n",
    "    print(f\"   Train: {X_train_use.shape}, Test: {X_test_use.shape}\")\n",
    "    \n",
    "    # Sauvegarde\n",
    "    print(f\"\\n Sauvegarde...\")\n",
    "    np.save(USE_TRAIN_PATH, X_train_use)\n",
    "    np.save(USE_TEST_PATH, X_test_use)\n",
    "    print(f\" Embeddings sauvegardés!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc1928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/28 12:30:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score Micro (USE) : 0.2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/28 12:30:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run MLFlow ID : 96d312bd96a74882a1b58c821cd651e0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EXPERIMENT_NAME = \"Approche_Supervisee_Features\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "MODEL_NAME = \"LogisticRegression\"\n",
    "C_PARAM = 0.1\n",
    "FEATURE_TYPE = \"USE\"\n",
    "\n",
    "with mlflow.start_run(run_name=f\"{FEATURE_TYPE}_{MODEL_NAME}\") as run:\n",
    "    \n",
    "    # 1. Enregistrement des paramètres\n",
    "    mlflow.log_param(\"feature_type\", FEATURE_TYPE)\n",
    "    mlflow.log_param(\"C_param\", C_PARAM)\n",
    "    mlflow.log_metric(\"embedding_time_sec\", use_embed_time) \n",
    "\n",
    "    # 2. Définition et Entraînement\n",
    "    classifier = OneVsRestClassifier(LogisticRegression(C=C_PARAM, solver='liblinear', random_state=42))\n",
    "    start_time = time.time()\n",
    "    classifier.fit(X_train_use, Y_train)\n",
    "    fit_time = time.time() - start_time\n",
    "    \n",
    "    # 3. Prédiction et Métriques\n",
    "    Y_pred_use = classifier.predict(X_test_use)\n",
    "    f1_micro = f1_score(Y_test, Y_pred_use, average='micro')\n",
    "    \n",
    "    mlflow.log_metric(\"f1_micro\", f1_micro)\n",
    "    mlflow.log_metric(\"fit_time_sec\", fit_time)\n",
    "    \n",
    "    print(f\"F1-Score Micro (USE) : {f1_micro:.4f}\")\n",
    "    \n",
    "    mlflow.sklearn.log_model(sk_model=classifier, name=\"use_classifier\")\n",
    "    print(f\"\\nRun MLFlow ID : {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d76ba188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Run: data=<RunData: metrics={'f1_micro': 0.26068759342301945,\n",
      " 'fit_time_sec': 2169.288969039917,\n",
      " 'tctp_top_5': 0.5803573963657009}, params={'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}, tags={'mlflow.runName': 'BERT_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/e8145289c8bc4d14873c9688e011c051/artifacts', end_time=1764868129991, experiment_id='282807502113289851', lifecycle_stage='active', run_id='e8145289c8bc4d14873c9688e011c051', run_name='BERT_LogisticRegression_C0.1', start_time=1764865920468, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[<LoggedModelOutput: model_id='m-26653bd7df1e448e874ed39516ac09a6', step=0>]>>, <Run: data=<RunData: metrics={}, params={'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}, tags={'mlflow.runName': 'BERT_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/d18c0b3561574de6a220592188cfd1e1/artifacts', end_time=1764865547179, experiment_id='282807502113289851', lifecycle_stage='active', run_id='d18c0b3561574de6a220592188cfd1e1', run_name='BERT_LogisticRegression_C0.1', start_time=1764863314553, status='FAILED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={}, params={'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}, tags={'mlflow.runName': 'BERT_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/150033c205474564b306fcf5e7115319/artifacts', end_time=1764863210795, experiment_id='282807502113289851', lifecycle_stage='active', run_id='150033c205474564b306fcf5e7115319', run_name='BERT_LogisticRegression_C0.1', start_time=1764862309406, status='FAILED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={}, params={'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}, tags={'mlflow.runName': 'BERT_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/42e69469671241ff8c0ddb5558dac790/artifacts', end_time=1764862174350, experiment_id='282807502113289851', lifecycle_stage='active', run_id='42e69469671241ff8c0ddb5558dac790', run_name='BERT_LogisticRegression_C0.1', start_time=1764860044383, status='FAILED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={'f1_micro': 0.10660520766929829,\n",
      " 'fit_time_sec': 78.44549679756165,\n",
      " 'hamming_loss': 0.004898591967373909,\n",
      " 'precision_micro': 0.8823051948051948,\n",
      " 'recall_micro': 0.05672981577161944}, params={'C_param': '0.1',\n",
      " 'feature_type': 'TF-IDF (BoW)',\n",
      " 'max_features_tfidf': '20000',\n",
      " 'model': 'LogisticRegression'}, tags={'mlflow.runName': 'TF-IDF (BoW)_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/7ecdccfb5cad4f0fbd0cf4869ce8ca84/artifacts', end_time=1764847747582, experiment_id='282807502113289851', lifecycle_stage='active', run_id='7ecdccfb5cad4f0fbd0cf4869ce8ca84', run_name='TF-IDF (BoW)_LogisticRegression_C0.1', start_time=1764847668047, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={}, params={}, tags={'mlflow.runName': 'TF-IDF (BoW)_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/375a085d2a964a6f91815f41f855186a/artifacts', end_time=1764847500741, experiment_id='282807502113289851', lifecycle_stage='active', run_id='375a085d2a964a6f91815f41f855186a', run_name='TF-IDF (BoW)_LogisticRegression_C0.1', start_time=1764847500665, status='FAILED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={}, params={'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}, tags={'mlflow.runName': 'BERT_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/d4358e642c79417091ffa42d81503873/artifacts', end_time=1764845535152, experiment_id='282807502113289851', lifecycle_stage='active', run_id='d4358e642c79417091ffa42d81503873', run_name='BERT_LogisticRegression_C0.1', start_time=1764845535087, status='FAILED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={}, params={'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}, tags={'mlflow.runName': 'BERT_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/519a78bf3d784161ac0eeef4945f2718/artifacts', end_time=1764845166869, experiment_id='282807502113289851', lifecycle_stage='active', run_id='519a78bf3d784161ac0eeef4945f2718', run_name='BERT_LogisticRegression_C0.1', start_time=1764845166789, status='FAILED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={'embedding_time_sec': 53.00649952888489,\n",
      " 'f1_micro': 0.25897379431843204,\n",
      " 'fit_time_sec': 726.1925277709961}, params={'C_param': '0.1', 'feature_type': 'USE'}, tags={'mlflow.runName': 'USE_LogisticRegression',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/96d312bd96a74882a1b58c821cd651e0/artifacts', end_time=1764329448525, experiment_id='282807502113289851', lifecycle_stage='active', run_id='96d312bd96a74882a1b58c821cd651e0', run_name='USE_LogisticRegression', start_time=1764328694068, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[<LoggedModelOutput: model_id='m-09421745df49416d82fb4a34777cde45', step=0>]>>, <Run: data=<RunData: metrics={'f1_micro': 0.30660586739841006, 'fit_time_sec': 264.4144322872162}, params={'C_param': '0.1',\n",
      " 'feature_type': 'Word2Vec_Mean',\n",
      " 'model': 'LogisticRegression',\n",
      " 'w2v_vector_size': '100',\n",
      " 'w2v_window': '5'}, tags={'mlflow.runName': 'Word2Vec_Mean_LogisticRegression_V100',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/adab6eead21748aabef90e9232bee797/artifacts', end_time=1764254265126, experiment_id='282807502113289851', lifecycle_stage='active', run_id='adab6eead21748aabef90e9232bee797', run_name='Word2Vec_Mean_LogisticRegression_V100', start_time=1764253978955, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[<LoggedModelOutput: model_id='m-9aeeed6183254fd7bcb97d712500e52b', step=0>]>>, <Run: data=<RunData: metrics={'f1_micro': 0.10660520766929829,\n",
      " 'fit_time_sec': 90.97752141952515,\n",
      " 'hamming_loss': 0.004898591967373909,\n",
      " 'precision_micro': 0.8823051948051948,\n",
      " 'recall_micro': 0.05672981577161944}, params={'C_param': '0.1',\n",
      " 'feature_type': 'TF-IDF (BoW)',\n",
      " 'max_features_tfidf': '20000',\n",
      " 'model': 'LogisticRegression'}, tags={'mlflow.runName': 'TF-IDF (BoW)_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/d3f6645f13ff4624bbf0eabfb34277b4/artifacts', end_time=1764253671948, experiment_id='282807502113289851', lifecycle_stage='active', run_id='d3f6645f13ff4624bbf0eabfb34277b4', run_name='TF-IDF (BoW)_LogisticRegression_C0.1', start_time=1764253579839, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={'f1_micro': 0.10660520766929829,\n",
      " 'fit_time_sec': 92.31606650352478,\n",
      " 'hamming_loss': 0.004898591967373909,\n",
      " 'precision_micro': 0.8823051948051948,\n",
      " 'recall_micro': 0.05672981577161944}, params={'C_param': '0.1',\n",
      " 'feature_type': 'TF-IDF (BoW)',\n",
      " 'max_features_tfidf': '20000',\n",
      " 'model': 'LogisticRegression'}, tags={'mlflow.runName': 'TF-IDF (BoW)_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/fdaea784ff5342a0859c11e4c0f1e0f8/artifacts', end_time=1764252815843, experiment_id='282807502113289851', lifecycle_stage='active', run_id='fdaea784ff5342a0859c11e4c0f1e0f8', run_name='TF-IDF (BoW)_LogisticRegression_C0.1', start_time=1764252722170, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={'f1_micro': 0.10660520766929829,\n",
      " 'fit_time_sec': 83.714923620224,\n",
      " 'hamming_loss': 0.004898591967373909,\n",
      " 'precision_micro': 0.8823051948051948,\n",
      " 'recall_micro': 0.05672981577161944}, params={'C_param': '0.1',\n",
      " 'feature_type': 'TF-IDF (BoW)',\n",
      " 'max_features_tfidf': '20000',\n",
      " 'model': 'LogisticRegression'}, tags={'mlflow.runName': 'TF-IDF (BoW)_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/c74c14c1130946f0a02a76cac9d33545/artifacts', end_time=1764251920489, experiment_id='282807502113289851', lifecycle_stage='active', run_id='c74c14c1130946f0a02a76cac9d33545', run_name='TF-IDF (BoW)_LogisticRegression_C0.1', start_time=1764251835667, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={}, params={'C_param': '0.1',\n",
      " 'feature_type': 'TF-IDF (BoW)',\n",
      " 'max_features_tfidf': '20000',\n",
      " 'model': 'LogisticRegression'}, tags={'mlflow.runName': 'TF-IDF (BoW)_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/289073ca90db45618ca1d9b6c9c30212/artifacts', end_time=1764251342625, experiment_id='282807502113289851', lifecycle_stage='active', run_id='289073ca90db45618ca1d9b6c9c30212', run_name='TF-IDF (BoW)_LogisticRegression_C0.1', start_time=1764251342529, status='FAILED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>, <Run: data=<RunData: metrics={'f1_micro': 0.10660520766929829,\n",
      " 'fit_time_sec': 73.08911418914795,\n",
      " 'hamming_loss': 0.004898591967373909,\n",
      " 'precision_micro': 0.8823051948051948,\n",
      " 'recall_micro': 0.05672981577161944}, params={'C_param': '0.1',\n",
      " 'feature_type': 'TF-IDF (BoW)',\n",
      " 'max_features_tfidf': '20000',\n",
      " 'model': 'LogisticRegression'}, tags={'mlflow.runName': 'TF-IDF (BoW)_LogisticRegression_C0.1',\n",
      " 'mlflow.source.name': 'c:\\\\Users\\\\lza\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'lza'}>, info=<RunInfo: artifact_uri='file:///c:/Users/lza/Documents/P05_Projet_tags_StackOverflow/mlruns/282807502113289851/f3a78a5c0a304b65999860d05c6cb219/artifacts', end_time=1764247767652, experiment_id='282807502113289851', lifecycle_stage='active', run_id='f3a78a5c0a304b65999860d05c6cb219', run_name='TF-IDF (BoW)_LogisticRegression_C0.1', start_time=1764247693529, status='FINISHED', user_id='lza'>, inputs=<RunInputs: dataset_inputs=[], model_inputs=[]>, outputs=<RunOutputs: model_outputs=[]>>]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "K_SUGGEST = 5 \n",
    "EXPERIMENT_NAME = \"Approche_Supervisee_Features\"\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "if experiment:\n",
    "    # Récupérer tous les runs (sans filtre problématique)\n",
    "    runs_data = client.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        order_by=[f\"metrics.tctp_top_{K_SUGGEST} DESC\"]\n",
    "    )\n",
    "print(runs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6354d095",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PagedList' object has no attribute 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mruns_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mfeature_type\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mAttributeError\u001b[39m: 'PagedList' object has no attribute 'params'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6c32023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de runs : 15\n",
      "\n",
      "--- Run: BERT_LogisticRegression_C0.1 ---\n",
      "   Params: {'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}\n",
      "   Metrics: {'f1_micro': 0.26068759342301945, 'fit_time_sec': 2169.288969039917, 'tctp_top_5': 0.5803573963657009}\n",
      "\n",
      "--- Run: BERT_LogisticRegression_C0.1 ---\n",
      "   Params: {'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}\n",
      "   Metrics: {}\n",
      "\n",
      "--- Run: BERT_LogisticRegression_C0.1 ---\n",
      "   Params: {'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}\n",
      "   Metrics: {}\n",
      "\n",
      "--- Run: BERT_LogisticRegression_C0.1 ---\n",
      "   Params: {'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}\n",
      "   Metrics: {}\n",
      "\n",
      "--- Run: TF-IDF (BoW)_LogisticRegression_C0.1 ---\n",
      "   Params: {'C_param': '0.1', 'feature_type': 'TF-IDF (BoW)', 'max_features_tfidf': '20000', 'model': 'LogisticRegression'}\n",
      "   Metrics: {'f1_micro': 0.10660520766929829, 'fit_time_sec': 78.44549679756165, 'hamming_loss': 0.004898591967373909, 'precision_micro': 0.8823051948051948, 'recall_micro': 0.05672981577161944}\n",
      "\n",
      "--- Run: TF-IDF (BoW)_LogisticRegression_C0.1 ---\n",
      "   Params: {}\n",
      "   Metrics: {}\n",
      "\n",
      "--- Run: BERT_LogisticRegression_C0.1 ---\n",
      "   Params: {'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}\n",
      "   Metrics: {}\n",
      "\n",
      "--- Run: BERT_LogisticRegression_C0.1 ---\n",
      "   Params: {'C_param': '0.1', 'feature_type': 'BERT', 'top_k_suggested': '5'}\n",
      "   Metrics: {}\n",
      "\n",
      "--- Run: USE_LogisticRegression ---\n",
      "   Params: {'C_param': '0.1', 'feature_type': 'USE'}\n",
      "   Metrics: {'embedding_time_sec': 53.00649952888489, 'f1_micro': 0.25897379431843204, 'fit_time_sec': 726.1925277709961}\n",
      "\n",
      "--- Run: Word2Vec_Mean_LogisticRegression_V100 ---\n",
      "   Params: {'C_param': '0.1', 'feature_type': 'Word2Vec_Mean', 'model': 'LogisticRegression', 'w2v_vector_size': '100', 'w2v_window': '5'}\n",
      "   Metrics: {'f1_micro': 0.30660586739841006, 'fit_time_sec': 264.4144322872162}\n",
      "\n",
      "--- Run: TF-IDF (BoW)_LogisticRegression_C0.1 ---\n",
      "   Params: {'C_param': '0.1', 'feature_type': 'TF-IDF (BoW)', 'max_features_tfidf': '20000', 'model': 'LogisticRegression'}\n",
      "   Metrics: {'f1_micro': 0.10660520766929829, 'fit_time_sec': 90.97752141952515, 'hamming_loss': 0.004898591967373909, 'precision_micro': 0.8823051948051948, 'recall_micro': 0.05672981577161944}\n",
      "\n",
      "--- Run: TF-IDF (BoW)_LogisticRegression_C0.1 ---\n",
      "   Params: {'C_param': '0.1', 'feature_type': 'TF-IDF (BoW)', 'max_features_tfidf': '20000', 'model': 'LogisticRegression'}\n",
      "   Metrics: {'f1_micro': 0.10660520766929829, 'fit_time_sec': 92.31606650352478, 'hamming_loss': 0.004898591967373909, 'precision_micro': 0.8823051948051948, 'recall_micro': 0.05672981577161944}\n",
      "\n",
      "--- Run: TF-IDF (BoW)_LogisticRegression_C0.1 ---\n",
      "   Params: {'C_param': '0.1', 'feature_type': 'TF-IDF (BoW)', 'max_features_tfidf': '20000', 'model': 'LogisticRegression'}\n",
      "   Metrics: {'f1_micro': 0.10660520766929829, 'fit_time_sec': 83.714923620224, 'hamming_loss': 0.004898591967373909, 'precision_micro': 0.8823051948051948, 'recall_micro': 0.05672981577161944}\n",
      "\n",
      "--- Run: TF-IDF (BoW)_LogisticRegression_C0.1 ---\n",
      "   Params: {'C_param': '0.1', 'feature_type': 'TF-IDF (BoW)', 'max_features_tfidf': '20000', 'model': 'LogisticRegression'}\n",
      "   Metrics: {}\n",
      "\n",
      "--- Run: TF-IDF (BoW)_LogisticRegression_C0.1 ---\n",
      "   Params: {'C_param': '0.1', 'feature_type': 'TF-IDF (BoW)', 'max_features_tfidf': '20000', 'model': 'LogisticRegression'}\n",
      "   Metrics: {'f1_micro': 0.10660520766929829, 'fit_time_sec': 73.08911418914795, 'hamming_loss': 0.004898591967373909, 'precision_micro': 0.8823051948051948, 'recall_micro': 0.05672981577161944}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(\"Approche_Supervisee_Features\")\n",
    "\n",
    "if experiment:\n",
    "    runs = client.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "    print(f\"Nombre total de runs : {len(runs)}\\n\")\n",
    "    \n",
    "    for run in runs:\n",
    "        print(f\"--- Run: {run.info.run_name} ---\")\n",
    "        print(f\"   Params: {run.data.params}\")\n",
    "        print(f\"   Metrics: {run.data.metrics}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b68d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tableau Récapitulatif des Performances :\n",
      "\n",
      "| Modèle   |   F1_Micro |   TCTP_Top5 |   Temps_Entrainement_sec |\n",
      "|:---------|-----------:|------------:|-------------------------:|\n",
      "| BERT     |   0.260688 |    0.580357 |                  2169.29 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lza\\AppData\\Local\\Temp\\ipykernel_22864\\3822659239.py:47: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Modèle', y='F1_Micro', data=df_results, ax=ax[0], palette=\"Blues_d\")\n",
      "C:\\Users\\lza\\AppData\\Local\\Temp\\ipykernel_22864\\3822659239.py:53: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Modèle', y='TCTP_Top5', data=df_results, ax=ax[1], palette=\"Greens_d\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "K_SUGGEST = 5 \n",
    "EXPERIMENT_NAME = \"Approche_Supervisee_Features\"\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "if experiment:\n",
    "    # Récupérer tous les runs (sans filtre problématique)\n",
    "    runs_data = client.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        order_by=[f\"metrics.tctp_top_{K_SUGGEST} DESC\"]\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    for run in runs_data:\n",
    "        # Vérifier que le run a bien la métrique TCTP\n",
    "        if f'tctp_top_{K_SUGGEST}' in run.data.metrics:\n",
    "            \n",
    "            feature_type = run.data.params.get('feature_type', 'N/A')\n",
    "            # Nettoyage des noms\n",
    "            if feature_type == 'TF-IDF (BoW)':\n",
    "                feature_type = 'TF-IDF'\n",
    "            elif feature_type == 'Word2Vec_Mean':\n",
    "                feature_type = 'Word2Vec'\n",
    "            \n",
    "            results.append({\n",
    "                'Modèle': feature_type,\n",
    "                'F1_Micro': run.data.metrics.get('f1_micro', 0),\n",
    "                'TCTP_Top5': run.data.metrics.get(f'tctp_top_{K_SUGGEST}', 0),\n",
    "                'Temps_Entrainement_sec': run.data.metrics.get('fit_time_sec', 0),\n",
    "            })\n",
    "\n",
    "    if results:  # Vérifier qu'on a des résultats\n",
    "        df_results = pd.DataFrame(results).sort_values(by='TCTP_Top5', ascending=False)\n",
    "        \n",
    "        print(\"\\n Tableau Récapitulatif des Performances :\\n\")\n",
    "        print(df_results.to_markdown(index=False))\n",
    "\n",
    "        # --- Graphique ---\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        sns.barplot(x='Modèle', y='F1_Micro', data=df_results, ax=ax[0], palette=\"Blues_d\")\n",
    "        ax[0].set_title('F1-Score Micro')\n",
    "        ax[0].set_ylabel('F1-Score')\n",
    "        ax[0].set_ylim(0, 1)  # Échelle fixe pour mieux comparer\n",
    "        ax[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        sns.barplot(x='Modèle', y='TCTP_Top5', data=df_results, ax=ax[1], palette=\"Greens_d\")\n",
    "        ax[1].set_title(f'Taux de Couverture (Top {K_SUGGEST})')\n",
    "        ax[1].set_ylabel('TCTP')\n",
    "        ax[1].set_ylim(0, 1)\n",
    "        ax[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        plt.suptitle('Comparaison des Modèles Supervisés', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('comparaison_modeles.png', dpi=150, bbox_inches='tight')  # Sauvegarde pour le rapport\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\" Aucun run avec la métrique TCTP trouvé.\")\n",
    "else:\n",
    "    print(\" Expérience non trouvée.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
